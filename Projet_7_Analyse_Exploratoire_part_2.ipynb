{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fa8de6ef",
   "metadata": {},
   "source": [
    "# Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aca084d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import scipy.stats as stats\n",
    "import researchpy as rp\n",
    "import re\n",
    "import featuretools as ft\n",
    "from sklearn.impute import SimpleImputer\n",
    "from functools import reduce\n",
    "\n",
    "\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "import mlflow.lightgbm\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import lightgbm as lgb\n",
    "from sklearn.pipeline import make_pipeline, Pipeline\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold\n",
    "\n",
    "from sklearn.metrics import accuracy_score, f1_score, classification_report, make_scorer\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.metrics import roc_auc_score, roc_curve\n",
    "from sklearn.metrics import precision_recall_curve, auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d008c02f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_colwidth', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae0f3e35",
   "metadata": {},
   "source": [
    "push test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3eb82697",
   "metadata": {},
   "source": [
    "# Fonctions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "711ea632",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataset_overview(df):\n",
    "    \"\"\"\n",
    "    Provides a comprehensive overview of a pandas DataFrame including:\n",
    "    - Shape of the dataset\n",
    "    - Column names and data types\n",
    "    - Missing values\n",
    "    - Basic statistics for numeric columns\n",
    "    - Unique values for categorical columns\n",
    "    \"\"\"\n",
    "\n",
    "    print(\"=\"*80)\n",
    "    print(\"DATASET OVERVIEW\")\n",
    "    print(\"=\"*80)\n",
    "\n",
    "    # Basic info\n",
    "    print(\"\\nDATASET SHAPE:\")\n",
    "    print(f\"Rows: {df.shape[0]}, Columns: {df.shape[1]}\")\n",
    "\n",
    "    print(\"/nCOLUMN INFORMATION:\")\n",
    "    print(df.dtypes.to_string())\n",
    "\n",
    "    # Missing values\n",
    "    print(\"/nMISSING VALUES:\")\n",
    "    missing = df.isnull().sum()\n",
    "    missing_percent = (missing / len(df)) * 100\n",
    "    missing_df = pd.DataFrame({'Missing Values': missing,\n",
    "                              'Percentage (%)': missing_percent.round(2)})\n",
    "    print(missing_df[missing_df['Missing Values'] > 0].sort_values('Percentage (%)', ascending=False))\n",
    "\n",
    "    # Numeric columns statistics\n",
    "    numeric_cols = df.select_dtypes(include=[np.number]).columns\n",
    "    if len(numeric_cols) > 0:\n",
    "        print(\"/nNUMERIC COLUMNS STATISTICS:\")\n",
    "        print(df[numeric_cols].describe().transpose()[['mean', '50%', 'std', 'min', 'max']]\n",
    "              .rename(columns={'50%': 'median'}))\n",
    "\n",
    "    # Categorical columns statistics\n",
    "    cat_cols = df.select_dtypes(include=['object', 'category']).columns\n",
    "    if len(cat_cols) > 0:\n",
    "        print(\"/nCATEGORICAL COLUMNS STATISTICS:\")\n",
    "        for col in cat_cols:\n",
    "            print(f\"\\nColumn: {col}\")\n",
    "            print(f\"Unique values: {df[col].nunique()}\")\n",
    "            print(\"Top 5 values:\")\n",
    "            print(df[col].value_counts().head())\n",
    "\n",
    "    print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "520d1d67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calculate missing values by column# Funct\n",
    "def missing_values_table(df):\n",
    "        # Total missing values\n",
    "        mis_val = df.isnull().sum()\n",
    "\n",
    "        # Percentage of missing values\n",
    "        mis_val_percent = 100 * df.isnull().sum() / len(df)\n",
    "\n",
    "        # Make a table with the results\n",
    "        mis_val_table = pd.concat([mis_val, mis_val_percent], axis=1)\n",
    "\n",
    "        # Rename the columns\n",
    "        mis_val_table_ren_columns = mis_val_table.rename(\n",
    "        columns = {0 : 'Missing Values', 1 : '% of Total Values'})\n",
    "\n",
    "        # Sort the table by percentage of missing descending\n",
    "        mis_val_table_ren_columns = mis_val_table_ren_columns[\n",
    "            mis_val_table_ren_columns.iloc[:,1] != 0].sort_values(\n",
    "        '% of Total Values', ascending=False).round(1)\n",
    "\n",
    "        # Print some summary information\n",
    "        print (\"Your selected dataframe has \" + str(df.shape[1]) + \" columns.\\n\"\n",
    "            \"There are \" + str(mis_val_table_ren_columns.shape[0]) +\n",
    "              \" columns that have missing values.\")\n",
    "\n",
    "        # Return the dataframe with missing information\n",
    "        return mis_val_table_ren_columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99655b97",
   "metadata": {},
   "source": [
    "## Fonction pour aggrégation valeurs numériques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "96e34967",
   "metadata": {},
   "outputs": [],
   "source": [
    "def agg_numeric(df, group_var, df_name):\n",
    "    \"\"\"Aggregates the numeric values in a dataframe. This can\n",
    "    be used to create features for each instance of the grouping variable.\n",
    "    \n",
    "    Parameters\n",
    "    --------\n",
    "        df (dataframe): \n",
    "            the dataframe to calculate the statistics on\n",
    "        group_var (string): \n",
    "            the variable by which to group df\n",
    "        df_name (string): \n",
    "            the variable used to rename the columns\n",
    "        \n",
    "    Return\n",
    "    --------\n",
    "        agg (dataframe): \n",
    "            a dataframe with the statistics aggregated for \n",
    "            all numeric columns. Each instance of the grouping variable will have \n",
    "            the statistics (mean, min, max, sum; currently supported) calculated. \n",
    "            The columns are also renamed to keep track of features created.\n",
    "    \n",
    "    \"\"\"\n",
    "    # Remove id variables other than grouping variable\n",
    "    for col in df:\n",
    "        if col != group_var and 'SK_ID' in col:\n",
    "            df = df.drop(columns = col)\n",
    "            \n",
    "    group_ids = df[group_var]\n",
    "    numeric_df = df.select_dtypes('number')\n",
    "    numeric_df[group_var] = group_ids\n",
    "\n",
    "    # Group by the specified variable and calculate the statistics\n",
    "    agg = numeric_df.groupby(group_var).agg(['count', 'mean', 'max', 'min', 'sum']).reset_index()\n",
    "\n",
    "    # Need to create new column names\n",
    "    columns = [group_var]\n",
    "\n",
    "    # Iterate through the variables names\n",
    "    for var in agg.columns.levels[0]:\n",
    "        # Skip the grouping variable\n",
    "        if var != group_var:\n",
    "            # Iterate through the stat names\n",
    "            for stat in agg.columns.levels[1][:-1]:\n",
    "                # Make a new column name for the variable and stat\n",
    "                columns.append('%s_%s_%s' % (df_name, var, stat))\n",
    "\n",
    "    agg.columns = columns\n",
    "    return agg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d991f7bb",
   "metadata": {},
   "source": [
    "## Fonction pour aggréger variables catégorielles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7bf5633c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_categorical(df, group_var, df_name):\n",
    "    \"\"\"Computes counts and normalized counts for each observation\n",
    "    of `group_var` of each unique category in every categorical variable\n",
    "    \n",
    "    Parameters\n",
    "    --------\n",
    "    df : dataframe \n",
    "        The dataframe to calculate the value counts for.\n",
    "        \n",
    "    group_var : string\n",
    "        The variable by which to group the dataframe. For each unique\n",
    "        value of this variable, the final dataframe will have one row\n",
    "        \n",
    "    df_name : string\n",
    "        Variable added to the front of column names to keep track of columns\n",
    "\n",
    "    \n",
    "    Return\n",
    "    --------\n",
    "    categorical : dataframe\n",
    "        A dataframe with counts and normalized counts of each unique category in every categorical variable\n",
    "        with one row for every unique value of the `group_var`.\n",
    "        \n",
    "    \"\"\"\n",
    "    \n",
    "    # Select the categorical columns\n",
    "    categorical = pd.get_dummies(df.select_dtypes('object'))\n",
    "\n",
    "    # Make sure to put the identifying id on the column\n",
    "    categorical[group_var] = df[group_var]\n",
    "\n",
    "    # Groupby the group var and calculate the sum and mean\n",
    "    categorical = categorical.groupby(group_var).agg(['sum', 'mean'])\n",
    "    \n",
    "    column_names = []\n",
    "    \n",
    "    # Iterate through the columns in level 0\n",
    "    for var in categorical.columns.levels[0]:\n",
    "        # Iterate through the stats in level 1\n",
    "        for stat in ['count', 'count_norm']:\n",
    "            # Make a new column name\n",
    "            column_names.append('%s_%s_%s' % (df_name, var, stat))\n",
    "    \n",
    "    categorical.columns = column_names\n",
    "    \n",
    "    return categorical"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb431dd4",
   "metadata": {},
   "source": [
    "# Chargement datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e96fde6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "HomeCredit_ini = pd.read_csv('data/HomeCredit_columns_description.csv', encoding='latin-1')\n",
    "POS_CASH_balance_ini = pd.read_csv('data/POS_CASH_balance.csv')\n",
    "installments_payments_ini = pd.read_csv('data/installments_payments.csv')\n",
    "previous_application_ini = pd.read_csv('data/previous_application.csv')\n",
    "application_test_ini = pd.read_csv('data/application_test.csv')\n",
    "application_train_ini = pd.read_csv('data/application_train.csv')\n",
    "bureau_balance_ini = pd.read_csv('data/bureau_balance.csv')\n",
    "bureau_ini = pd.read_csv('data/bureau.csv')\n",
    "sample_submission_ini = pd.read_csv('data/sample_submission.csv')\n",
    "credit_card_balance_ini = pd.read_csv('data/credit_card_balance.csv')\n",
    "features_manual_and_func_from_first_three_with_app_train_ini = pd.read_csv('data/features_manual_and_func_from_first_three_with_app_train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bc70fb0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "HomeCredit = HomeCredit_ini.copy()\n",
    "POS_CASH_balance = POS_CASH_balance_ini.copy()\n",
    "installments_payments = installments_payments_ini.copy()\n",
    "previous_application = previous_application_ini.copy()\n",
    "application_test = application_test_ini.copy()\n",
    "application_train = application_train_ini.copy()\n",
    "bureau_balance = bureau_balance_ini.copy()\n",
    "bureau = bureau_ini.copy()\n",
    "sample_submission = sample_submission_ini.copy()\n",
    "credit_card_balance = credit_card_balance_ini.copy()\n",
    "features_manual_and_func_from_first_three_with_app_train = features_manual_and_func_from_first_three_with_app_train_ini.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1b2ed69",
   "metadata": {},
   "source": [
    "# Rappel précédent notebook et étapes à suivre"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cce93d4d",
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "source": [
    "Au cours du précédent notebook on a pu réaliser plusieurs runs avec LightBGM en utilisant les données des trois premiers datasets qui sont : application_train, bureau et bureau_balance avec des feature créees manuellement, des features créees avec les fonctions d'aggrégation pour les variables numériques et catégorielles et aussi des features créees avec feature tools. Les résultats n'étant pas concluants on va ajouter les données contenues dans les autres datasets. On ne va pas aller autant en détail notamment du à un manque de connaissances métier.\n",
    "\n",
    "Les étapes à suivre sont les suivantes : - Obtenir les features des autres DataFrames\n",
    "                                         - Tout regrouper en un seul DataFrame\n",
    "                                         - Réaliser un test initial avec LightGBM en introduisant de la crossvalidation et réaliser un peu de fine tuning\n",
    "                                         - Analyser les corrélations et éventuellement retirer les variables trop corréelées entre elles\n",
    "                                         - Relancer LightBGM\n",
    "                                         - Analyser la feature importance et voir si l'on peut se débarasser du bruit\n",
    "                                         - Relancer LightGBM\n",
    "                                         - Aller plus en détail sur la feature importance\n",
    "                                         - Si l'on suppose que le coût d'un FN (client ne pouvant pas rembourser le prêt mais prédit comme pouvant le rembourser) est 10 fois plus supérieur à celui d'un FP on peut introduire des poids dans notre modèle\n",
    "                                         - Relancer LightGBM et analyser/optimiser le seuil de décision\n",
    "                                         - Plus de fine tuning avec GridSearchCV\n",
    "                                         - Tout au long de ces analyses comparer les résultats en utilisant ROC AUC et les différentes métriques liées au matrices de confusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28f2541d",
   "metadata": {},
   "source": [
    "# Overview des DataFrames"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f87f7c85",
   "metadata": {},
   "source": [
    "Même si on pourrait fusionner certains de ces DataFrames avant on va éviter sinon les aggrégations avec la moyenne par exemple pourraient être faussées/introduction de biais"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3bfa7ffc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SK_ID_PREV</th>\n",
       "      <th>SK_ID_CURR</th>\n",
       "      <th>NAME_CONTRACT_TYPE</th>\n",
       "      <th>AMT_ANNUITY</th>\n",
       "      <th>AMT_APPLICATION</th>\n",
       "      <th>AMT_CREDIT</th>\n",
       "      <th>AMT_DOWN_PAYMENT</th>\n",
       "      <th>AMT_GOODS_PRICE</th>\n",
       "      <th>WEEKDAY_APPR_PROCESS_START</th>\n",
       "      <th>HOUR_APPR_PROCESS_START</th>\n",
       "      <th>...</th>\n",
       "      <th>NAME_SELLER_INDUSTRY</th>\n",
       "      <th>CNT_PAYMENT</th>\n",
       "      <th>NAME_YIELD_GROUP</th>\n",
       "      <th>PRODUCT_COMBINATION</th>\n",
       "      <th>DAYS_FIRST_DRAWING</th>\n",
       "      <th>DAYS_FIRST_DUE</th>\n",
       "      <th>DAYS_LAST_DUE_1ST_VERSION</th>\n",
       "      <th>DAYS_LAST_DUE</th>\n",
       "      <th>DAYS_TERMINATION</th>\n",
       "      <th>NFLAG_INSURED_ON_APPROVAL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2030495</td>\n",
       "      <td>271877</td>\n",
       "      <td>Consumer loans</td>\n",
       "      <td>1730.430</td>\n",
       "      <td>17145.0</td>\n",
       "      <td>17145.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>17145.0</td>\n",
       "      <td>SATURDAY</td>\n",
       "      <td>15</td>\n",
       "      <td>...</td>\n",
       "      <td>Connectivity</td>\n",
       "      <td>12.0</td>\n",
       "      <td>middle</td>\n",
       "      <td>POS mobile with interest</td>\n",
       "      <td>365243.0</td>\n",
       "      <td>-42.0</td>\n",
       "      <td>300.0</td>\n",
       "      <td>-42.0</td>\n",
       "      <td>-37.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2802425</td>\n",
       "      <td>108129</td>\n",
       "      <td>Cash loans</td>\n",
       "      <td>25188.615</td>\n",
       "      <td>607500.0</td>\n",
       "      <td>679671.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>607500.0</td>\n",
       "      <td>THURSDAY</td>\n",
       "      <td>11</td>\n",
       "      <td>...</td>\n",
       "      <td>XNA</td>\n",
       "      <td>36.0</td>\n",
       "      <td>low_action</td>\n",
       "      <td>Cash X-Sell: low</td>\n",
       "      <td>365243.0</td>\n",
       "      <td>-134.0</td>\n",
       "      <td>916.0</td>\n",
       "      <td>365243.0</td>\n",
       "      <td>365243.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2523466</td>\n",
       "      <td>122040</td>\n",
       "      <td>Cash loans</td>\n",
       "      <td>15060.735</td>\n",
       "      <td>112500.0</td>\n",
       "      <td>136444.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>112500.0</td>\n",
       "      <td>TUESDAY</td>\n",
       "      <td>11</td>\n",
       "      <td>...</td>\n",
       "      <td>XNA</td>\n",
       "      <td>12.0</td>\n",
       "      <td>high</td>\n",
       "      <td>Cash X-Sell: high</td>\n",
       "      <td>365243.0</td>\n",
       "      <td>-271.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>365243.0</td>\n",
       "      <td>365243.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2819243</td>\n",
       "      <td>176158</td>\n",
       "      <td>Cash loans</td>\n",
       "      <td>47041.335</td>\n",
       "      <td>450000.0</td>\n",
       "      <td>470790.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>450000.0</td>\n",
       "      <td>MONDAY</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>XNA</td>\n",
       "      <td>12.0</td>\n",
       "      <td>middle</td>\n",
       "      <td>Cash X-Sell: middle</td>\n",
       "      <td>365243.0</td>\n",
       "      <td>-482.0</td>\n",
       "      <td>-152.0</td>\n",
       "      <td>-182.0</td>\n",
       "      <td>-177.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1784265</td>\n",
       "      <td>202054</td>\n",
       "      <td>Cash loans</td>\n",
       "      <td>31924.395</td>\n",
       "      <td>337500.0</td>\n",
       "      <td>404055.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>337500.0</td>\n",
       "      <td>THURSDAY</td>\n",
       "      <td>9</td>\n",
       "      <td>...</td>\n",
       "      <td>XNA</td>\n",
       "      <td>24.0</td>\n",
       "      <td>high</td>\n",
       "      <td>Cash Street: high</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1670209</th>\n",
       "      <td>2300464</td>\n",
       "      <td>352015</td>\n",
       "      <td>Consumer loans</td>\n",
       "      <td>14704.290</td>\n",
       "      <td>267295.5</td>\n",
       "      <td>311400.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>267295.5</td>\n",
       "      <td>WEDNESDAY</td>\n",
       "      <td>12</td>\n",
       "      <td>...</td>\n",
       "      <td>Furniture</td>\n",
       "      <td>30.0</td>\n",
       "      <td>low_normal</td>\n",
       "      <td>POS industry with interest</td>\n",
       "      <td>365243.0</td>\n",
       "      <td>-508.0</td>\n",
       "      <td>362.0</td>\n",
       "      <td>-358.0</td>\n",
       "      <td>-351.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1670210</th>\n",
       "      <td>2357031</td>\n",
       "      <td>334635</td>\n",
       "      <td>Consumer loans</td>\n",
       "      <td>6622.020</td>\n",
       "      <td>87750.0</td>\n",
       "      <td>64291.5</td>\n",
       "      <td>29250.0</td>\n",
       "      <td>87750.0</td>\n",
       "      <td>TUESDAY</td>\n",
       "      <td>15</td>\n",
       "      <td>...</td>\n",
       "      <td>Furniture</td>\n",
       "      <td>12.0</td>\n",
       "      <td>middle</td>\n",
       "      <td>POS industry with interest</td>\n",
       "      <td>365243.0</td>\n",
       "      <td>-1604.0</td>\n",
       "      <td>-1274.0</td>\n",
       "      <td>-1304.0</td>\n",
       "      <td>-1297.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1670211</th>\n",
       "      <td>2659632</td>\n",
       "      <td>249544</td>\n",
       "      <td>Consumer loans</td>\n",
       "      <td>11520.855</td>\n",
       "      <td>105237.0</td>\n",
       "      <td>102523.5</td>\n",
       "      <td>10525.5</td>\n",
       "      <td>105237.0</td>\n",
       "      <td>MONDAY</td>\n",
       "      <td>12</td>\n",
       "      <td>...</td>\n",
       "      <td>Consumer electronics</td>\n",
       "      <td>10.0</td>\n",
       "      <td>low_normal</td>\n",
       "      <td>POS household with interest</td>\n",
       "      <td>365243.0</td>\n",
       "      <td>-1457.0</td>\n",
       "      <td>-1187.0</td>\n",
       "      <td>-1187.0</td>\n",
       "      <td>-1181.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1670212</th>\n",
       "      <td>2785582</td>\n",
       "      <td>400317</td>\n",
       "      <td>Cash loans</td>\n",
       "      <td>18821.520</td>\n",
       "      <td>180000.0</td>\n",
       "      <td>191880.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>180000.0</td>\n",
       "      <td>WEDNESDAY</td>\n",
       "      <td>9</td>\n",
       "      <td>...</td>\n",
       "      <td>XNA</td>\n",
       "      <td>12.0</td>\n",
       "      <td>low_normal</td>\n",
       "      <td>Cash X-Sell: low</td>\n",
       "      <td>365243.0</td>\n",
       "      <td>-1155.0</td>\n",
       "      <td>-825.0</td>\n",
       "      <td>-825.0</td>\n",
       "      <td>-817.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1670213</th>\n",
       "      <td>2418762</td>\n",
       "      <td>261212</td>\n",
       "      <td>Cash loans</td>\n",
       "      <td>16431.300</td>\n",
       "      <td>360000.0</td>\n",
       "      <td>360000.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>360000.0</td>\n",
       "      <td>SUNDAY</td>\n",
       "      <td>10</td>\n",
       "      <td>...</td>\n",
       "      <td>XNA</td>\n",
       "      <td>48.0</td>\n",
       "      <td>middle</td>\n",
       "      <td>Cash X-Sell: middle</td>\n",
       "      <td>365243.0</td>\n",
       "      <td>-1163.0</td>\n",
       "      <td>247.0</td>\n",
       "      <td>-443.0</td>\n",
       "      <td>-423.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1670214 rows × 37 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         SK_ID_PREV  SK_ID_CURR NAME_CONTRACT_TYPE  AMT_ANNUITY   \n",
       "0           2030495      271877     Consumer loans     1730.430  \\\n",
       "1           2802425      108129         Cash loans    25188.615   \n",
       "2           2523466      122040         Cash loans    15060.735   \n",
       "3           2819243      176158         Cash loans    47041.335   \n",
       "4           1784265      202054         Cash loans    31924.395   \n",
       "...             ...         ...                ...          ...   \n",
       "1670209     2300464      352015     Consumer loans    14704.290   \n",
       "1670210     2357031      334635     Consumer loans     6622.020   \n",
       "1670211     2659632      249544     Consumer loans    11520.855   \n",
       "1670212     2785582      400317         Cash loans    18821.520   \n",
       "1670213     2418762      261212         Cash loans    16431.300   \n",
       "\n",
       "         AMT_APPLICATION  AMT_CREDIT  AMT_DOWN_PAYMENT  AMT_GOODS_PRICE   \n",
       "0                17145.0     17145.0               0.0          17145.0  \\\n",
       "1               607500.0    679671.0               NaN         607500.0   \n",
       "2               112500.0    136444.5               NaN         112500.0   \n",
       "3               450000.0    470790.0               NaN         450000.0   \n",
       "4               337500.0    404055.0               NaN         337500.0   \n",
       "...                  ...         ...               ...              ...   \n",
       "1670209         267295.5    311400.0               0.0         267295.5   \n",
       "1670210          87750.0     64291.5           29250.0          87750.0   \n",
       "1670211         105237.0    102523.5           10525.5         105237.0   \n",
       "1670212         180000.0    191880.0               NaN         180000.0   \n",
       "1670213         360000.0    360000.0               NaN         360000.0   \n",
       "\n",
       "        WEEKDAY_APPR_PROCESS_START  HOUR_APPR_PROCESS_START  ...   \n",
       "0                         SATURDAY                       15  ...  \\\n",
       "1                         THURSDAY                       11  ...   \n",
       "2                          TUESDAY                       11  ...   \n",
       "3                           MONDAY                        7  ...   \n",
       "4                         THURSDAY                        9  ...   \n",
       "...                            ...                      ...  ...   \n",
       "1670209                  WEDNESDAY                       12  ...   \n",
       "1670210                    TUESDAY                       15  ...   \n",
       "1670211                     MONDAY                       12  ...   \n",
       "1670212                  WEDNESDAY                        9  ...   \n",
       "1670213                     SUNDAY                       10  ...   \n",
       "\n",
       "         NAME_SELLER_INDUSTRY  CNT_PAYMENT  NAME_YIELD_GROUP   \n",
       "0                Connectivity         12.0            middle  \\\n",
       "1                         XNA         36.0        low_action   \n",
       "2                         XNA         12.0              high   \n",
       "3                         XNA         12.0            middle   \n",
       "4                         XNA         24.0              high   \n",
       "...                       ...          ...               ...   \n",
       "1670209             Furniture         30.0        low_normal   \n",
       "1670210             Furniture         12.0            middle   \n",
       "1670211  Consumer electronics         10.0        low_normal   \n",
       "1670212                   XNA         12.0        low_normal   \n",
       "1670213                   XNA         48.0            middle   \n",
       "\n",
       "                 PRODUCT_COMBINATION  DAYS_FIRST_DRAWING DAYS_FIRST_DUE   \n",
       "0           POS mobile with interest            365243.0          -42.0  \\\n",
       "1                   Cash X-Sell: low            365243.0         -134.0   \n",
       "2                  Cash X-Sell: high            365243.0         -271.0   \n",
       "3                Cash X-Sell: middle            365243.0         -482.0   \n",
       "4                  Cash Street: high                 NaN            NaN   \n",
       "...                              ...                 ...            ...   \n",
       "1670209   POS industry with interest            365243.0         -508.0   \n",
       "1670210   POS industry with interest            365243.0        -1604.0   \n",
       "1670211  POS household with interest            365243.0        -1457.0   \n",
       "1670212             Cash X-Sell: low            365243.0        -1155.0   \n",
       "1670213          Cash X-Sell: middle            365243.0        -1163.0   \n",
       "\n",
       "        DAYS_LAST_DUE_1ST_VERSION  DAYS_LAST_DUE DAYS_TERMINATION   \n",
       "0                           300.0          -42.0            -37.0  \\\n",
       "1                           916.0       365243.0         365243.0   \n",
       "2                            59.0       365243.0         365243.0   \n",
       "3                          -152.0         -182.0           -177.0   \n",
       "4                             NaN            NaN              NaN   \n",
       "...                           ...            ...              ...   \n",
       "1670209                     362.0         -358.0           -351.0   \n",
       "1670210                   -1274.0        -1304.0          -1297.0   \n",
       "1670211                   -1187.0        -1187.0          -1181.0   \n",
       "1670212                    -825.0         -825.0           -817.0   \n",
       "1670213                     247.0         -443.0           -423.0   \n",
       "\n",
       "        NFLAG_INSURED_ON_APPROVAL  \n",
       "0                             0.0  \n",
       "1                             1.0  \n",
       "2                             1.0  \n",
       "3                             1.0  \n",
       "4                             NaN  \n",
       "...                           ...  \n",
       "1670209                       0.0  \n",
       "1670210                       0.0  \n",
       "1670211                       0.0  \n",
       "1670212                       1.0  \n",
       "1670213                       0.0  \n",
       "\n",
       "[1670214 rows x 37 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "previous_application"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e395fd17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SK_ID_PREV</th>\n",
       "      <th>SK_ID_CURR</th>\n",
       "      <th>MONTHS_BALANCE</th>\n",
       "      <th>CNT_INSTALMENT</th>\n",
       "      <th>CNT_INSTALMENT_FUTURE</th>\n",
       "      <th>NAME_CONTRACT_STATUS</th>\n",
       "      <th>SK_DPD</th>\n",
       "      <th>SK_DPD_DEF</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1803195</td>\n",
       "      <td>182943</td>\n",
       "      <td>-31</td>\n",
       "      <td>48.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>Active</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1715348</td>\n",
       "      <td>367990</td>\n",
       "      <td>-33</td>\n",
       "      <td>36.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>Active</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1784872</td>\n",
       "      <td>397406</td>\n",
       "      <td>-32</td>\n",
       "      <td>12.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>Active</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1903291</td>\n",
       "      <td>269225</td>\n",
       "      <td>-35</td>\n",
       "      <td>48.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>Active</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2341044</td>\n",
       "      <td>334279</td>\n",
       "      <td>-35</td>\n",
       "      <td>36.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>Active</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10001353</th>\n",
       "      <td>2448283</td>\n",
       "      <td>226558</td>\n",
       "      <td>-20</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Active</td>\n",
       "      <td>843</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10001354</th>\n",
       "      <td>1717234</td>\n",
       "      <td>141565</td>\n",
       "      <td>-19</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Active</td>\n",
       "      <td>602</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10001355</th>\n",
       "      <td>1283126</td>\n",
       "      <td>315695</td>\n",
       "      <td>-21</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Active</td>\n",
       "      <td>609</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10001356</th>\n",
       "      <td>1082516</td>\n",
       "      <td>450255</td>\n",
       "      <td>-22</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Active</td>\n",
       "      <td>614</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10001357</th>\n",
       "      <td>1259607</td>\n",
       "      <td>174278</td>\n",
       "      <td>-52</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Completed</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10001358 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          SK_ID_PREV  SK_ID_CURR  MONTHS_BALANCE  CNT_INSTALMENT   \n",
       "0            1803195      182943             -31            48.0  \\\n",
       "1            1715348      367990             -33            36.0   \n",
       "2            1784872      397406             -32            12.0   \n",
       "3            1903291      269225             -35            48.0   \n",
       "4            2341044      334279             -35            36.0   \n",
       "...              ...         ...             ...             ...   \n",
       "10001353     2448283      226558             -20             6.0   \n",
       "10001354     1717234      141565             -19            12.0   \n",
       "10001355     1283126      315695             -21            10.0   \n",
       "10001356     1082516      450255             -22            12.0   \n",
       "10001357     1259607      174278             -52            16.0   \n",
       "\n",
       "          CNT_INSTALMENT_FUTURE NAME_CONTRACT_STATUS  SK_DPD  SK_DPD_DEF  \n",
       "0                          45.0               Active       0           0  \n",
       "1                          35.0               Active       0           0  \n",
       "2                           9.0               Active       0           0  \n",
       "3                          42.0               Active       0           0  \n",
       "4                          35.0               Active       0           0  \n",
       "...                         ...                  ...     ...         ...  \n",
       "10001353                    0.0               Active     843           0  \n",
       "10001354                    0.0               Active     602           0  \n",
       "10001355                    0.0               Active     609           0  \n",
       "10001356                    0.0               Active     614           0  \n",
       "10001357                    0.0            Completed       0           0  \n",
       "\n",
       "[10001358 rows x 8 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "POS_CASH_balance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "75855659",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SK_ID_PREV</th>\n",
       "      <th>SK_ID_CURR</th>\n",
       "      <th>MONTHS_BALANCE</th>\n",
       "      <th>AMT_BALANCE</th>\n",
       "      <th>AMT_CREDIT_LIMIT_ACTUAL</th>\n",
       "      <th>AMT_DRAWINGS_ATM_CURRENT</th>\n",
       "      <th>AMT_DRAWINGS_CURRENT</th>\n",
       "      <th>AMT_DRAWINGS_OTHER_CURRENT</th>\n",
       "      <th>AMT_DRAWINGS_POS_CURRENT</th>\n",
       "      <th>AMT_INST_MIN_REGULARITY</th>\n",
       "      <th>...</th>\n",
       "      <th>AMT_RECIVABLE</th>\n",
       "      <th>AMT_TOTAL_RECEIVABLE</th>\n",
       "      <th>CNT_DRAWINGS_ATM_CURRENT</th>\n",
       "      <th>CNT_DRAWINGS_CURRENT</th>\n",
       "      <th>CNT_DRAWINGS_OTHER_CURRENT</th>\n",
       "      <th>CNT_DRAWINGS_POS_CURRENT</th>\n",
       "      <th>CNT_INSTALMENT_MATURE_CUM</th>\n",
       "      <th>NAME_CONTRACT_STATUS</th>\n",
       "      <th>SK_DPD</th>\n",
       "      <th>SK_DPD_DEF</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2562384</td>\n",
       "      <td>378907</td>\n",
       "      <td>-6</td>\n",
       "      <td>56.970</td>\n",
       "      <td>135000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>877.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>877.5</td>\n",
       "      <td>1700.325</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>Active</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2582071</td>\n",
       "      <td>363914</td>\n",
       "      <td>-1</td>\n",
       "      <td>63975.555</td>\n",
       "      <td>45000</td>\n",
       "      <td>2250.0</td>\n",
       "      <td>2250.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2250.000</td>\n",
       "      <td>...</td>\n",
       "      <td>64875.555</td>\n",
       "      <td>64875.555</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>69.0</td>\n",
       "      <td>Active</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1740877</td>\n",
       "      <td>371185</td>\n",
       "      <td>-7</td>\n",
       "      <td>31815.225</td>\n",
       "      <td>450000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2250.000</td>\n",
       "      <td>...</td>\n",
       "      <td>31460.085</td>\n",
       "      <td>31460.085</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>Active</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1389973</td>\n",
       "      <td>337855</td>\n",
       "      <td>-4</td>\n",
       "      <td>236572.110</td>\n",
       "      <td>225000</td>\n",
       "      <td>2250.0</td>\n",
       "      <td>2250.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11795.760</td>\n",
       "      <td>...</td>\n",
       "      <td>233048.970</td>\n",
       "      <td>233048.970</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>Active</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1891521</td>\n",
       "      <td>126868</td>\n",
       "      <td>-1</td>\n",
       "      <td>453919.455</td>\n",
       "      <td>450000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11547.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11547.0</td>\n",
       "      <td>22924.890</td>\n",
       "      <td>...</td>\n",
       "      <td>453919.455</td>\n",
       "      <td>453919.455</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>Active</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3840307</th>\n",
       "      <td>1036507</td>\n",
       "      <td>328243</td>\n",
       "      <td>-9</td>\n",
       "      <td>0.000</td>\n",
       "      <td>45000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Active</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3840308</th>\n",
       "      <td>1714892</td>\n",
       "      <td>347207</td>\n",
       "      <td>-9</td>\n",
       "      <td>0.000</td>\n",
       "      <td>45000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>Active</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3840309</th>\n",
       "      <td>1302323</td>\n",
       "      <td>215757</td>\n",
       "      <td>-9</td>\n",
       "      <td>275784.975</td>\n",
       "      <td>585000</td>\n",
       "      <td>270000.0</td>\n",
       "      <td>270000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2250.000</td>\n",
       "      <td>...</td>\n",
       "      <td>273093.975</td>\n",
       "      <td>273093.975</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>Active</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3840310</th>\n",
       "      <td>1624872</td>\n",
       "      <td>430337</td>\n",
       "      <td>-10</td>\n",
       "      <td>0.000</td>\n",
       "      <td>450000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Active</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3840311</th>\n",
       "      <td>2411345</td>\n",
       "      <td>236760</td>\n",
       "      <td>-10</td>\n",
       "      <td>0.000</td>\n",
       "      <td>157500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>Completed</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3840312 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         SK_ID_PREV  SK_ID_CURR  MONTHS_BALANCE  AMT_BALANCE   \n",
       "0           2562384      378907              -6       56.970  \\\n",
       "1           2582071      363914              -1    63975.555   \n",
       "2           1740877      371185              -7    31815.225   \n",
       "3           1389973      337855              -4   236572.110   \n",
       "4           1891521      126868              -1   453919.455   \n",
       "...             ...         ...             ...          ...   \n",
       "3840307     1036507      328243              -9        0.000   \n",
       "3840308     1714892      347207              -9        0.000   \n",
       "3840309     1302323      215757              -9   275784.975   \n",
       "3840310     1624872      430337             -10        0.000   \n",
       "3840311     2411345      236760             -10        0.000   \n",
       "\n",
       "         AMT_CREDIT_LIMIT_ACTUAL  AMT_DRAWINGS_ATM_CURRENT   \n",
       "0                         135000                       0.0  \\\n",
       "1                          45000                    2250.0   \n",
       "2                         450000                       0.0   \n",
       "3                         225000                    2250.0   \n",
       "4                         450000                       0.0   \n",
       "...                          ...                       ...   \n",
       "3840307                    45000                       NaN   \n",
       "3840308                    45000                       0.0   \n",
       "3840309                   585000                  270000.0   \n",
       "3840310                   450000                       NaN   \n",
       "3840311                   157500                       0.0   \n",
       "\n",
       "         AMT_DRAWINGS_CURRENT  AMT_DRAWINGS_OTHER_CURRENT   \n",
       "0                       877.5                         0.0  \\\n",
       "1                      2250.0                         0.0   \n",
       "2                         0.0                         0.0   \n",
       "3                      2250.0                         0.0   \n",
       "4                     11547.0                         0.0   \n",
       "...                       ...                         ...   \n",
       "3840307                   0.0                         NaN   \n",
       "3840308                   0.0                         0.0   \n",
       "3840309              270000.0                         0.0   \n",
       "3840310                   0.0                         NaN   \n",
       "3840311                   0.0                         0.0   \n",
       "\n",
       "         AMT_DRAWINGS_POS_CURRENT  AMT_INST_MIN_REGULARITY  ...   \n",
       "0                           877.5                 1700.325  ...  \\\n",
       "1                             0.0                 2250.000  ...   \n",
       "2                             0.0                 2250.000  ...   \n",
       "3                             0.0                11795.760  ...   \n",
       "4                         11547.0                22924.890  ...   \n",
       "...                           ...                      ...  ...   \n",
       "3840307                       NaN                    0.000  ...   \n",
       "3840308                       0.0                    0.000  ...   \n",
       "3840309                       0.0                 2250.000  ...   \n",
       "3840310                       NaN                    0.000  ...   \n",
       "3840311                       0.0                    0.000  ...   \n",
       "\n",
       "         AMT_RECIVABLE  AMT_TOTAL_RECEIVABLE  CNT_DRAWINGS_ATM_CURRENT   \n",
       "0                0.000                 0.000                       0.0  \\\n",
       "1            64875.555             64875.555                       1.0   \n",
       "2            31460.085             31460.085                       0.0   \n",
       "3           233048.970            233048.970                       1.0   \n",
       "4           453919.455            453919.455                       0.0   \n",
       "...                ...                   ...                       ...   \n",
       "3840307          0.000                 0.000                       NaN   \n",
       "3840308          0.000                 0.000                       0.0   \n",
       "3840309     273093.975            273093.975                       2.0   \n",
       "3840310          0.000                 0.000                       NaN   \n",
       "3840311          0.000                 0.000                       0.0   \n",
       "\n",
       "         CNT_DRAWINGS_CURRENT  CNT_DRAWINGS_OTHER_CURRENT   \n",
       "0                           1                         0.0  \\\n",
       "1                           1                         0.0   \n",
       "2                           0                         0.0   \n",
       "3                           1                         0.0   \n",
       "4                           1                         0.0   \n",
       "...                       ...                         ...   \n",
       "3840307                     0                         NaN   \n",
       "3840308                     0                         0.0   \n",
       "3840309                     2                         0.0   \n",
       "3840310                     0                         NaN   \n",
       "3840311                     0                         0.0   \n",
       "\n",
       "         CNT_DRAWINGS_POS_CURRENT  CNT_INSTALMENT_MATURE_CUM   \n",
       "0                             1.0                       35.0  \\\n",
       "1                             0.0                       69.0   \n",
       "2                             0.0                       30.0   \n",
       "3                             0.0                       10.0   \n",
       "4                             1.0                      101.0   \n",
       "...                           ...                        ...   \n",
       "3840307                       NaN                        0.0   \n",
       "3840308                       0.0                       23.0   \n",
       "3840309                       0.0                       18.0   \n",
       "3840310                       NaN                        0.0   \n",
       "3840311                       0.0                       21.0   \n",
       "\n",
       "         NAME_CONTRACT_STATUS  SK_DPD  SK_DPD_DEF  \n",
       "0                      Active       0           0  \n",
       "1                      Active       0           0  \n",
       "2                      Active       0           0  \n",
       "3                      Active       0           0  \n",
       "4                      Active       0           0  \n",
       "...                       ...     ...         ...  \n",
       "3840307                Active       0           0  \n",
       "3840308                Active       0           0  \n",
       "3840309                Active       0           0  \n",
       "3840310                Active       0           0  \n",
       "3840311             Completed       0           0  \n",
       "\n",
       "[3840312 rows x 23 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "credit_card_balance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2e571f24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SK_ID_PREV</th>\n",
       "      <th>SK_ID_CURR</th>\n",
       "      <th>NUM_INSTALMENT_VERSION</th>\n",
       "      <th>NUM_INSTALMENT_NUMBER</th>\n",
       "      <th>DAYS_INSTALMENT</th>\n",
       "      <th>DAYS_ENTRY_PAYMENT</th>\n",
       "      <th>AMT_INSTALMENT</th>\n",
       "      <th>AMT_PAYMENT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1054186</td>\n",
       "      <td>161674</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6</td>\n",
       "      <td>-1180.0</td>\n",
       "      <td>-1187.0</td>\n",
       "      <td>6948.360</td>\n",
       "      <td>6948.360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1330831</td>\n",
       "      <td>151639</td>\n",
       "      <td>0.0</td>\n",
       "      <td>34</td>\n",
       "      <td>-2156.0</td>\n",
       "      <td>-2156.0</td>\n",
       "      <td>1716.525</td>\n",
       "      <td>1716.525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2085231</td>\n",
       "      <td>193053</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>-63.0</td>\n",
       "      <td>-63.0</td>\n",
       "      <td>25425.000</td>\n",
       "      <td>25425.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2452527</td>\n",
       "      <td>199697</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "      <td>-2418.0</td>\n",
       "      <td>-2426.0</td>\n",
       "      <td>24350.130</td>\n",
       "      <td>24350.130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2714724</td>\n",
       "      <td>167756</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>-1383.0</td>\n",
       "      <td>-1366.0</td>\n",
       "      <td>2165.040</td>\n",
       "      <td>2160.585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13605396</th>\n",
       "      <td>2186857</td>\n",
       "      <td>428057</td>\n",
       "      <td>0.0</td>\n",
       "      <td>66</td>\n",
       "      <td>-1624.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>67.500</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13605397</th>\n",
       "      <td>1310347</td>\n",
       "      <td>414406</td>\n",
       "      <td>0.0</td>\n",
       "      <td>47</td>\n",
       "      <td>-1539.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>67.500</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13605398</th>\n",
       "      <td>1308766</td>\n",
       "      <td>402199</td>\n",
       "      <td>0.0</td>\n",
       "      <td>43</td>\n",
       "      <td>-7.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>43737.435</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13605399</th>\n",
       "      <td>1062206</td>\n",
       "      <td>409297</td>\n",
       "      <td>0.0</td>\n",
       "      <td>43</td>\n",
       "      <td>-1986.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>67.500</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13605400</th>\n",
       "      <td>2448869</td>\n",
       "      <td>434321</td>\n",
       "      <td>1.0</td>\n",
       "      <td>19</td>\n",
       "      <td>-27.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11504.250</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>13605401 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          SK_ID_PREV  SK_ID_CURR  NUM_INSTALMENT_VERSION   \n",
       "0            1054186      161674                     1.0  \\\n",
       "1            1330831      151639                     0.0   \n",
       "2            2085231      193053                     2.0   \n",
       "3            2452527      199697                     1.0   \n",
       "4            2714724      167756                     1.0   \n",
       "...              ...         ...                     ...   \n",
       "13605396     2186857      428057                     0.0   \n",
       "13605397     1310347      414406                     0.0   \n",
       "13605398     1308766      402199                     0.0   \n",
       "13605399     1062206      409297                     0.0   \n",
       "13605400     2448869      434321                     1.0   \n",
       "\n",
       "          NUM_INSTALMENT_NUMBER  DAYS_INSTALMENT  DAYS_ENTRY_PAYMENT   \n",
       "0                             6          -1180.0             -1187.0  \\\n",
       "1                            34          -2156.0             -2156.0   \n",
       "2                             1            -63.0               -63.0   \n",
       "3                             3          -2418.0             -2426.0   \n",
       "4                             2          -1383.0             -1366.0   \n",
       "...                         ...              ...                 ...   \n",
       "13605396                     66          -1624.0                 NaN   \n",
       "13605397                     47          -1539.0                 NaN   \n",
       "13605398                     43             -7.0                 NaN   \n",
       "13605399                     43          -1986.0                 NaN   \n",
       "13605400                     19            -27.0                 NaN   \n",
       "\n",
       "          AMT_INSTALMENT  AMT_PAYMENT  \n",
       "0               6948.360     6948.360  \n",
       "1               1716.525     1716.525  \n",
       "2              25425.000    25425.000  \n",
       "3              24350.130    24350.130  \n",
       "4               2165.040     2160.585  \n",
       "...                  ...          ...  \n",
       "13605396          67.500          NaN  \n",
       "13605397          67.500          NaN  \n",
       "13605398       43737.435          NaN  \n",
       "13605399          67.500          NaN  \n",
       "13605400       11504.250          NaN  \n",
       "\n",
       "[13605401 rows x 8 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "installments_payments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fa84738",
   "metadata": {},
   "source": [
    "# Aggrégation des DataFrames"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dbe6f36",
   "metadata": {},
   "source": [
    "## Aggrégation de previous_application"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b00150a",
   "metadata": {},
   "source": [
    "### Overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "541b7021",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1670214"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "previous_application['SK_ID_PREV'].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11b42e2b",
   "metadata": {},
   "source": [
    "### Aggrégation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e3b7e2c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SK_ID_CURR</th>\n",
       "      <th>previous_application_AMT_ANNUITY_count</th>\n",
       "      <th>previous_application_AMT_ANNUITY_mean</th>\n",
       "      <th>previous_application_AMT_ANNUITY_max</th>\n",
       "      <th>previous_application_AMT_ANNUITY_min</th>\n",
       "      <th>previous_application_AMT_ANNUITY_sum</th>\n",
       "      <th>previous_application_AMT_APPLICATION_count</th>\n",
       "      <th>previous_application_AMT_APPLICATION_mean</th>\n",
       "      <th>previous_application_AMT_APPLICATION_max</th>\n",
       "      <th>previous_application_AMT_APPLICATION_min</th>\n",
       "      <th>...</th>\n",
       "      <th>previous_application_DAYS_TERMINATION_count</th>\n",
       "      <th>previous_application_DAYS_TERMINATION_mean</th>\n",
       "      <th>previous_application_DAYS_TERMINATION_max</th>\n",
       "      <th>previous_application_DAYS_TERMINATION_min</th>\n",
       "      <th>previous_application_DAYS_TERMINATION_sum</th>\n",
       "      <th>previous_application_NFLAG_INSURED_ON_APPROVAL_count</th>\n",
       "      <th>previous_application_NFLAG_INSURED_ON_APPROVAL_mean</th>\n",
       "      <th>previous_application_NFLAG_INSURED_ON_APPROVAL_max</th>\n",
       "      <th>previous_application_NFLAG_INSURED_ON_APPROVAL_min</th>\n",
       "      <th>previous_application_NFLAG_INSURED_ON_APPROVAL_sum</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100001</td>\n",
       "      <td>1</td>\n",
       "      <td>3951.000000</td>\n",
       "      <td>3951.000</td>\n",
       "      <td>3951.000</td>\n",
       "      <td>3951.000</td>\n",
       "      <td>1</td>\n",
       "      <td>24835.500</td>\n",
       "      <td>24835.5</td>\n",
       "      <td>24835.5</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>-1612.000000</td>\n",
       "      <td>-1612.0</td>\n",
       "      <td>-1612.0</td>\n",
       "      <td>-1612.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100002</td>\n",
       "      <td>1</td>\n",
       "      <td>9251.775000</td>\n",
       "      <td>9251.775</td>\n",
       "      <td>9251.775</td>\n",
       "      <td>9251.775</td>\n",
       "      <td>1</td>\n",
       "      <td>179055.000</td>\n",
       "      <td>179055.0</td>\n",
       "      <td>179055.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>-17.000000</td>\n",
       "      <td>-17.0</td>\n",
       "      <td>-17.0</td>\n",
       "      <td>-17.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100003</td>\n",
       "      <td>3</td>\n",
       "      <td>56553.990000</td>\n",
       "      <td>98356.995</td>\n",
       "      <td>6737.310</td>\n",
       "      <td>169661.970</td>\n",
       "      <td>3</td>\n",
       "      <td>435436.500</td>\n",
       "      <td>900000.0</td>\n",
       "      <td>68809.5</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>-1047.333333</td>\n",
       "      <td>-527.0</td>\n",
       "      <td>-1976.0</td>\n",
       "      <td>-3142.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100004</td>\n",
       "      <td>1</td>\n",
       "      <td>5357.250000</td>\n",
       "      <td>5357.250</td>\n",
       "      <td>5357.250</td>\n",
       "      <td>5357.250</td>\n",
       "      <td>1</td>\n",
       "      <td>24282.000</td>\n",
       "      <td>24282.0</td>\n",
       "      <td>24282.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>-714.000000</td>\n",
       "      <td>-714.0</td>\n",
       "      <td>-714.0</td>\n",
       "      <td>-714.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>100005</td>\n",
       "      <td>1</td>\n",
       "      <td>4813.200000</td>\n",
       "      <td>4813.200</td>\n",
       "      <td>4813.200</td>\n",
       "      <td>4813.200</td>\n",
       "      <td>2</td>\n",
       "      <td>22308.750</td>\n",
       "      <td>44617.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>-460.000000</td>\n",
       "      <td>-460.0</td>\n",
       "      <td>-460.0</td>\n",
       "      <td>-460.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>338852</th>\n",
       "      <td>456251</td>\n",
       "      <td>1</td>\n",
       "      <td>6605.910000</td>\n",
       "      <td>6605.910</td>\n",
       "      <td>6605.910</td>\n",
       "      <td>6605.910</td>\n",
       "      <td>1</td>\n",
       "      <td>40455.000</td>\n",
       "      <td>40455.0</td>\n",
       "      <td>40455.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>-25.000000</td>\n",
       "      <td>-25.0</td>\n",
       "      <td>-25.0</td>\n",
       "      <td>-25.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>338853</th>\n",
       "      <td>456252</td>\n",
       "      <td>1</td>\n",
       "      <td>10074.465000</td>\n",
       "      <td>10074.465</td>\n",
       "      <td>10074.465</td>\n",
       "      <td>10074.465</td>\n",
       "      <td>1</td>\n",
       "      <td>57595.500</td>\n",
       "      <td>57595.5</td>\n",
       "      <td>57595.5</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>-2311.000000</td>\n",
       "      <td>-2311.0</td>\n",
       "      <td>-2311.0</td>\n",
       "      <td>-2311.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>338854</th>\n",
       "      <td>456253</td>\n",
       "      <td>2</td>\n",
       "      <td>4770.405000</td>\n",
       "      <td>5567.715</td>\n",
       "      <td>3973.095</td>\n",
       "      <td>9540.810</td>\n",
       "      <td>2</td>\n",
       "      <td>24162.750</td>\n",
       "      <td>28912.5</td>\n",
       "      <td>19413.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>-2212.500000</td>\n",
       "      <td>-1712.0</td>\n",
       "      <td>-2713.0</td>\n",
       "      <td>-4425.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>338855</th>\n",
       "      <td>456254</td>\n",
       "      <td>2</td>\n",
       "      <td>10681.132500</td>\n",
       "      <td>19065.825</td>\n",
       "      <td>2296.440</td>\n",
       "      <td>21362.265</td>\n",
       "      <td>2</td>\n",
       "      <td>121317.750</td>\n",
       "      <td>223789.5</td>\n",
       "      <td>18846.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>365243.000000</td>\n",
       "      <td>365243.0</td>\n",
       "      <td>365243.0</td>\n",
       "      <td>730486.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>338856</th>\n",
       "      <td>456255</td>\n",
       "      <td>8</td>\n",
       "      <td>20775.391875</td>\n",
       "      <td>54022.140</td>\n",
       "      <td>2250.000</td>\n",
       "      <td>166203.135</td>\n",
       "      <td>8</td>\n",
       "      <td>362770.875</td>\n",
       "      <td>1170000.0</td>\n",
       "      <td>45000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>-349.000000</td>\n",
       "      <td>-64.0</td>\n",
       "      <td>-687.0</td>\n",
       "      <td>-2094.0</td>\n",
       "      <td>6</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>338857 rows × 96 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        SK_ID_CURR  previous_application_AMT_ANNUITY_count   \n",
       "0           100001                                       1  \\\n",
       "1           100002                                       1   \n",
       "2           100003                                       3   \n",
       "3           100004                                       1   \n",
       "4           100005                                       1   \n",
       "...            ...                                     ...   \n",
       "338852      456251                                       1   \n",
       "338853      456252                                       1   \n",
       "338854      456253                                       2   \n",
       "338855      456254                                       2   \n",
       "338856      456255                                       8   \n",
       "\n",
       "        previous_application_AMT_ANNUITY_mean   \n",
       "0                                 3951.000000  \\\n",
       "1                                 9251.775000   \n",
       "2                                56553.990000   \n",
       "3                                 5357.250000   \n",
       "4                                 4813.200000   \n",
       "...                                       ...   \n",
       "338852                            6605.910000   \n",
       "338853                           10074.465000   \n",
       "338854                            4770.405000   \n",
       "338855                           10681.132500   \n",
       "338856                           20775.391875   \n",
       "\n",
       "        previous_application_AMT_ANNUITY_max   \n",
       "0                                   3951.000  \\\n",
       "1                                   9251.775   \n",
       "2                                  98356.995   \n",
       "3                                   5357.250   \n",
       "4                                   4813.200   \n",
       "...                                      ...   \n",
       "338852                              6605.910   \n",
       "338853                             10074.465   \n",
       "338854                              5567.715   \n",
       "338855                             19065.825   \n",
       "338856                             54022.140   \n",
       "\n",
       "        previous_application_AMT_ANNUITY_min   \n",
       "0                                   3951.000  \\\n",
       "1                                   9251.775   \n",
       "2                                   6737.310   \n",
       "3                                   5357.250   \n",
       "4                                   4813.200   \n",
       "...                                      ...   \n",
       "338852                              6605.910   \n",
       "338853                             10074.465   \n",
       "338854                              3973.095   \n",
       "338855                              2296.440   \n",
       "338856                              2250.000   \n",
       "\n",
       "        previous_application_AMT_ANNUITY_sum   \n",
       "0                                   3951.000  \\\n",
       "1                                   9251.775   \n",
       "2                                 169661.970   \n",
       "3                                   5357.250   \n",
       "4                                   4813.200   \n",
       "...                                      ...   \n",
       "338852                              6605.910   \n",
       "338853                             10074.465   \n",
       "338854                              9540.810   \n",
       "338855                             21362.265   \n",
       "338856                            166203.135   \n",
       "\n",
       "        previous_application_AMT_APPLICATION_count   \n",
       "0                                                1  \\\n",
       "1                                                1   \n",
       "2                                                3   \n",
       "3                                                1   \n",
       "4                                                2   \n",
       "...                                            ...   \n",
       "338852                                           1   \n",
       "338853                                           1   \n",
       "338854                                           2   \n",
       "338855                                           2   \n",
       "338856                                           8   \n",
       "\n",
       "        previous_application_AMT_APPLICATION_mean   \n",
       "0                                       24835.500  \\\n",
       "1                                      179055.000   \n",
       "2                                      435436.500   \n",
       "3                                       24282.000   \n",
       "4                                       22308.750   \n",
       "...                                           ...   \n",
       "338852                                  40455.000   \n",
       "338853                                  57595.500   \n",
       "338854                                  24162.750   \n",
       "338855                                 121317.750   \n",
       "338856                                 362770.875   \n",
       "\n",
       "        previous_application_AMT_APPLICATION_max   \n",
       "0                                        24835.5  \\\n",
       "1                                       179055.0   \n",
       "2                                       900000.0   \n",
       "3                                        24282.0   \n",
       "4                                        44617.5   \n",
       "...                                          ...   \n",
       "338852                                   40455.0   \n",
       "338853                                   57595.5   \n",
       "338854                                   28912.5   \n",
       "338855                                  223789.5   \n",
       "338856                                 1170000.0   \n",
       "\n",
       "        previous_application_AMT_APPLICATION_min  ...   \n",
       "0                                        24835.5  ...  \\\n",
       "1                                       179055.0  ...   \n",
       "2                                        68809.5  ...   \n",
       "3                                        24282.0  ...   \n",
       "4                                            0.0  ...   \n",
       "...                                          ...  ...   \n",
       "338852                                   40455.0  ...   \n",
       "338853                                   57595.5  ...   \n",
       "338854                                   19413.0  ...   \n",
       "338855                                   18846.0  ...   \n",
       "338856                                   45000.0  ...   \n",
       "\n",
       "        previous_application_DAYS_TERMINATION_count   \n",
       "0                                                 1  \\\n",
       "1                                                 1   \n",
       "2                                                 3   \n",
       "3                                                 1   \n",
       "4                                                 1   \n",
       "...                                             ...   \n",
       "338852                                            1   \n",
       "338853                                            1   \n",
       "338854                                            2   \n",
       "338855                                            2   \n",
       "338856                                            6   \n",
       "\n",
       "        previous_application_DAYS_TERMINATION_mean   \n",
       "0                                     -1612.000000  \\\n",
       "1                                       -17.000000   \n",
       "2                                     -1047.333333   \n",
       "3                                      -714.000000   \n",
       "4                                      -460.000000   \n",
       "...                                            ...   \n",
       "338852                                  -25.000000   \n",
       "338853                                -2311.000000   \n",
       "338854                                -2212.500000   \n",
       "338855                               365243.000000   \n",
       "338856                                 -349.000000   \n",
       "\n",
       "        previous_application_DAYS_TERMINATION_max   \n",
       "0                                         -1612.0  \\\n",
       "1                                           -17.0   \n",
       "2                                          -527.0   \n",
       "3                                          -714.0   \n",
       "4                                          -460.0   \n",
       "...                                           ...   \n",
       "338852                                      -25.0   \n",
       "338853                                    -2311.0   \n",
       "338854                                    -1712.0   \n",
       "338855                                   365243.0   \n",
       "338856                                      -64.0   \n",
       "\n",
       "        previous_application_DAYS_TERMINATION_min   \n",
       "0                                         -1612.0  \\\n",
       "1                                           -17.0   \n",
       "2                                         -1976.0   \n",
       "3                                          -714.0   \n",
       "4                                          -460.0   \n",
       "...                                           ...   \n",
       "338852                                      -25.0   \n",
       "338853                                    -2311.0   \n",
       "338854                                    -2713.0   \n",
       "338855                                   365243.0   \n",
       "338856                                     -687.0   \n",
       "\n",
       "        previous_application_DAYS_TERMINATION_sum   \n",
       "0                                         -1612.0  \\\n",
       "1                                           -17.0   \n",
       "2                                         -3142.0   \n",
       "3                                          -714.0   \n",
       "4                                          -460.0   \n",
       "...                                           ...   \n",
       "338852                                      -25.0   \n",
       "338853                                    -2311.0   \n",
       "338854                                    -4425.0   \n",
       "338855                                   730486.0   \n",
       "338856                                    -2094.0   \n",
       "\n",
       "        previous_application_NFLAG_INSURED_ON_APPROVAL_count   \n",
       "0                                                          1  \\\n",
       "1                                                          1   \n",
       "2                                                          3   \n",
       "3                                                          1   \n",
       "4                                                          1   \n",
       "...                                                      ...   \n",
       "338852                                                     1   \n",
       "338853                                                     1   \n",
       "338854                                                     2   \n",
       "338855                                                     2   \n",
       "338856                                                     6   \n",
       "\n",
       "        previous_application_NFLAG_INSURED_ON_APPROVAL_mean   \n",
       "0                                                  0.000000  \\\n",
       "1                                                  0.000000   \n",
       "2                                                  0.666667   \n",
       "3                                                  0.000000   \n",
       "4                                                  0.000000   \n",
       "...                                                     ...   \n",
       "338852                                             0.000000   \n",
       "338853                                             1.000000   \n",
       "338854                                             0.500000   \n",
       "338855                                             0.500000   \n",
       "338856                                             0.333333   \n",
       "\n",
       "        previous_application_NFLAG_INSURED_ON_APPROVAL_max   \n",
       "0                                                      0.0  \\\n",
       "1                                                      0.0   \n",
       "2                                                      1.0   \n",
       "3                                                      0.0   \n",
       "4                                                      0.0   \n",
       "...                                                    ...   \n",
       "338852                                                 0.0   \n",
       "338853                                                 1.0   \n",
       "338854                                                 1.0   \n",
       "338855                                                 1.0   \n",
       "338856                                                 1.0   \n",
       "\n",
       "        previous_application_NFLAG_INSURED_ON_APPROVAL_min   \n",
       "0                                                      0.0  \\\n",
       "1                                                      0.0   \n",
       "2                                                      0.0   \n",
       "3                                                      0.0   \n",
       "4                                                      0.0   \n",
       "...                                                    ...   \n",
       "338852                                                 0.0   \n",
       "338853                                                 1.0   \n",
       "338854                                                 0.0   \n",
       "338855                                                 0.0   \n",
       "338856                                                 0.0   \n",
       "\n",
       "        previous_application_NFLAG_INSURED_ON_APPROVAL_sum  \n",
       "0                                                      0.0  \n",
       "1                                                      0.0  \n",
       "2                                                      2.0  \n",
       "3                                                      0.0  \n",
       "4                                                      0.0  \n",
       "...                                                    ...  \n",
       "338852                                                 0.0  \n",
       "338853                                                 1.0  \n",
       "338854                                                 1.0  \n",
       "338855                                                 1.0  \n",
       "338856                                                 2.0  \n",
       "\n",
       "[338857 rows x 96 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "previous_application_num_agg_SK_ID_CURR = agg_numeric(previous_application.drop(columns=['SK_ID_PREV']), group_var='SK_ID_CURR', df_name='previous_application')\n",
    "previous_application_num_agg_SK_ID_CURR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a034ae6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>previous_application_NAME_CONTRACT_TYPE_Cash loans_count</th>\n",
       "      <th>previous_application_NAME_CONTRACT_TYPE_Cash loans_count_norm</th>\n",
       "      <th>previous_application_NAME_CONTRACT_TYPE_Consumer loans_count</th>\n",
       "      <th>previous_application_NAME_CONTRACT_TYPE_Consumer loans_count_norm</th>\n",
       "      <th>previous_application_NAME_CONTRACT_TYPE_Revolving loans_count</th>\n",
       "      <th>previous_application_NAME_CONTRACT_TYPE_Revolving loans_count_norm</th>\n",
       "      <th>previous_application_NAME_CONTRACT_TYPE_XNA_count</th>\n",
       "      <th>previous_application_NAME_CONTRACT_TYPE_XNA_count_norm</th>\n",
       "      <th>previous_application_WEEKDAY_APPR_PROCESS_START_FRIDAY_count</th>\n",
       "      <th>previous_application_WEEKDAY_APPR_PROCESS_START_FRIDAY_count_norm</th>\n",
       "      <th>...</th>\n",
       "      <th>previous_application_PRODUCT_COMBINATION_POS industry without interest_count</th>\n",
       "      <th>previous_application_PRODUCT_COMBINATION_POS industry without interest_count_norm</th>\n",
       "      <th>previous_application_PRODUCT_COMBINATION_POS mobile with interest_count</th>\n",
       "      <th>previous_application_PRODUCT_COMBINATION_POS mobile with interest_count_norm</th>\n",
       "      <th>previous_application_PRODUCT_COMBINATION_POS mobile without interest_count</th>\n",
       "      <th>previous_application_PRODUCT_COMBINATION_POS mobile without interest_count_norm</th>\n",
       "      <th>previous_application_PRODUCT_COMBINATION_POS other with interest_count</th>\n",
       "      <th>previous_application_PRODUCT_COMBINATION_POS other with interest_count_norm</th>\n",
       "      <th>previous_application_PRODUCT_COMBINATION_POS others without interest_count</th>\n",
       "      <th>previous_application_PRODUCT_COMBINATION_POS others without interest_count_norm</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SK_ID_CURR</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>100001</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100002</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100003</th>\n",
       "      <td>1</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>2</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100004</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100005</th>\n",
       "      <td>1</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>456251</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>456252</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>456253</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>456254</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>456255</th>\n",
       "      <td>4</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>3</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>338857 rows × 286 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            previous_application_NAME_CONTRACT_TYPE_Cash loans_count   \n",
       "SK_ID_CURR                                                             \n",
       "100001                                                             0  \\\n",
       "100002                                                             0   \n",
       "100003                                                             1   \n",
       "100004                                                             0   \n",
       "100005                                                             1   \n",
       "...                                                              ...   \n",
       "456251                                                             0   \n",
       "456252                                                             0   \n",
       "456253                                                             0   \n",
       "456254                                                             0   \n",
       "456255                                                             4   \n",
       "\n",
       "            previous_application_NAME_CONTRACT_TYPE_Cash loans_count_norm   \n",
       "SK_ID_CURR                                                                  \n",
       "100001                                                           0.000000  \\\n",
       "100002                                                           0.000000   \n",
       "100003                                                           0.333333   \n",
       "100004                                                           0.000000   \n",
       "100005                                                           0.500000   \n",
       "...                                                                   ...   \n",
       "456251                                                           0.000000   \n",
       "456252                                                           0.000000   \n",
       "456253                                                           0.000000   \n",
       "456254                                                           0.000000   \n",
       "456255                                                           0.500000   \n",
       "\n",
       "            previous_application_NAME_CONTRACT_TYPE_Consumer loans_count   \n",
       "SK_ID_CURR                                                                 \n",
       "100001                                                                 1  \\\n",
       "100002                                                                 1   \n",
       "100003                                                                 2   \n",
       "100004                                                                 1   \n",
       "100005                                                                 1   \n",
       "...                                                                  ...   \n",
       "456251                                                                 1   \n",
       "456252                                                                 1   \n",
       "456253                                                                 2   \n",
       "456254                                                                 2   \n",
       "456255                                                                 3   \n",
       "\n",
       "            previous_application_NAME_CONTRACT_TYPE_Consumer loans_count_norm   \n",
       "SK_ID_CURR                                                                      \n",
       "100001                                                               1.000000  \\\n",
       "100002                                                               1.000000   \n",
       "100003                                                               0.666667   \n",
       "100004                                                               1.000000   \n",
       "100005                                                               0.500000   \n",
       "...                                                                       ...   \n",
       "456251                                                               1.000000   \n",
       "456252                                                               1.000000   \n",
       "456253                                                               1.000000   \n",
       "456254                                                               1.000000   \n",
       "456255                                                               0.375000   \n",
       "\n",
       "            previous_application_NAME_CONTRACT_TYPE_Revolving loans_count   \n",
       "SK_ID_CURR                                                                  \n",
       "100001                                                                  0  \\\n",
       "100002                                                                  0   \n",
       "100003                                                                  0   \n",
       "100004                                                                  0   \n",
       "100005                                                                  0   \n",
       "...                                                                   ...   \n",
       "456251                                                                  0   \n",
       "456252                                                                  0   \n",
       "456253                                                                  0   \n",
       "456254                                                                  0   \n",
       "456255                                                                  1   \n",
       "\n",
       "            previous_application_NAME_CONTRACT_TYPE_Revolving loans_count_norm   \n",
       "SK_ID_CURR                                                                       \n",
       "100001                                                                   0.000  \\\n",
       "100002                                                                   0.000   \n",
       "100003                                                                   0.000   \n",
       "100004                                                                   0.000   \n",
       "100005                                                                   0.000   \n",
       "...                                                                        ...   \n",
       "456251                                                                   0.000   \n",
       "456252                                                                   0.000   \n",
       "456253                                                                   0.000   \n",
       "456254                                                                   0.000   \n",
       "456255                                                                   0.125   \n",
       "\n",
       "            previous_application_NAME_CONTRACT_TYPE_XNA_count   \n",
       "SK_ID_CURR                                                      \n",
       "100001                                                      0  \\\n",
       "100002                                                      0   \n",
       "100003                                                      0   \n",
       "100004                                                      0   \n",
       "100005                                                      0   \n",
       "...                                                       ...   \n",
       "456251                                                      0   \n",
       "456252                                                      0   \n",
       "456253                                                      0   \n",
       "456254                                                      0   \n",
       "456255                                                      0   \n",
       "\n",
       "            previous_application_NAME_CONTRACT_TYPE_XNA_count_norm   \n",
       "SK_ID_CURR                                                           \n",
       "100001                                                         0.0  \\\n",
       "100002                                                         0.0   \n",
       "100003                                                         0.0   \n",
       "100004                                                         0.0   \n",
       "100005                                                         0.0   \n",
       "...                                                            ...   \n",
       "456251                                                         0.0   \n",
       "456252                                                         0.0   \n",
       "456253                                                         0.0   \n",
       "456254                                                         0.0   \n",
       "456255                                                         0.0   \n",
       "\n",
       "            previous_application_WEEKDAY_APPR_PROCESS_START_FRIDAY_count   \n",
       "SK_ID_CURR                                                                 \n",
       "100001                                                                 1  \\\n",
       "100002                                                                 0   \n",
       "100003                                                                 1   \n",
       "100004                                                                 1   \n",
       "100005                                                                 1   \n",
       "...                                                                  ...   \n",
       "456251                                                                 0   \n",
       "456252                                                                 0   \n",
       "456253                                                                 0   \n",
       "456254                                                                 0   \n",
       "456255                                                                 3   \n",
       "\n",
       "            previous_application_WEEKDAY_APPR_PROCESS_START_FRIDAY_count_norm   \n",
       "SK_ID_CURR                                                                      \n",
       "100001                                                               1.000000  \\\n",
       "100002                                                               0.000000   \n",
       "100003                                                               0.333333   \n",
       "100004                                                               1.000000   \n",
       "100005                                                               0.500000   \n",
       "...                                                                       ...   \n",
       "456251                                                               0.000000   \n",
       "456252                                                               0.000000   \n",
       "456253                                                               0.000000   \n",
       "456254                                                               0.000000   \n",
       "456255                                                               0.375000   \n",
       "\n",
       "            ...   \n",
       "SK_ID_CURR  ...   \n",
       "100001      ...  \\\n",
       "100002      ...   \n",
       "100003      ...   \n",
       "100004      ...   \n",
       "100005      ...   \n",
       "...         ...   \n",
       "456251      ...   \n",
       "456252      ...   \n",
       "456253      ...   \n",
       "456254      ...   \n",
       "456255      ...   \n",
       "\n",
       "            previous_application_PRODUCT_COMBINATION_POS industry without interest_count   \n",
       "SK_ID_CURR                                                                                 \n",
       "100001                                                                                 0  \\\n",
       "100002                                                                                 0   \n",
       "100003                                                                                 0   \n",
       "100004                                                                                 0   \n",
       "100005                                                                                 0   \n",
       "...                                                                                  ...   \n",
       "456251                                                                                 0   \n",
       "456252                                                                                 0   \n",
       "456253                                                                                 0   \n",
       "456254                                                                                 0   \n",
       "456255                                                                                 0   \n",
       "\n",
       "            previous_application_PRODUCT_COMBINATION_POS industry without interest_count_norm   \n",
       "SK_ID_CURR                                                                                      \n",
       "100001                                                                                    0.0  \\\n",
       "100002                                                                                    0.0   \n",
       "100003                                                                                    0.0   \n",
       "100004                                                                                    0.0   \n",
       "100005                                                                                    0.0   \n",
       "...                                                                                       ...   \n",
       "456251                                                                                    0.0   \n",
       "456252                                                                                    0.0   \n",
       "456253                                                                                    0.0   \n",
       "456254                                                                                    0.0   \n",
       "456255                                                                                    0.0   \n",
       "\n",
       "            previous_application_PRODUCT_COMBINATION_POS mobile with interest_count   \n",
       "SK_ID_CURR                                                                            \n",
       "100001                                                                            1  \\\n",
       "100002                                                                            0   \n",
       "100003                                                                            0   \n",
       "100004                                                                            0   \n",
       "100005                                                                            1   \n",
       "...                                                                             ...   \n",
       "456251                                                                            1   \n",
       "456252                                                                            0   \n",
       "456253                                                                            2   \n",
       "456254                                                                            1   \n",
       "456255                                                                            2   \n",
       "\n",
       "            previous_application_PRODUCT_COMBINATION_POS mobile with interest_count_norm   \n",
       "SK_ID_CURR                                                                                 \n",
       "100001                                                                              1.00  \\\n",
       "100002                                                                              0.00   \n",
       "100003                                                                              0.00   \n",
       "100004                                                                              0.00   \n",
       "100005                                                                              0.50   \n",
       "...                                                                                  ...   \n",
       "456251                                                                              1.00   \n",
       "456252                                                                              0.00   \n",
       "456253                                                                              1.00   \n",
       "456254                                                                              0.50   \n",
       "456255                                                                              0.25   \n",
       "\n",
       "            previous_application_PRODUCT_COMBINATION_POS mobile without interest_count   \n",
       "SK_ID_CURR                                                                               \n",
       "100001                                                                               0  \\\n",
       "100002                                                                               0   \n",
       "100003                                                                               0   \n",
       "100004                                                                               1   \n",
       "100005                                                                               0   \n",
       "...                                                                                ...   \n",
       "456251                                                                               0   \n",
       "456252                                                                               0   \n",
       "456253                                                                               0   \n",
       "456254                                                                               0   \n",
       "456255                                                                               0   \n",
       "\n",
       "            previous_application_PRODUCT_COMBINATION_POS mobile without interest_count_norm   \n",
       "SK_ID_CURR                                                                                    \n",
       "100001                                                                                  0.0  \\\n",
       "100002                                                                                  0.0   \n",
       "100003                                                                                  0.0   \n",
       "100004                                                                                  1.0   \n",
       "100005                                                                                  0.0   \n",
       "...                                                                                     ...   \n",
       "456251                                                                                  0.0   \n",
       "456252                                                                                  0.0   \n",
       "456253                                                                                  0.0   \n",
       "456254                                                                                  0.0   \n",
       "456255                                                                                  0.0   \n",
       "\n",
       "            previous_application_PRODUCT_COMBINATION_POS other with interest_count   \n",
       "SK_ID_CURR                                                                           \n",
       "100001                                                                           0  \\\n",
       "100002                                                                           1   \n",
       "100003                                                                           0   \n",
       "100004                                                                           0   \n",
       "100005                                                                           0   \n",
       "...                                                                            ...   \n",
       "456251                                                                           0   \n",
       "456252                                                                           0   \n",
       "456253                                                                           0   \n",
       "456254                                                                           0   \n",
       "456255                                                                           0   \n",
       "\n",
       "            previous_application_PRODUCT_COMBINATION_POS other with interest_count_norm   \n",
       "SK_ID_CURR                                                                                \n",
       "100001                                                                              0.0  \\\n",
       "100002                                                                              1.0   \n",
       "100003                                                                              0.0   \n",
       "100004                                                                              0.0   \n",
       "100005                                                                              0.0   \n",
       "...                                                                                 ...   \n",
       "456251                                                                              0.0   \n",
       "456252                                                                              0.0   \n",
       "456253                                                                              0.0   \n",
       "456254                                                                              0.0   \n",
       "456255                                                                              0.0   \n",
       "\n",
       "            previous_application_PRODUCT_COMBINATION_POS others without interest_count   \n",
       "SK_ID_CURR                                                                               \n",
       "100001                                                                               0  \\\n",
       "100002                                                                               0   \n",
       "100003                                                                               0   \n",
       "100004                                                                               0   \n",
       "100005                                                                               0   \n",
       "...                                                                                ...   \n",
       "456251                                                                               0   \n",
       "456252                                                                               0   \n",
       "456253                                                                               0   \n",
       "456254                                                                               0   \n",
       "456255                                                                               0   \n",
       "\n",
       "            previous_application_PRODUCT_COMBINATION_POS others without interest_count_norm  \n",
       "SK_ID_CURR                                                                                   \n",
       "100001                                                                                  0.0  \n",
       "100002                                                                                  0.0  \n",
       "100003                                                                                  0.0  \n",
       "100004                                                                                  0.0  \n",
       "100005                                                                                  0.0  \n",
       "...                                                                                     ...  \n",
       "456251                                                                                  0.0  \n",
       "456252                                                                                  0.0  \n",
       "456253                                                                                  0.0  \n",
       "456254                                                                                  0.0  \n",
       "456255                                                                                  0.0  \n",
       "\n",
       "[338857 rows x 286 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "previous_application_cat_agg_SK_ID_CURR = count_categorical(previous_application.drop(columns=['SK_ID_PREV']), group_var='SK_ID_CURR', df_name='previous_application')\n",
    "previous_application_cat_agg_SK_ID_CURR"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "436d6781",
   "metadata": {},
   "source": [
    "### Feature names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cc638f54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# previous_application_num_agg_SK_ID_CURR and previous_application_cat_agg_SK_ID_CURR"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "859e88a9",
   "metadata": {},
   "source": [
    "## Aggrégation de POS_CASH_BALANCE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "510af146",
   "metadata": {},
   "source": [
    "### Overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6025ffd1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SK_ID_PREV</th>\n",
       "      <th>SK_ID_CURR</th>\n",
       "      <th>MONTHS_BALANCE</th>\n",
       "      <th>CNT_INSTALMENT</th>\n",
       "      <th>CNT_INSTALMENT_FUTURE</th>\n",
       "      <th>NAME_CONTRACT_STATUS</th>\n",
       "      <th>SK_DPD</th>\n",
       "      <th>SK_DPD_DEF</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1803195</td>\n",
       "      <td>182943</td>\n",
       "      <td>-31</td>\n",
       "      <td>48.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>Active</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1715348</td>\n",
       "      <td>367990</td>\n",
       "      <td>-33</td>\n",
       "      <td>36.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>Active</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1784872</td>\n",
       "      <td>397406</td>\n",
       "      <td>-32</td>\n",
       "      <td>12.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>Active</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1903291</td>\n",
       "      <td>269225</td>\n",
       "      <td>-35</td>\n",
       "      <td>48.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>Active</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2341044</td>\n",
       "      <td>334279</td>\n",
       "      <td>-35</td>\n",
       "      <td>36.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>Active</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10001353</th>\n",
       "      <td>2448283</td>\n",
       "      <td>226558</td>\n",
       "      <td>-20</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Active</td>\n",
       "      <td>843</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10001354</th>\n",
       "      <td>1717234</td>\n",
       "      <td>141565</td>\n",
       "      <td>-19</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Active</td>\n",
       "      <td>602</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10001355</th>\n",
       "      <td>1283126</td>\n",
       "      <td>315695</td>\n",
       "      <td>-21</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Active</td>\n",
       "      <td>609</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10001356</th>\n",
       "      <td>1082516</td>\n",
       "      <td>450255</td>\n",
       "      <td>-22</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Active</td>\n",
       "      <td>614</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10001357</th>\n",
       "      <td>1259607</td>\n",
       "      <td>174278</td>\n",
       "      <td>-52</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Completed</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10001358 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          SK_ID_PREV  SK_ID_CURR  MONTHS_BALANCE  CNT_INSTALMENT   \n",
       "0            1803195      182943             -31            48.0  \\\n",
       "1            1715348      367990             -33            36.0   \n",
       "2            1784872      397406             -32            12.0   \n",
       "3            1903291      269225             -35            48.0   \n",
       "4            2341044      334279             -35            36.0   \n",
       "...              ...         ...             ...             ...   \n",
       "10001353     2448283      226558             -20             6.0   \n",
       "10001354     1717234      141565             -19            12.0   \n",
       "10001355     1283126      315695             -21            10.0   \n",
       "10001356     1082516      450255             -22            12.0   \n",
       "10001357     1259607      174278             -52            16.0   \n",
       "\n",
       "          CNT_INSTALMENT_FUTURE NAME_CONTRACT_STATUS  SK_DPD  SK_DPD_DEF  \n",
       "0                          45.0               Active       0           0  \n",
       "1                          35.0               Active       0           0  \n",
       "2                           9.0               Active       0           0  \n",
       "3                          42.0               Active       0           0  \n",
       "4                          35.0               Active       0           0  \n",
       "...                         ...                  ...     ...         ...  \n",
       "10001353                    0.0               Active     843           0  \n",
       "10001354                    0.0               Active     602           0  \n",
       "10001355                    0.0               Active     609           0  \n",
       "10001356                    0.0               Active     614           0  \n",
       "10001357                    0.0            Completed       0           0  \n",
       "\n",
       "[10001358 rows x 8 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "POS_CASH_balance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8efc51fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "936325"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "POS_CASH_balance['SK_ID_PREV'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "90cc7a22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "337252"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "POS_CASH_balance['SK_ID_CURR'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2ee37d59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Table</th>\n",
       "      <th>Row</th>\n",
       "      <th>Description</th>\n",
       "      <th>Special</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>145</td>\n",
       "      <td>POS_CASH_balance.csv</td>\n",
       "      <td>SK_ID_PREV</td>\n",
       "      <td>ID of previous credit in Home Credit related to loan in our sample. (One loan in our sample can have 0,1,2 or more previous loans in Home Credit)</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>146</td>\n",
       "      <td>POS_CASH_balance.csv</td>\n",
       "      <td>SK_ID_CURR</td>\n",
       "      <td>ID of loan in our sample</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>147</td>\n",
       "      <td>POS_CASH_balance.csv</td>\n",
       "      <td>MONTHS_BALANCE</td>\n",
       "      <td>Month of balance relative to application date (-1 means the information to the freshest monthly snapshot, 0 means the information at application - often it will be the same as -1 as many banks are not updating the information to Credit Bureau regularly )</td>\n",
       "      <td>time only relative to the application</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>148</td>\n",
       "      <td>POS_CASH_balance.csv</td>\n",
       "      <td>CNT_INSTALMENT</td>\n",
       "      <td>Term of previous credit (can change over time)</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>149</td>\n",
       "      <td>POS_CASH_balance.csv</td>\n",
       "      <td>CNT_INSTALMENT_FUTURE</td>\n",
       "      <td>Installments left to pay on the previous credit</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>150</td>\n",
       "      <td>POS_CASH_balance.csv</td>\n",
       "      <td>NAME_CONTRACT_STATUS</td>\n",
       "      <td>Contract status during the month</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>151</td>\n",
       "      <td>POS_CASH_balance.csv</td>\n",
       "      <td>SK_DPD</td>\n",
       "      <td>DPD (days past due) during the month of previous credit</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>152</td>\n",
       "      <td>POS_CASH_balance.csv</td>\n",
       "      <td>SK_DPD_DEF</td>\n",
       "      <td>DPD during the month with tolerance (debts with low loan amounts are ignored) of the previous credit</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Unnamed: 0                 Table                    Row   \n",
       "142         145  POS_CASH_balance.csv            SK_ID_PREV   \\\n",
       "143         146  POS_CASH_balance.csv             SK_ID_CURR   \n",
       "144         147  POS_CASH_balance.csv         MONTHS_BALANCE   \n",
       "145         148  POS_CASH_balance.csv         CNT_INSTALMENT   \n",
       "146         149  POS_CASH_balance.csv  CNT_INSTALMENT_FUTURE   \n",
       "147         150  POS_CASH_balance.csv   NAME_CONTRACT_STATUS   \n",
       "148         151  POS_CASH_balance.csv                 SK_DPD   \n",
       "149         152  POS_CASH_balance.csv             SK_DPD_DEF   \n",
       "\n",
       "                                                                                                                                                                                                                                                        Description   \n",
       "142                                                                                                               ID of previous credit in Home Credit related to loan in our sample. (One loan in our sample can have 0,1,2 or more previous loans in Home Credit)  \\\n",
       "143                                                                                                                                                                                                                                        ID of loan in our sample   \n",
       "144  Month of balance relative to application date (-1 means the information to the freshest monthly snapshot, 0 means the information at application - often it will be the same as -1 as many banks are not updating the information to Credit Bureau regularly )   \n",
       "145                                                                                                                                                                                                                  Term of previous credit (can change over time)   \n",
       "146                                                                                                                                                                                                                 Installments left to pay on the previous credit   \n",
       "147                                                                                                                                                                                                                                Contract status during the month   \n",
       "148                                                                                                                                                                                                         DPD (days past due) during the month of previous credit   \n",
       "149                                                                                                                                                            DPD during the month with tolerance (debts with low loan amounts are ignored) of the previous credit   \n",
       "\n",
       "                                   Special  \n",
       "142                                    NaN  \n",
       "143                                    NaN  \n",
       "144  time only relative to the application  \n",
       "145                                    NaN  \n",
       "146                                    NaN  \n",
       "147                                    NaN  \n",
       "148                                    NaN  \n",
       "149                                    NaN  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "HomeCredit[HomeCredit['Table'] == 'POS_CASH_balance.csv']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3bca942",
   "metadata": {},
   "source": [
    "### Aggrégation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "daabcade",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SK_ID_CURR</th>\n",
       "      <th>POS_CASH_balance_MONTHS_BALANCE_count</th>\n",
       "      <th>POS_CASH_balance_MONTHS_BALANCE_mean</th>\n",
       "      <th>POS_CASH_balance_MONTHS_BALANCE_max</th>\n",
       "      <th>POS_CASH_balance_MONTHS_BALANCE_min</th>\n",
       "      <th>POS_CASH_balance_MONTHS_BALANCE_sum</th>\n",
       "      <th>POS_CASH_balance_CNT_INSTALMENT_count</th>\n",
       "      <th>POS_CASH_balance_CNT_INSTALMENT_mean</th>\n",
       "      <th>POS_CASH_balance_CNT_INSTALMENT_max</th>\n",
       "      <th>POS_CASH_balance_CNT_INSTALMENT_min</th>\n",
       "      <th>...</th>\n",
       "      <th>POS_CASH_balance_SK_DPD_count</th>\n",
       "      <th>POS_CASH_balance_SK_DPD_mean</th>\n",
       "      <th>POS_CASH_balance_SK_DPD_max</th>\n",
       "      <th>POS_CASH_balance_SK_DPD_min</th>\n",
       "      <th>POS_CASH_balance_SK_DPD_sum</th>\n",
       "      <th>POS_CASH_balance_SK_DPD_DEF_count</th>\n",
       "      <th>POS_CASH_balance_SK_DPD_DEF_mean</th>\n",
       "      <th>POS_CASH_balance_SK_DPD_DEF_max</th>\n",
       "      <th>POS_CASH_balance_SK_DPD_DEF_min</th>\n",
       "      <th>POS_CASH_balance_SK_DPD_DEF_sum</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100001</td>\n",
       "      <td>9</td>\n",
       "      <td>-72.555556</td>\n",
       "      <td>-53</td>\n",
       "      <td>-96</td>\n",
       "      <td>-653</td>\n",
       "      <td>9</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>9</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100002</td>\n",
       "      <td>19</td>\n",
       "      <td>-10.000000</td>\n",
       "      <td>-1</td>\n",
       "      <td>-19</td>\n",
       "      <td>-190</td>\n",
       "      <td>19</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>24.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>...</td>\n",
       "      <td>19</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100003</td>\n",
       "      <td>28</td>\n",
       "      <td>-43.785714</td>\n",
       "      <td>-18</td>\n",
       "      <td>-77</td>\n",
       "      <td>-1226</td>\n",
       "      <td>28</td>\n",
       "      <td>10.107143</td>\n",
       "      <td>12.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>...</td>\n",
       "      <td>28</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>28</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100004</td>\n",
       "      <td>4</td>\n",
       "      <td>-25.500000</td>\n",
       "      <td>-24</td>\n",
       "      <td>-27</td>\n",
       "      <td>-102</td>\n",
       "      <td>4</td>\n",
       "      <td>3.750000</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>100005</td>\n",
       "      <td>11</td>\n",
       "      <td>-20.000000</td>\n",
       "      <td>-15</td>\n",
       "      <td>-25</td>\n",
       "      <td>-220</td>\n",
       "      <td>10</td>\n",
       "      <td>11.700000</td>\n",
       "      <td>12.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>...</td>\n",
       "      <td>11</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>337247</th>\n",
       "      <td>456251</td>\n",
       "      <td>9</td>\n",
       "      <td>-5.000000</td>\n",
       "      <td>-1</td>\n",
       "      <td>-9</td>\n",
       "      <td>-45</td>\n",
       "      <td>8</td>\n",
       "      <td>7.875000</td>\n",
       "      <td>8.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>...</td>\n",
       "      <td>9</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>337248</th>\n",
       "      <td>456252</td>\n",
       "      <td>7</td>\n",
       "      <td>-79.000000</td>\n",
       "      <td>-76</td>\n",
       "      <td>-82</td>\n",
       "      <td>-553</td>\n",
       "      <td>7</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>337249</th>\n",
       "      <td>456253</td>\n",
       "      <td>17</td>\n",
       "      <td>-79.235294</td>\n",
       "      <td>-57</td>\n",
       "      <td>-96</td>\n",
       "      <td>-1347</td>\n",
       "      <td>17</td>\n",
       "      <td>6.705882</td>\n",
       "      <td>12.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>17</td>\n",
       "      <td>0.294118</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>17</td>\n",
       "      <td>0.294118</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>337250</th>\n",
       "      <td>456254</td>\n",
       "      <td>20</td>\n",
       "      <td>-5.550000</td>\n",
       "      <td>-1</td>\n",
       "      <td>-11</td>\n",
       "      <td>-111</td>\n",
       "      <td>20</td>\n",
       "      <td>14.900000</td>\n",
       "      <td>16.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>...</td>\n",
       "      <td>20</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>337251</th>\n",
       "      <td>456255</td>\n",
       "      <td>71</td>\n",
       "      <td>-16.408451</td>\n",
       "      <td>-2</td>\n",
       "      <td>-33</td>\n",
       "      <td>-1165</td>\n",
       "      <td>71</td>\n",
       "      <td>22.788732</td>\n",
       "      <td>36.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>71</td>\n",
       "      <td>0.070423</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>71</td>\n",
       "      <td>0.070423</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>337252 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        SK_ID_CURR  POS_CASH_balance_MONTHS_BALANCE_count   \n",
       "0           100001                                      9  \\\n",
       "1           100002                                     19   \n",
       "2           100003                                     28   \n",
       "3           100004                                      4   \n",
       "4           100005                                     11   \n",
       "...            ...                                    ...   \n",
       "337247      456251                                      9   \n",
       "337248      456252                                      7   \n",
       "337249      456253                                     17   \n",
       "337250      456254                                     20   \n",
       "337251      456255                                     71   \n",
       "\n",
       "        POS_CASH_balance_MONTHS_BALANCE_mean   \n",
       "0                                 -72.555556  \\\n",
       "1                                 -10.000000   \n",
       "2                                 -43.785714   \n",
       "3                                 -25.500000   \n",
       "4                                 -20.000000   \n",
       "...                                      ...   \n",
       "337247                             -5.000000   \n",
       "337248                            -79.000000   \n",
       "337249                            -79.235294   \n",
       "337250                             -5.550000   \n",
       "337251                            -16.408451   \n",
       "\n",
       "        POS_CASH_balance_MONTHS_BALANCE_max   \n",
       "0                                       -53  \\\n",
       "1                                        -1   \n",
       "2                                       -18   \n",
       "3                                       -24   \n",
       "4                                       -15   \n",
       "...                                     ...   \n",
       "337247                                   -1   \n",
       "337248                                  -76   \n",
       "337249                                  -57   \n",
       "337250                                   -1   \n",
       "337251                                   -2   \n",
       "\n",
       "        POS_CASH_balance_MONTHS_BALANCE_min   \n",
       "0                                       -96  \\\n",
       "1                                       -19   \n",
       "2                                       -77   \n",
       "3                                       -27   \n",
       "4                                       -25   \n",
       "...                                     ...   \n",
       "337247                                   -9   \n",
       "337248                                  -82   \n",
       "337249                                  -96   \n",
       "337250                                  -11   \n",
       "337251                                  -33   \n",
       "\n",
       "        POS_CASH_balance_MONTHS_BALANCE_sum   \n",
       "0                                      -653  \\\n",
       "1                                      -190   \n",
       "2                                     -1226   \n",
       "3                                      -102   \n",
       "4                                      -220   \n",
       "...                                     ...   \n",
       "337247                                  -45   \n",
       "337248                                 -553   \n",
       "337249                                -1347   \n",
       "337250                                 -111   \n",
       "337251                                -1165   \n",
       "\n",
       "        POS_CASH_balance_CNT_INSTALMENT_count   \n",
       "0                                           9  \\\n",
       "1                                          19   \n",
       "2                                          28   \n",
       "3                                           4   \n",
       "4                                          10   \n",
       "...                                       ...   \n",
       "337247                                      8   \n",
       "337248                                      7   \n",
       "337249                                     17   \n",
       "337250                                     20   \n",
       "337251                                     71   \n",
       "\n",
       "        POS_CASH_balance_CNT_INSTALMENT_mean   \n",
       "0                                   4.000000  \\\n",
       "1                                  24.000000   \n",
       "2                                  10.107143   \n",
       "3                                   3.750000   \n",
       "4                                  11.700000   \n",
       "...                                      ...   \n",
       "337247                              7.875000   \n",
       "337248                              6.000000   \n",
       "337249                              6.705882   \n",
       "337250                             14.900000   \n",
       "337251                             22.788732   \n",
       "\n",
       "        POS_CASH_balance_CNT_INSTALMENT_max   \n",
       "0                                       4.0  \\\n",
       "1                                      24.0   \n",
       "2                                      12.0   \n",
       "3                                       4.0   \n",
       "4                                      12.0   \n",
       "...                                     ...   \n",
       "337247                                  8.0   \n",
       "337248                                  6.0   \n",
       "337249                                 12.0   \n",
       "337250                                 16.0   \n",
       "337251                                 36.0   \n",
       "\n",
       "        POS_CASH_balance_CNT_INSTALMENT_min  ...   \n",
       "0                                       4.0  ...  \\\n",
       "1                                      24.0  ...   \n",
       "2                                       6.0  ...   \n",
       "3                                       3.0  ...   \n",
       "4                                       9.0  ...   \n",
       "...                                     ...  ...   \n",
       "337247                                  7.0  ...   \n",
       "337248                                  6.0  ...   \n",
       "337249                                  4.0  ...   \n",
       "337250                                 14.0  ...   \n",
       "337251                                  3.0  ...   \n",
       "\n",
       "        POS_CASH_balance_SK_DPD_count  POS_CASH_balance_SK_DPD_mean   \n",
       "0                                   9                      0.777778  \\\n",
       "1                                  19                      0.000000   \n",
       "2                                  28                      0.000000   \n",
       "3                                   4                      0.000000   \n",
       "4                                  11                      0.000000   \n",
       "...                               ...                           ...   \n",
       "337247                              9                      0.000000   \n",
       "337248                              7                      0.000000   \n",
       "337249                             17                      0.294118   \n",
       "337250                             20                      0.000000   \n",
       "337251                             71                      0.070423   \n",
       "\n",
       "        POS_CASH_balance_SK_DPD_max  POS_CASH_balance_SK_DPD_min   \n",
       "0                                 7                            0  \\\n",
       "1                                 0                            0   \n",
       "2                                 0                            0   \n",
       "3                                 0                            0   \n",
       "4                                 0                            0   \n",
       "...                             ...                          ...   \n",
       "337247                            0                            0   \n",
       "337248                            0                            0   \n",
       "337249                            5                            0   \n",
       "337250                            0                            0   \n",
       "337251                            5                            0   \n",
       "\n",
       "        POS_CASH_balance_SK_DPD_sum  POS_CASH_balance_SK_DPD_DEF_count   \n",
       "0                                 7                                  9  \\\n",
       "1                                 0                                 19   \n",
       "2                                 0                                 28   \n",
       "3                                 0                                  4   \n",
       "4                                 0                                 11   \n",
       "...                             ...                                ...   \n",
       "337247                            0                                  9   \n",
       "337248                            0                                  7   \n",
       "337249                            5                                 17   \n",
       "337250                            0                                 20   \n",
       "337251                            5                                 71   \n",
       "\n",
       "        POS_CASH_balance_SK_DPD_DEF_mean  POS_CASH_balance_SK_DPD_DEF_max   \n",
       "0                               0.777778                                7  \\\n",
       "1                               0.000000                                0   \n",
       "2                               0.000000                                0   \n",
       "3                               0.000000                                0   \n",
       "4                               0.000000                                0   \n",
       "...                                  ...                              ...   \n",
       "337247                          0.000000                                0   \n",
       "337248                          0.000000                                0   \n",
       "337249                          0.294118                                5   \n",
       "337250                          0.000000                                0   \n",
       "337251                          0.070423                                5   \n",
       "\n",
       "        POS_CASH_balance_SK_DPD_DEF_min  POS_CASH_balance_SK_DPD_DEF_sum  \n",
       "0                                     0                                7  \n",
       "1                                     0                                0  \n",
       "2                                     0                                0  \n",
       "3                                     0                                0  \n",
       "4                                     0                                0  \n",
       "...                                 ...                              ...  \n",
       "337247                                0                                0  \n",
       "337248                                0                                0  \n",
       "337249                                0                                5  \n",
       "337250                                0                                0  \n",
       "337251                                0                                5  \n",
       "\n",
       "[337252 rows x 26 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "POS_CASH_balance_num_agg_SK_ID_CURR = agg_numeric(POS_CASH_balance.drop(columns=['SK_ID_PREV']), group_var='SK_ID_CURR', df_name='POS_CASH_balance')\n",
    "POS_CASH_balance_num_agg_SK_ID_CURR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "aaab2e63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>POS_CASH_balance_NAME_CONTRACT_STATUS_Active_count</th>\n",
       "      <th>POS_CASH_balance_NAME_CONTRACT_STATUS_Active_count_norm</th>\n",
       "      <th>POS_CASH_balance_NAME_CONTRACT_STATUS_Amortized debt_count</th>\n",
       "      <th>POS_CASH_balance_NAME_CONTRACT_STATUS_Amortized debt_count_norm</th>\n",
       "      <th>POS_CASH_balance_NAME_CONTRACT_STATUS_Approved_count</th>\n",
       "      <th>POS_CASH_balance_NAME_CONTRACT_STATUS_Approved_count_norm</th>\n",
       "      <th>POS_CASH_balance_NAME_CONTRACT_STATUS_Canceled_count</th>\n",
       "      <th>POS_CASH_balance_NAME_CONTRACT_STATUS_Canceled_count_norm</th>\n",
       "      <th>POS_CASH_balance_NAME_CONTRACT_STATUS_Completed_count</th>\n",
       "      <th>POS_CASH_balance_NAME_CONTRACT_STATUS_Completed_count_norm</th>\n",
       "      <th>POS_CASH_balance_NAME_CONTRACT_STATUS_Demand_count</th>\n",
       "      <th>POS_CASH_balance_NAME_CONTRACT_STATUS_Demand_count_norm</th>\n",
       "      <th>POS_CASH_balance_NAME_CONTRACT_STATUS_Returned to the store_count</th>\n",
       "      <th>POS_CASH_balance_NAME_CONTRACT_STATUS_Returned to the store_count_norm</th>\n",
       "      <th>POS_CASH_balance_NAME_CONTRACT_STATUS_Signed_count</th>\n",
       "      <th>POS_CASH_balance_NAME_CONTRACT_STATUS_Signed_count_norm</th>\n",
       "      <th>POS_CASH_balance_NAME_CONTRACT_STATUS_XNA_count</th>\n",
       "      <th>POS_CASH_balance_NAME_CONTRACT_STATUS_XNA_count_norm</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SK_ID_CURR</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>100001</th>\n",
       "      <td>7</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100002</th>\n",
       "      <td>19</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100003</th>\n",
       "      <td>26</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100004</th>\n",
       "      <td>3</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100005</th>\n",
       "      <td>9</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>456251</th>\n",
       "      <td>7</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>456252</th>\n",
       "      <td>6</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>456253</th>\n",
       "      <td>15</td>\n",
       "      <td>0.882353</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.117647</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>456254</th>\n",
       "      <td>20</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>456255</th>\n",
       "      <td>65</td>\n",
       "      <td>0.915493</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6</td>\n",
       "      <td>0.084507</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>337252 rows × 18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            POS_CASH_balance_NAME_CONTRACT_STATUS_Active_count   \n",
       "SK_ID_CURR                                                       \n",
       "100001                                                       7  \\\n",
       "100002                                                      19   \n",
       "100003                                                      26   \n",
       "100004                                                       3   \n",
       "100005                                                       9   \n",
       "...                                                        ...   \n",
       "456251                                                       7   \n",
       "456252                                                       6   \n",
       "456253                                                      15   \n",
       "456254                                                      20   \n",
       "456255                                                      65   \n",
       "\n",
       "            POS_CASH_balance_NAME_CONTRACT_STATUS_Active_count_norm   \n",
       "SK_ID_CURR                                                            \n",
       "100001                                                     0.777778  \\\n",
       "100002                                                     1.000000   \n",
       "100003                                                     0.928571   \n",
       "100004                                                     0.750000   \n",
       "100005                                                     0.818182   \n",
       "...                                                             ...   \n",
       "456251                                                     0.777778   \n",
       "456252                                                     0.857143   \n",
       "456253                                                     0.882353   \n",
       "456254                                                     1.000000   \n",
       "456255                                                     0.915493   \n",
       "\n",
       "            POS_CASH_balance_NAME_CONTRACT_STATUS_Amortized debt_count   \n",
       "SK_ID_CURR                                                               \n",
       "100001                                                               0  \\\n",
       "100002                                                               0   \n",
       "100003                                                               0   \n",
       "100004                                                               0   \n",
       "100005                                                               0   \n",
       "...                                                                ...   \n",
       "456251                                                               0   \n",
       "456252                                                               0   \n",
       "456253                                                               0   \n",
       "456254                                                               0   \n",
       "456255                                                               0   \n",
       "\n",
       "            POS_CASH_balance_NAME_CONTRACT_STATUS_Amortized debt_count_norm   \n",
       "SK_ID_CURR                                                                    \n",
       "100001                                                                  0.0  \\\n",
       "100002                                                                  0.0   \n",
       "100003                                                                  0.0   \n",
       "100004                                                                  0.0   \n",
       "100005                                                                  0.0   \n",
       "...                                                                     ...   \n",
       "456251                                                                  0.0   \n",
       "456252                                                                  0.0   \n",
       "456253                                                                  0.0   \n",
       "456254                                                                  0.0   \n",
       "456255                                                                  0.0   \n",
       "\n",
       "            POS_CASH_balance_NAME_CONTRACT_STATUS_Approved_count   \n",
       "SK_ID_CURR                                                         \n",
       "100001                                                         0  \\\n",
       "100002                                                         0   \n",
       "100003                                                         0   \n",
       "100004                                                         0   \n",
       "100005                                                         0   \n",
       "...                                                          ...   \n",
       "456251                                                         0   \n",
       "456252                                                         0   \n",
       "456253                                                         0   \n",
       "456254                                                         0   \n",
       "456255                                                         0   \n",
       "\n",
       "            POS_CASH_balance_NAME_CONTRACT_STATUS_Approved_count_norm   \n",
       "SK_ID_CURR                                                              \n",
       "100001                                                            0.0  \\\n",
       "100002                                                            0.0   \n",
       "100003                                                            0.0   \n",
       "100004                                                            0.0   \n",
       "100005                                                            0.0   \n",
       "...                                                               ...   \n",
       "456251                                                            0.0   \n",
       "456252                                                            0.0   \n",
       "456253                                                            0.0   \n",
       "456254                                                            0.0   \n",
       "456255                                                            0.0   \n",
       "\n",
       "            POS_CASH_balance_NAME_CONTRACT_STATUS_Canceled_count   \n",
       "SK_ID_CURR                                                         \n",
       "100001                                                         0  \\\n",
       "100002                                                         0   \n",
       "100003                                                         0   \n",
       "100004                                                         0   \n",
       "100005                                                         0   \n",
       "...                                                          ...   \n",
       "456251                                                         0   \n",
       "456252                                                         0   \n",
       "456253                                                         0   \n",
       "456254                                                         0   \n",
       "456255                                                         0   \n",
       "\n",
       "            POS_CASH_balance_NAME_CONTRACT_STATUS_Canceled_count_norm   \n",
       "SK_ID_CURR                                                              \n",
       "100001                                                            0.0  \\\n",
       "100002                                                            0.0   \n",
       "100003                                                            0.0   \n",
       "100004                                                            0.0   \n",
       "100005                                                            0.0   \n",
       "...                                                               ...   \n",
       "456251                                                            0.0   \n",
       "456252                                                            0.0   \n",
       "456253                                                            0.0   \n",
       "456254                                                            0.0   \n",
       "456255                                                            0.0   \n",
       "\n",
       "            POS_CASH_balance_NAME_CONTRACT_STATUS_Completed_count   \n",
       "SK_ID_CURR                                                          \n",
       "100001                                                          2  \\\n",
       "100002                                                          0   \n",
       "100003                                                          2   \n",
       "100004                                                          1   \n",
       "100005                                                          1   \n",
       "...                                                           ...   \n",
       "456251                                                          1   \n",
       "456252                                                          1   \n",
       "456253                                                          2   \n",
       "456254                                                          0   \n",
       "456255                                                          6   \n",
       "\n",
       "            POS_CASH_balance_NAME_CONTRACT_STATUS_Completed_count_norm   \n",
       "SK_ID_CURR                                                               \n",
       "100001                                                        0.222222  \\\n",
       "100002                                                        0.000000   \n",
       "100003                                                        0.071429   \n",
       "100004                                                        0.250000   \n",
       "100005                                                        0.090909   \n",
       "...                                                                ...   \n",
       "456251                                                        0.111111   \n",
       "456252                                                        0.142857   \n",
       "456253                                                        0.117647   \n",
       "456254                                                        0.000000   \n",
       "456255                                                        0.084507   \n",
       "\n",
       "            POS_CASH_balance_NAME_CONTRACT_STATUS_Demand_count   \n",
       "SK_ID_CURR                                                       \n",
       "100001                                                       0  \\\n",
       "100002                                                       0   \n",
       "100003                                                       0   \n",
       "100004                                                       0   \n",
       "100005                                                       0   \n",
       "...                                                        ...   \n",
       "456251                                                       0   \n",
       "456252                                                       0   \n",
       "456253                                                       0   \n",
       "456254                                                       0   \n",
       "456255                                                       0   \n",
       "\n",
       "            POS_CASH_balance_NAME_CONTRACT_STATUS_Demand_count_norm   \n",
       "SK_ID_CURR                                                            \n",
       "100001                                                          0.0  \\\n",
       "100002                                                          0.0   \n",
       "100003                                                          0.0   \n",
       "100004                                                          0.0   \n",
       "100005                                                          0.0   \n",
       "...                                                             ...   \n",
       "456251                                                          0.0   \n",
       "456252                                                          0.0   \n",
       "456253                                                          0.0   \n",
       "456254                                                          0.0   \n",
       "456255                                                          0.0   \n",
       "\n",
       "            POS_CASH_balance_NAME_CONTRACT_STATUS_Returned to the store_count   \n",
       "SK_ID_CURR                                                                      \n",
       "100001                                                                      0  \\\n",
       "100002                                                                      0   \n",
       "100003                                                                      0   \n",
       "100004                                                                      0   \n",
       "100005                                                                      0   \n",
       "...                                                                       ...   \n",
       "456251                                                                      0   \n",
       "456252                                                                      0   \n",
       "456253                                                                      0   \n",
       "456254                                                                      0   \n",
       "456255                                                                      0   \n",
       "\n",
       "            POS_CASH_balance_NAME_CONTRACT_STATUS_Returned to the store_count_norm   \n",
       "SK_ID_CURR                                                                           \n",
       "100001                                                                         0.0  \\\n",
       "100002                                                                         0.0   \n",
       "100003                                                                         0.0   \n",
       "100004                                                                         0.0   \n",
       "100005                                                                         0.0   \n",
       "...                                                                            ...   \n",
       "456251                                                                         0.0   \n",
       "456252                                                                         0.0   \n",
       "456253                                                                         0.0   \n",
       "456254                                                                         0.0   \n",
       "456255                                                                         0.0   \n",
       "\n",
       "            POS_CASH_balance_NAME_CONTRACT_STATUS_Signed_count   \n",
       "SK_ID_CURR                                                       \n",
       "100001                                                       0  \\\n",
       "100002                                                       0   \n",
       "100003                                                       0   \n",
       "100004                                                       0   \n",
       "100005                                                       1   \n",
       "...                                                        ...   \n",
       "456251                                                       1   \n",
       "456252                                                       0   \n",
       "456253                                                       0   \n",
       "456254                                                       0   \n",
       "456255                                                       0   \n",
       "\n",
       "            POS_CASH_balance_NAME_CONTRACT_STATUS_Signed_count_norm   \n",
       "SK_ID_CURR                                                            \n",
       "100001                                                     0.000000  \\\n",
       "100002                                                     0.000000   \n",
       "100003                                                     0.000000   \n",
       "100004                                                     0.000000   \n",
       "100005                                                     0.090909   \n",
       "...                                                             ...   \n",
       "456251                                                     0.111111   \n",
       "456252                                                     0.000000   \n",
       "456253                                                     0.000000   \n",
       "456254                                                     0.000000   \n",
       "456255                                                     0.000000   \n",
       "\n",
       "            POS_CASH_balance_NAME_CONTRACT_STATUS_XNA_count   \n",
       "SK_ID_CURR                                                    \n",
       "100001                                                    0  \\\n",
       "100002                                                    0   \n",
       "100003                                                    0   \n",
       "100004                                                    0   \n",
       "100005                                                    0   \n",
       "...                                                     ...   \n",
       "456251                                                    0   \n",
       "456252                                                    0   \n",
       "456253                                                    0   \n",
       "456254                                                    0   \n",
       "456255                                                    0   \n",
       "\n",
       "            POS_CASH_balance_NAME_CONTRACT_STATUS_XNA_count_norm  \n",
       "SK_ID_CURR                                                        \n",
       "100001                                                       0.0  \n",
       "100002                                                       0.0  \n",
       "100003                                                       0.0  \n",
       "100004                                                       0.0  \n",
       "100005                                                       0.0  \n",
       "...                                                          ...  \n",
       "456251                                                       0.0  \n",
       "456252                                                       0.0  \n",
       "456253                                                       0.0  \n",
       "456254                                                       0.0  \n",
       "456255                                                       0.0  \n",
       "\n",
       "[337252 rows x 18 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "POS_CASH_balance_cat_agg_SK_ID_CURR = count_categorical(POS_CASH_balance.drop(columns=['SK_ID_PREV']), group_var='SK_ID_CURR', df_name='POS_CASH_balance')\n",
    "POS_CASH_balance_cat_agg_SK_ID_CURR"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47e7f57d",
   "metadata": {},
   "source": [
    "### Feature names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9179a6a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# POS_CASH_balance_num_agg_SK_ID_CURR and POS_CASH_balance_cat_agg_SK_ID_CURR"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64267fc8",
   "metadata": {},
   "source": [
    "## Aggrégation de credit_card_balance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ba10a00",
   "metadata": {},
   "source": [
    "### Overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "30f1283d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SK_ID_PREV</th>\n",
       "      <th>SK_ID_CURR</th>\n",
       "      <th>MONTHS_BALANCE</th>\n",
       "      <th>AMT_BALANCE</th>\n",
       "      <th>AMT_CREDIT_LIMIT_ACTUAL</th>\n",
       "      <th>AMT_DRAWINGS_ATM_CURRENT</th>\n",
       "      <th>AMT_DRAWINGS_CURRENT</th>\n",
       "      <th>AMT_DRAWINGS_OTHER_CURRENT</th>\n",
       "      <th>AMT_DRAWINGS_POS_CURRENT</th>\n",
       "      <th>AMT_INST_MIN_REGULARITY</th>\n",
       "      <th>...</th>\n",
       "      <th>AMT_RECIVABLE</th>\n",
       "      <th>AMT_TOTAL_RECEIVABLE</th>\n",
       "      <th>CNT_DRAWINGS_ATM_CURRENT</th>\n",
       "      <th>CNT_DRAWINGS_CURRENT</th>\n",
       "      <th>CNT_DRAWINGS_OTHER_CURRENT</th>\n",
       "      <th>CNT_DRAWINGS_POS_CURRENT</th>\n",
       "      <th>CNT_INSTALMENT_MATURE_CUM</th>\n",
       "      <th>NAME_CONTRACT_STATUS</th>\n",
       "      <th>SK_DPD</th>\n",
       "      <th>SK_DPD_DEF</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2562384</td>\n",
       "      <td>378907</td>\n",
       "      <td>-6</td>\n",
       "      <td>56.970</td>\n",
       "      <td>135000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>877.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>877.5</td>\n",
       "      <td>1700.325</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>Active</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2582071</td>\n",
       "      <td>363914</td>\n",
       "      <td>-1</td>\n",
       "      <td>63975.555</td>\n",
       "      <td>45000</td>\n",
       "      <td>2250.0</td>\n",
       "      <td>2250.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2250.000</td>\n",
       "      <td>...</td>\n",
       "      <td>64875.555</td>\n",
       "      <td>64875.555</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>69.0</td>\n",
       "      <td>Active</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1740877</td>\n",
       "      <td>371185</td>\n",
       "      <td>-7</td>\n",
       "      <td>31815.225</td>\n",
       "      <td>450000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2250.000</td>\n",
       "      <td>...</td>\n",
       "      <td>31460.085</td>\n",
       "      <td>31460.085</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>Active</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1389973</td>\n",
       "      <td>337855</td>\n",
       "      <td>-4</td>\n",
       "      <td>236572.110</td>\n",
       "      <td>225000</td>\n",
       "      <td>2250.0</td>\n",
       "      <td>2250.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11795.760</td>\n",
       "      <td>...</td>\n",
       "      <td>233048.970</td>\n",
       "      <td>233048.970</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>Active</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1891521</td>\n",
       "      <td>126868</td>\n",
       "      <td>-1</td>\n",
       "      <td>453919.455</td>\n",
       "      <td>450000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11547.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11547.0</td>\n",
       "      <td>22924.890</td>\n",
       "      <td>...</td>\n",
       "      <td>453919.455</td>\n",
       "      <td>453919.455</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>Active</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3840307</th>\n",
       "      <td>1036507</td>\n",
       "      <td>328243</td>\n",
       "      <td>-9</td>\n",
       "      <td>0.000</td>\n",
       "      <td>45000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Active</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3840308</th>\n",
       "      <td>1714892</td>\n",
       "      <td>347207</td>\n",
       "      <td>-9</td>\n",
       "      <td>0.000</td>\n",
       "      <td>45000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>Active</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3840309</th>\n",
       "      <td>1302323</td>\n",
       "      <td>215757</td>\n",
       "      <td>-9</td>\n",
       "      <td>275784.975</td>\n",
       "      <td>585000</td>\n",
       "      <td>270000.0</td>\n",
       "      <td>270000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2250.000</td>\n",
       "      <td>...</td>\n",
       "      <td>273093.975</td>\n",
       "      <td>273093.975</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>Active</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3840310</th>\n",
       "      <td>1624872</td>\n",
       "      <td>430337</td>\n",
       "      <td>-10</td>\n",
       "      <td>0.000</td>\n",
       "      <td>450000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Active</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3840311</th>\n",
       "      <td>2411345</td>\n",
       "      <td>236760</td>\n",
       "      <td>-10</td>\n",
       "      <td>0.000</td>\n",
       "      <td>157500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>Completed</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3840312 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         SK_ID_PREV  SK_ID_CURR  MONTHS_BALANCE  AMT_BALANCE   \n",
       "0           2562384      378907              -6       56.970  \\\n",
       "1           2582071      363914              -1    63975.555   \n",
       "2           1740877      371185              -7    31815.225   \n",
       "3           1389973      337855              -4   236572.110   \n",
       "4           1891521      126868              -1   453919.455   \n",
       "...             ...         ...             ...          ...   \n",
       "3840307     1036507      328243              -9        0.000   \n",
       "3840308     1714892      347207              -9        0.000   \n",
       "3840309     1302323      215757              -9   275784.975   \n",
       "3840310     1624872      430337             -10        0.000   \n",
       "3840311     2411345      236760             -10        0.000   \n",
       "\n",
       "         AMT_CREDIT_LIMIT_ACTUAL  AMT_DRAWINGS_ATM_CURRENT   \n",
       "0                         135000                       0.0  \\\n",
       "1                          45000                    2250.0   \n",
       "2                         450000                       0.0   \n",
       "3                         225000                    2250.0   \n",
       "4                         450000                       0.0   \n",
       "...                          ...                       ...   \n",
       "3840307                    45000                       NaN   \n",
       "3840308                    45000                       0.0   \n",
       "3840309                   585000                  270000.0   \n",
       "3840310                   450000                       NaN   \n",
       "3840311                   157500                       0.0   \n",
       "\n",
       "         AMT_DRAWINGS_CURRENT  AMT_DRAWINGS_OTHER_CURRENT   \n",
       "0                       877.5                         0.0  \\\n",
       "1                      2250.0                         0.0   \n",
       "2                         0.0                         0.0   \n",
       "3                      2250.0                         0.0   \n",
       "4                     11547.0                         0.0   \n",
       "...                       ...                         ...   \n",
       "3840307                   0.0                         NaN   \n",
       "3840308                   0.0                         0.0   \n",
       "3840309              270000.0                         0.0   \n",
       "3840310                   0.0                         NaN   \n",
       "3840311                   0.0                         0.0   \n",
       "\n",
       "         AMT_DRAWINGS_POS_CURRENT  AMT_INST_MIN_REGULARITY  ...   \n",
       "0                           877.5                 1700.325  ...  \\\n",
       "1                             0.0                 2250.000  ...   \n",
       "2                             0.0                 2250.000  ...   \n",
       "3                             0.0                11795.760  ...   \n",
       "4                         11547.0                22924.890  ...   \n",
       "...                           ...                      ...  ...   \n",
       "3840307                       NaN                    0.000  ...   \n",
       "3840308                       0.0                    0.000  ...   \n",
       "3840309                       0.0                 2250.000  ...   \n",
       "3840310                       NaN                    0.000  ...   \n",
       "3840311                       0.0                    0.000  ...   \n",
       "\n",
       "         AMT_RECIVABLE  AMT_TOTAL_RECEIVABLE  CNT_DRAWINGS_ATM_CURRENT   \n",
       "0                0.000                 0.000                       0.0  \\\n",
       "1            64875.555             64875.555                       1.0   \n",
       "2            31460.085             31460.085                       0.0   \n",
       "3           233048.970            233048.970                       1.0   \n",
       "4           453919.455            453919.455                       0.0   \n",
       "...                ...                   ...                       ...   \n",
       "3840307          0.000                 0.000                       NaN   \n",
       "3840308          0.000                 0.000                       0.0   \n",
       "3840309     273093.975            273093.975                       2.0   \n",
       "3840310          0.000                 0.000                       NaN   \n",
       "3840311          0.000                 0.000                       0.0   \n",
       "\n",
       "         CNT_DRAWINGS_CURRENT  CNT_DRAWINGS_OTHER_CURRENT   \n",
       "0                           1                         0.0  \\\n",
       "1                           1                         0.0   \n",
       "2                           0                         0.0   \n",
       "3                           1                         0.0   \n",
       "4                           1                         0.0   \n",
       "...                       ...                         ...   \n",
       "3840307                     0                         NaN   \n",
       "3840308                     0                         0.0   \n",
       "3840309                     2                         0.0   \n",
       "3840310                     0                         NaN   \n",
       "3840311                     0                         0.0   \n",
       "\n",
       "         CNT_DRAWINGS_POS_CURRENT  CNT_INSTALMENT_MATURE_CUM   \n",
       "0                             1.0                       35.0  \\\n",
       "1                             0.0                       69.0   \n",
       "2                             0.0                       30.0   \n",
       "3                             0.0                       10.0   \n",
       "4                             1.0                      101.0   \n",
       "...                           ...                        ...   \n",
       "3840307                       NaN                        0.0   \n",
       "3840308                       0.0                       23.0   \n",
       "3840309                       0.0                       18.0   \n",
       "3840310                       NaN                        0.0   \n",
       "3840311                       0.0                       21.0   \n",
       "\n",
       "         NAME_CONTRACT_STATUS  SK_DPD  SK_DPD_DEF  \n",
       "0                      Active       0           0  \n",
       "1                      Active       0           0  \n",
       "2                      Active       0           0  \n",
       "3                      Active       0           0  \n",
       "4                      Active       0           0  \n",
       "...                       ...     ...         ...  \n",
       "3840307                Active       0           0  \n",
       "3840308                Active       0           0  \n",
       "3840309                Active       0           0  \n",
       "3840310                Active       0           0  \n",
       "3840311             Completed       0           0  \n",
       "\n",
       "[3840312 rows x 23 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "credit_card_balance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b104880a",
   "metadata": {},
   "source": [
    "### Aggrégation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "22beb3ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SK_ID_CURR</th>\n",
       "      <th>credit_card_balance_MONTHS_BALANCE_count</th>\n",
       "      <th>credit_card_balance_MONTHS_BALANCE_mean</th>\n",
       "      <th>credit_card_balance_MONTHS_BALANCE_max</th>\n",
       "      <th>credit_card_balance_MONTHS_BALANCE_min</th>\n",
       "      <th>credit_card_balance_MONTHS_BALANCE_sum</th>\n",
       "      <th>credit_card_balance_AMT_BALANCE_count</th>\n",
       "      <th>credit_card_balance_AMT_BALANCE_mean</th>\n",
       "      <th>credit_card_balance_AMT_BALANCE_max</th>\n",
       "      <th>credit_card_balance_AMT_BALANCE_min</th>\n",
       "      <th>...</th>\n",
       "      <th>credit_card_balance_SK_DPD_count</th>\n",
       "      <th>credit_card_balance_SK_DPD_mean</th>\n",
       "      <th>credit_card_balance_SK_DPD_max</th>\n",
       "      <th>credit_card_balance_SK_DPD_min</th>\n",
       "      <th>credit_card_balance_SK_DPD_sum</th>\n",
       "      <th>credit_card_balance_SK_DPD_DEF_count</th>\n",
       "      <th>credit_card_balance_SK_DPD_DEF_mean</th>\n",
       "      <th>credit_card_balance_SK_DPD_DEF_max</th>\n",
       "      <th>credit_card_balance_SK_DPD_DEF_min</th>\n",
       "      <th>credit_card_balance_SK_DPD_DEF_sum</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100006</td>\n",
       "      <td>6</td>\n",
       "      <td>-3.5</td>\n",
       "      <td>-1</td>\n",
       "      <td>-6</td>\n",
       "      <td>-21</td>\n",
       "      <td>6</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100011</td>\n",
       "      <td>74</td>\n",
       "      <td>-38.5</td>\n",
       "      <td>-2</td>\n",
       "      <td>-75</td>\n",
       "      <td>-2849</td>\n",
       "      <td>74</td>\n",
       "      <td>54482.111149</td>\n",
       "      <td>189000.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>74</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>74</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100013</td>\n",
       "      <td>96</td>\n",
       "      <td>-48.5</td>\n",
       "      <td>-1</td>\n",
       "      <td>-96</td>\n",
       "      <td>-4656</td>\n",
       "      <td>96</td>\n",
       "      <td>18159.919219</td>\n",
       "      <td>161420.220</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>96</td>\n",
       "      <td>0.010417</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>96</td>\n",
       "      <td>0.010417</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100021</td>\n",
       "      <td>17</td>\n",
       "      <td>-10.0</td>\n",
       "      <td>-2</td>\n",
       "      <td>-18</td>\n",
       "      <td>-170</td>\n",
       "      <td>17</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>17</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>100023</td>\n",
       "      <td>8</td>\n",
       "      <td>-7.5</td>\n",
       "      <td>-4</td>\n",
       "      <td>-11</td>\n",
       "      <td>-60</td>\n",
       "      <td>8</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>8</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103553</th>\n",
       "      <td>456244</td>\n",
       "      <td>41</td>\n",
       "      <td>-21.0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-41</td>\n",
       "      <td>-861</td>\n",
       "      <td>41</td>\n",
       "      <td>131834.730732</td>\n",
       "      <td>453627.675</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>41</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>41</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103554</th>\n",
       "      <td>456246</td>\n",
       "      <td>8</td>\n",
       "      <td>-5.5</td>\n",
       "      <td>-2</td>\n",
       "      <td>-9</td>\n",
       "      <td>-44</td>\n",
       "      <td>8</td>\n",
       "      <td>13136.731875</td>\n",
       "      <td>43490.115</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>8</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103555</th>\n",
       "      <td>456247</td>\n",
       "      <td>95</td>\n",
       "      <td>-49.0</td>\n",
       "      <td>-2</td>\n",
       "      <td>-96</td>\n",
       "      <td>-4655</td>\n",
       "      <td>95</td>\n",
       "      <td>23216.396211</td>\n",
       "      <td>190202.130</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>95</td>\n",
       "      <td>0.031579</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>95</td>\n",
       "      <td>0.021053</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103556</th>\n",
       "      <td>456248</td>\n",
       "      <td>23</td>\n",
       "      <td>-13.0</td>\n",
       "      <td>-2</td>\n",
       "      <td>-24</td>\n",
       "      <td>-299</td>\n",
       "      <td>23</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>23</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103557</th>\n",
       "      <td>456250</td>\n",
       "      <td>12</td>\n",
       "      <td>-6.5</td>\n",
       "      <td>-1</td>\n",
       "      <td>-12</td>\n",
       "      <td>-78</td>\n",
       "      <td>12</td>\n",
       "      <td>173589.326250</td>\n",
       "      <td>200208.915</td>\n",
       "      <td>153832.725</td>\n",
       "      <td>...</td>\n",
       "      <td>12</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>103558 rows × 101 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        SK_ID_CURR  credit_card_balance_MONTHS_BALANCE_count   \n",
       "0           100006                                         6  \\\n",
       "1           100011                                        74   \n",
       "2           100013                                        96   \n",
       "3           100021                                        17   \n",
       "4           100023                                         8   \n",
       "...            ...                                       ...   \n",
       "103553      456244                                        41   \n",
       "103554      456246                                         8   \n",
       "103555      456247                                        95   \n",
       "103556      456248                                        23   \n",
       "103557      456250                                        12   \n",
       "\n",
       "        credit_card_balance_MONTHS_BALANCE_mean   \n",
       "0                                          -3.5  \\\n",
       "1                                         -38.5   \n",
       "2                                         -48.5   \n",
       "3                                         -10.0   \n",
       "4                                          -7.5   \n",
       "...                                         ...   \n",
       "103553                                    -21.0   \n",
       "103554                                     -5.5   \n",
       "103555                                    -49.0   \n",
       "103556                                    -13.0   \n",
       "103557                                     -6.5   \n",
       "\n",
       "        credit_card_balance_MONTHS_BALANCE_max   \n",
       "0                                           -1  \\\n",
       "1                                           -2   \n",
       "2                                           -1   \n",
       "3                                           -2   \n",
       "4                                           -4   \n",
       "...                                        ...   \n",
       "103553                                      -1   \n",
       "103554                                      -2   \n",
       "103555                                      -2   \n",
       "103556                                      -2   \n",
       "103557                                      -1   \n",
       "\n",
       "        credit_card_balance_MONTHS_BALANCE_min   \n",
       "0                                           -6  \\\n",
       "1                                          -75   \n",
       "2                                          -96   \n",
       "3                                          -18   \n",
       "4                                          -11   \n",
       "...                                        ...   \n",
       "103553                                     -41   \n",
       "103554                                      -9   \n",
       "103555                                     -96   \n",
       "103556                                     -24   \n",
       "103557                                     -12   \n",
       "\n",
       "        credit_card_balance_MONTHS_BALANCE_sum   \n",
       "0                                          -21  \\\n",
       "1                                        -2849   \n",
       "2                                        -4656   \n",
       "3                                         -170   \n",
       "4                                          -60   \n",
       "...                                        ...   \n",
       "103553                                    -861   \n",
       "103554                                     -44   \n",
       "103555                                   -4655   \n",
       "103556                                    -299   \n",
       "103557                                     -78   \n",
       "\n",
       "        credit_card_balance_AMT_BALANCE_count   \n",
       "0                                           6  \\\n",
       "1                                          74   \n",
       "2                                          96   \n",
       "3                                          17   \n",
       "4                                           8   \n",
       "...                                       ...   \n",
       "103553                                     41   \n",
       "103554                                      8   \n",
       "103555                                     95   \n",
       "103556                                     23   \n",
       "103557                                     12   \n",
       "\n",
       "        credit_card_balance_AMT_BALANCE_mean   \n",
       "0                                   0.000000  \\\n",
       "1                               54482.111149   \n",
       "2                               18159.919219   \n",
       "3                                   0.000000   \n",
       "4                                   0.000000   \n",
       "...                                      ...   \n",
       "103553                         131834.730732   \n",
       "103554                          13136.731875   \n",
       "103555                          23216.396211   \n",
       "103556                              0.000000   \n",
       "103557                         173589.326250   \n",
       "\n",
       "        credit_card_balance_AMT_BALANCE_max   \n",
       "0                                     0.000  \\\n",
       "1                                189000.000   \n",
       "2                                161420.220   \n",
       "3                                     0.000   \n",
       "4                                     0.000   \n",
       "...                                     ...   \n",
       "103553                           453627.675   \n",
       "103554                            43490.115   \n",
       "103555                           190202.130   \n",
       "103556                                0.000   \n",
       "103557                           200208.915   \n",
       "\n",
       "        credit_card_balance_AMT_BALANCE_min  ...   \n",
       "0                                     0.000  ...  \\\n",
       "1                                     0.000  ...   \n",
       "2                                     0.000  ...   \n",
       "3                                     0.000  ...   \n",
       "4                                     0.000  ...   \n",
       "...                                     ...  ...   \n",
       "103553                                0.000  ...   \n",
       "103554                                0.000  ...   \n",
       "103555                                0.000  ...   \n",
       "103556                                0.000  ...   \n",
       "103557                           153832.725  ...   \n",
       "\n",
       "        credit_card_balance_SK_DPD_count  credit_card_balance_SK_DPD_mean   \n",
       "0                                      6                         0.000000  \\\n",
       "1                                     74                         0.000000   \n",
       "2                                     96                         0.010417   \n",
       "3                                     17                         0.000000   \n",
       "4                                      8                         0.000000   \n",
       "...                                  ...                              ...   \n",
       "103553                                41                         0.000000   \n",
       "103554                                 8                         0.000000   \n",
       "103555                                95                         0.031579   \n",
       "103556                                23                         0.000000   \n",
       "103557                                12                         0.000000   \n",
       "\n",
       "        credit_card_balance_SK_DPD_max  credit_card_balance_SK_DPD_min   \n",
       "0                                    0                               0  \\\n",
       "1                                    0                               0   \n",
       "2                                    1                               0   \n",
       "3                                    0                               0   \n",
       "4                                    0                               0   \n",
       "...                                ...                             ...   \n",
       "103553                               0                               0   \n",
       "103554                               0                               0   \n",
       "103555                               1                               0   \n",
       "103556                               0                               0   \n",
       "103557                               0                               0   \n",
       "\n",
       "        credit_card_balance_SK_DPD_sum  credit_card_balance_SK_DPD_DEF_count   \n",
       "0                                    0                                     6  \\\n",
       "1                                    0                                    74   \n",
       "2                                    1                                    96   \n",
       "3                                    0                                    17   \n",
       "4                                    0                                     8   \n",
       "...                                ...                                   ...   \n",
       "103553                               0                                    41   \n",
       "103554                               0                                     8   \n",
       "103555                               3                                    95   \n",
       "103556                               0                                    23   \n",
       "103557                               0                                    12   \n",
       "\n",
       "        credit_card_balance_SK_DPD_DEF_mean   \n",
       "0                                  0.000000  \\\n",
       "1                                  0.000000   \n",
       "2                                  0.010417   \n",
       "3                                  0.000000   \n",
       "4                                  0.000000   \n",
       "...                                     ...   \n",
       "103553                             0.000000   \n",
       "103554                             0.000000   \n",
       "103555                             0.021053   \n",
       "103556                             0.000000   \n",
       "103557                             0.000000   \n",
       "\n",
       "        credit_card_balance_SK_DPD_DEF_max   \n",
       "0                                        0  \\\n",
       "1                                        0   \n",
       "2                                        1   \n",
       "3                                        0   \n",
       "4                                        0   \n",
       "...                                    ...   \n",
       "103553                                   0   \n",
       "103554                                   0   \n",
       "103555                                   1   \n",
       "103556                                   0   \n",
       "103557                                   0   \n",
       "\n",
       "        credit_card_balance_SK_DPD_DEF_min  credit_card_balance_SK_DPD_DEF_sum  \n",
       "0                                        0                                   0  \n",
       "1                                        0                                   0  \n",
       "2                                        0                                   1  \n",
       "3                                        0                                   0  \n",
       "4                                        0                                   0  \n",
       "...                                    ...                                 ...  \n",
       "103553                                   0                                   0  \n",
       "103554                                   0                                   0  \n",
       "103555                                   0                                   2  \n",
       "103556                                   0                                   0  \n",
       "103557                                   0                                   0  \n",
       "\n",
       "[103558 rows x 101 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "credit_card_balance_num_agg_SK_ID_CURR = agg_numeric(credit_card_balance.drop(columns=['SK_ID_PREV']), group_var='SK_ID_CURR', df_name='credit_card_balance')\n",
    "credit_card_balance_num_agg_SK_ID_CURR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9b38332e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>credit_card_balance_NAME_CONTRACT_STATUS_Active_count</th>\n",
       "      <th>credit_card_balance_NAME_CONTRACT_STATUS_Active_count_norm</th>\n",
       "      <th>credit_card_balance_NAME_CONTRACT_STATUS_Approved_count</th>\n",
       "      <th>credit_card_balance_NAME_CONTRACT_STATUS_Approved_count_norm</th>\n",
       "      <th>credit_card_balance_NAME_CONTRACT_STATUS_Completed_count</th>\n",
       "      <th>credit_card_balance_NAME_CONTRACT_STATUS_Completed_count_norm</th>\n",
       "      <th>credit_card_balance_NAME_CONTRACT_STATUS_Demand_count</th>\n",
       "      <th>credit_card_balance_NAME_CONTRACT_STATUS_Demand_count_norm</th>\n",
       "      <th>credit_card_balance_NAME_CONTRACT_STATUS_Refused_count</th>\n",
       "      <th>credit_card_balance_NAME_CONTRACT_STATUS_Refused_count_norm</th>\n",
       "      <th>credit_card_balance_NAME_CONTRACT_STATUS_Sent proposal_count</th>\n",
       "      <th>credit_card_balance_NAME_CONTRACT_STATUS_Sent proposal_count_norm</th>\n",
       "      <th>credit_card_balance_NAME_CONTRACT_STATUS_Signed_count</th>\n",
       "      <th>credit_card_balance_NAME_CONTRACT_STATUS_Signed_count_norm</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SK_ID_CURR</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>100006</th>\n",
       "      <td>6</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100011</th>\n",
       "      <td>74</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100013</th>\n",
       "      <td>96</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100021</th>\n",
       "      <td>7</td>\n",
       "      <td>0.411765</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10</td>\n",
       "      <td>0.588235</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100023</th>\n",
       "      <td>8</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>456244</th>\n",
       "      <td>36</td>\n",
       "      <td>0.878049</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "      <td>0.121951</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>456246</th>\n",
       "      <td>8</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>456247</th>\n",
       "      <td>95</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>456248</th>\n",
       "      <td>23</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>456250</th>\n",
       "      <td>12</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>103558 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            credit_card_balance_NAME_CONTRACT_STATUS_Active_count   \n",
       "SK_ID_CURR                                                          \n",
       "100006                                                          6  \\\n",
       "100011                                                         74   \n",
       "100013                                                         96   \n",
       "100021                                                          7   \n",
       "100023                                                          8   \n",
       "...                                                           ...   \n",
       "456244                                                         36   \n",
       "456246                                                          8   \n",
       "456247                                                         95   \n",
       "456248                                                         23   \n",
       "456250                                                         12   \n",
       "\n",
       "            credit_card_balance_NAME_CONTRACT_STATUS_Active_count_norm   \n",
       "SK_ID_CURR                                                               \n",
       "100006                                                        1.000000  \\\n",
       "100011                                                        1.000000   \n",
       "100013                                                        1.000000   \n",
       "100021                                                        0.411765   \n",
       "100023                                                        1.000000   \n",
       "...                                                                ...   \n",
       "456244                                                        0.878049   \n",
       "456246                                                        1.000000   \n",
       "456247                                                        1.000000   \n",
       "456248                                                        1.000000   \n",
       "456250                                                        1.000000   \n",
       "\n",
       "            credit_card_balance_NAME_CONTRACT_STATUS_Approved_count   \n",
       "SK_ID_CURR                                                            \n",
       "100006                                                            0  \\\n",
       "100011                                                            0   \n",
       "100013                                                            0   \n",
       "100021                                                            0   \n",
       "100023                                                            0   \n",
       "...                                                             ...   \n",
       "456244                                                            0   \n",
       "456246                                                            0   \n",
       "456247                                                            0   \n",
       "456248                                                            0   \n",
       "456250                                                            0   \n",
       "\n",
       "            credit_card_balance_NAME_CONTRACT_STATUS_Approved_count_norm   \n",
       "SK_ID_CURR                                                                 \n",
       "100006                                                               0.0  \\\n",
       "100011                                                               0.0   \n",
       "100013                                                               0.0   \n",
       "100021                                                               0.0   \n",
       "100023                                                               0.0   \n",
       "...                                                                  ...   \n",
       "456244                                                               0.0   \n",
       "456246                                                               0.0   \n",
       "456247                                                               0.0   \n",
       "456248                                                               0.0   \n",
       "456250                                                               0.0   \n",
       "\n",
       "            credit_card_balance_NAME_CONTRACT_STATUS_Completed_count   \n",
       "SK_ID_CURR                                                             \n",
       "100006                                                             0  \\\n",
       "100011                                                             0   \n",
       "100013                                                             0   \n",
       "100021                                                            10   \n",
       "100023                                                             0   \n",
       "...                                                              ...   \n",
       "456244                                                             5   \n",
       "456246                                                             0   \n",
       "456247                                                             0   \n",
       "456248                                                             0   \n",
       "456250                                                             0   \n",
       "\n",
       "            credit_card_balance_NAME_CONTRACT_STATUS_Completed_count_norm   \n",
       "SK_ID_CURR                                                                  \n",
       "100006                                                           0.000000  \\\n",
       "100011                                                           0.000000   \n",
       "100013                                                           0.000000   \n",
       "100021                                                           0.588235   \n",
       "100023                                                           0.000000   \n",
       "...                                                                   ...   \n",
       "456244                                                           0.121951   \n",
       "456246                                                           0.000000   \n",
       "456247                                                           0.000000   \n",
       "456248                                                           0.000000   \n",
       "456250                                                           0.000000   \n",
       "\n",
       "            credit_card_balance_NAME_CONTRACT_STATUS_Demand_count   \n",
       "SK_ID_CURR                                                          \n",
       "100006                                                          0  \\\n",
       "100011                                                          0   \n",
       "100013                                                          0   \n",
       "100021                                                          0   \n",
       "100023                                                          0   \n",
       "...                                                           ...   \n",
       "456244                                                          0   \n",
       "456246                                                          0   \n",
       "456247                                                          0   \n",
       "456248                                                          0   \n",
       "456250                                                          0   \n",
       "\n",
       "            credit_card_balance_NAME_CONTRACT_STATUS_Demand_count_norm   \n",
       "SK_ID_CURR                                                               \n",
       "100006                                                             0.0  \\\n",
       "100011                                                             0.0   \n",
       "100013                                                             0.0   \n",
       "100021                                                             0.0   \n",
       "100023                                                             0.0   \n",
       "...                                                                ...   \n",
       "456244                                                             0.0   \n",
       "456246                                                             0.0   \n",
       "456247                                                             0.0   \n",
       "456248                                                             0.0   \n",
       "456250                                                             0.0   \n",
       "\n",
       "            credit_card_balance_NAME_CONTRACT_STATUS_Refused_count   \n",
       "SK_ID_CURR                                                           \n",
       "100006                                                           0  \\\n",
       "100011                                                           0   \n",
       "100013                                                           0   \n",
       "100021                                                           0   \n",
       "100023                                                           0   \n",
       "...                                                            ...   \n",
       "456244                                                           0   \n",
       "456246                                                           0   \n",
       "456247                                                           0   \n",
       "456248                                                           0   \n",
       "456250                                                           0   \n",
       "\n",
       "            credit_card_balance_NAME_CONTRACT_STATUS_Refused_count_norm   \n",
       "SK_ID_CURR                                                                \n",
       "100006                                                              0.0  \\\n",
       "100011                                                              0.0   \n",
       "100013                                                              0.0   \n",
       "100021                                                              0.0   \n",
       "100023                                                              0.0   \n",
       "...                                                                 ...   \n",
       "456244                                                              0.0   \n",
       "456246                                                              0.0   \n",
       "456247                                                              0.0   \n",
       "456248                                                              0.0   \n",
       "456250                                                              0.0   \n",
       "\n",
       "            credit_card_balance_NAME_CONTRACT_STATUS_Sent proposal_count   \n",
       "SK_ID_CURR                                                                 \n",
       "100006                                                                 0  \\\n",
       "100011                                                                 0   \n",
       "100013                                                                 0   \n",
       "100021                                                                 0   \n",
       "100023                                                                 0   \n",
       "...                                                                  ...   \n",
       "456244                                                                 0   \n",
       "456246                                                                 0   \n",
       "456247                                                                 0   \n",
       "456248                                                                 0   \n",
       "456250                                                                 0   \n",
       "\n",
       "            credit_card_balance_NAME_CONTRACT_STATUS_Sent proposal_count_norm   \n",
       "SK_ID_CURR                                                                      \n",
       "100006                                                                    0.0  \\\n",
       "100011                                                                    0.0   \n",
       "100013                                                                    0.0   \n",
       "100021                                                                    0.0   \n",
       "100023                                                                    0.0   \n",
       "...                                                                       ...   \n",
       "456244                                                                    0.0   \n",
       "456246                                                                    0.0   \n",
       "456247                                                                    0.0   \n",
       "456248                                                                    0.0   \n",
       "456250                                                                    0.0   \n",
       "\n",
       "            credit_card_balance_NAME_CONTRACT_STATUS_Signed_count   \n",
       "SK_ID_CURR                                                          \n",
       "100006                                                          0  \\\n",
       "100011                                                          0   \n",
       "100013                                                          0   \n",
       "100021                                                          0   \n",
       "100023                                                          0   \n",
       "...                                                           ...   \n",
       "456244                                                          0   \n",
       "456246                                                          0   \n",
       "456247                                                          0   \n",
       "456248                                                          0   \n",
       "456250                                                          0   \n",
       "\n",
       "            credit_card_balance_NAME_CONTRACT_STATUS_Signed_count_norm  \n",
       "SK_ID_CURR                                                              \n",
       "100006                                                             0.0  \n",
       "100011                                                             0.0  \n",
       "100013                                                             0.0  \n",
       "100021                                                             0.0  \n",
       "100023                                                             0.0  \n",
       "...                                                                ...  \n",
       "456244                                                             0.0  \n",
       "456246                                                             0.0  \n",
       "456247                                                             0.0  \n",
       "456248                                                             0.0  \n",
       "456250                                                             0.0  \n",
       "\n",
       "[103558 rows x 14 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "credit_card_balance_cat_agg_SK_ID_CURR = count_categorical(credit_card_balance.drop(columns=['SK_ID_PREV']), group_var='SK_ID_CURR', df_name='credit_card_balance')\n",
    "credit_card_balance_cat_agg_SK_ID_CURR"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61c1ca65",
   "metadata": {},
   "source": [
    "### Feature names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "bf4f9b6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# credit_card_balance_num_agg_SK_ID_CURR and credit_card_balance_cat_agg_SK_ID_CURR"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "070b795a",
   "metadata": {},
   "source": [
    "## Aggrégation de installments_payments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd7bb265",
   "metadata": {},
   "source": [
    "### Overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "23bc3a49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SK_ID_PREV</th>\n",
       "      <th>SK_ID_CURR</th>\n",
       "      <th>NUM_INSTALMENT_VERSION</th>\n",
       "      <th>NUM_INSTALMENT_NUMBER</th>\n",
       "      <th>DAYS_INSTALMENT</th>\n",
       "      <th>DAYS_ENTRY_PAYMENT</th>\n",
       "      <th>AMT_INSTALMENT</th>\n",
       "      <th>AMT_PAYMENT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1054186</td>\n",
       "      <td>161674</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6</td>\n",
       "      <td>-1180.0</td>\n",
       "      <td>-1187.0</td>\n",
       "      <td>6948.360</td>\n",
       "      <td>6948.360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1330831</td>\n",
       "      <td>151639</td>\n",
       "      <td>0.0</td>\n",
       "      <td>34</td>\n",
       "      <td>-2156.0</td>\n",
       "      <td>-2156.0</td>\n",
       "      <td>1716.525</td>\n",
       "      <td>1716.525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2085231</td>\n",
       "      <td>193053</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>-63.0</td>\n",
       "      <td>-63.0</td>\n",
       "      <td>25425.000</td>\n",
       "      <td>25425.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2452527</td>\n",
       "      <td>199697</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "      <td>-2418.0</td>\n",
       "      <td>-2426.0</td>\n",
       "      <td>24350.130</td>\n",
       "      <td>24350.130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2714724</td>\n",
       "      <td>167756</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>-1383.0</td>\n",
       "      <td>-1366.0</td>\n",
       "      <td>2165.040</td>\n",
       "      <td>2160.585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13605396</th>\n",
       "      <td>2186857</td>\n",
       "      <td>428057</td>\n",
       "      <td>0.0</td>\n",
       "      <td>66</td>\n",
       "      <td>-1624.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>67.500</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13605397</th>\n",
       "      <td>1310347</td>\n",
       "      <td>414406</td>\n",
       "      <td>0.0</td>\n",
       "      <td>47</td>\n",
       "      <td>-1539.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>67.500</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13605398</th>\n",
       "      <td>1308766</td>\n",
       "      <td>402199</td>\n",
       "      <td>0.0</td>\n",
       "      <td>43</td>\n",
       "      <td>-7.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>43737.435</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13605399</th>\n",
       "      <td>1062206</td>\n",
       "      <td>409297</td>\n",
       "      <td>0.0</td>\n",
       "      <td>43</td>\n",
       "      <td>-1986.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>67.500</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13605400</th>\n",
       "      <td>2448869</td>\n",
       "      <td>434321</td>\n",
       "      <td>1.0</td>\n",
       "      <td>19</td>\n",
       "      <td>-27.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11504.250</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>13605401 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          SK_ID_PREV  SK_ID_CURR  NUM_INSTALMENT_VERSION   \n",
       "0            1054186      161674                     1.0  \\\n",
       "1            1330831      151639                     0.0   \n",
       "2            2085231      193053                     2.0   \n",
       "3            2452527      199697                     1.0   \n",
       "4            2714724      167756                     1.0   \n",
       "...              ...         ...                     ...   \n",
       "13605396     2186857      428057                     0.0   \n",
       "13605397     1310347      414406                     0.0   \n",
       "13605398     1308766      402199                     0.0   \n",
       "13605399     1062206      409297                     0.0   \n",
       "13605400     2448869      434321                     1.0   \n",
       "\n",
       "          NUM_INSTALMENT_NUMBER  DAYS_INSTALMENT  DAYS_ENTRY_PAYMENT   \n",
       "0                             6          -1180.0             -1187.0  \\\n",
       "1                            34          -2156.0             -2156.0   \n",
       "2                             1            -63.0               -63.0   \n",
       "3                             3          -2418.0             -2426.0   \n",
       "4                             2          -1383.0             -1366.0   \n",
       "...                         ...              ...                 ...   \n",
       "13605396                     66          -1624.0                 NaN   \n",
       "13605397                     47          -1539.0                 NaN   \n",
       "13605398                     43             -7.0                 NaN   \n",
       "13605399                     43          -1986.0                 NaN   \n",
       "13605400                     19            -27.0                 NaN   \n",
       "\n",
       "          AMT_INSTALMENT  AMT_PAYMENT  \n",
       "0               6948.360     6948.360  \n",
       "1               1716.525     1716.525  \n",
       "2              25425.000    25425.000  \n",
       "3              24350.130    24350.130  \n",
       "4               2165.040     2160.585  \n",
       "...                  ...          ...  \n",
       "13605396          67.500          NaN  \n",
       "13605397          67.500          NaN  \n",
       "13605398       43737.435          NaN  \n",
       "13605399          67.500          NaN  \n",
       "13605400       11504.250          NaN  \n",
       "\n",
       "[13605401 rows x 8 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "installments_payments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e284dbb",
   "metadata": {},
   "source": [
    "### Aggrégation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "fb791d9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SK_ID_CURR</th>\n",
       "      <th>credit_card_balance_NUM_INSTALMENT_VERSION_count</th>\n",
       "      <th>credit_card_balance_NUM_INSTALMENT_VERSION_mean</th>\n",
       "      <th>credit_card_balance_NUM_INSTALMENT_VERSION_max</th>\n",
       "      <th>credit_card_balance_NUM_INSTALMENT_VERSION_min</th>\n",
       "      <th>credit_card_balance_NUM_INSTALMENT_VERSION_sum</th>\n",
       "      <th>credit_card_balance_NUM_INSTALMENT_NUMBER_count</th>\n",
       "      <th>credit_card_balance_NUM_INSTALMENT_NUMBER_mean</th>\n",
       "      <th>credit_card_balance_NUM_INSTALMENT_NUMBER_max</th>\n",
       "      <th>credit_card_balance_NUM_INSTALMENT_NUMBER_min</th>\n",
       "      <th>...</th>\n",
       "      <th>credit_card_balance_AMT_INSTALMENT_count</th>\n",
       "      <th>credit_card_balance_AMT_INSTALMENT_mean</th>\n",
       "      <th>credit_card_balance_AMT_INSTALMENT_max</th>\n",
       "      <th>credit_card_balance_AMT_INSTALMENT_min</th>\n",
       "      <th>credit_card_balance_AMT_INSTALMENT_sum</th>\n",
       "      <th>credit_card_balance_AMT_PAYMENT_count</th>\n",
       "      <th>credit_card_balance_AMT_PAYMENT_mean</th>\n",
       "      <th>credit_card_balance_AMT_PAYMENT_max</th>\n",
       "      <th>credit_card_balance_AMT_PAYMENT_min</th>\n",
       "      <th>credit_card_balance_AMT_PAYMENT_sum</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100001</td>\n",
       "      <td>7</td>\n",
       "      <td>1.142857</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>7</td>\n",
       "      <td>2.714286</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>5885.132143</td>\n",
       "      <td>17397.900</td>\n",
       "      <td>3951.000</td>\n",
       "      <td>41195.925</td>\n",
       "      <td>7</td>\n",
       "      <td>5885.132143</td>\n",
       "      <td>17397.900</td>\n",
       "      <td>3951.000</td>\n",
       "      <td>41195.925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100002</td>\n",
       "      <td>19</td>\n",
       "      <td>1.052632</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>19</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>19</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>19</td>\n",
       "      <td>11559.247105</td>\n",
       "      <td>53093.745</td>\n",
       "      <td>9251.775</td>\n",
       "      <td>219625.695</td>\n",
       "      <td>19</td>\n",
       "      <td>11559.247105</td>\n",
       "      <td>53093.745</td>\n",
       "      <td>9251.775</td>\n",
       "      <td>219625.695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100003</td>\n",
       "      <td>25</td>\n",
       "      <td>1.040000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>25</td>\n",
       "      <td>5.080000</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>25</td>\n",
       "      <td>64754.586000</td>\n",
       "      <td>560835.360</td>\n",
       "      <td>6662.970</td>\n",
       "      <td>1618864.650</td>\n",
       "      <td>25</td>\n",
       "      <td>64754.586000</td>\n",
       "      <td>560835.360</td>\n",
       "      <td>6662.970</td>\n",
       "      <td>1618864.650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100004</td>\n",
       "      <td>3</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>7096.155000</td>\n",
       "      <td>10573.965</td>\n",
       "      <td>5357.250</td>\n",
       "      <td>21288.465</td>\n",
       "      <td>3</td>\n",
       "      <td>7096.155000</td>\n",
       "      <td>10573.965</td>\n",
       "      <td>5357.250</td>\n",
       "      <td>21288.465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>100005</td>\n",
       "      <td>9</td>\n",
       "      <td>1.111111</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>9</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>9</td>\n",
       "      <td>6240.205000</td>\n",
       "      <td>17656.245</td>\n",
       "      <td>4813.200</td>\n",
       "      <td>56161.845</td>\n",
       "      <td>9</td>\n",
       "      <td>6240.205000</td>\n",
       "      <td>17656.245</td>\n",
       "      <td>4813.200</td>\n",
       "      <td>56161.845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>339582</th>\n",
       "      <td>456251</td>\n",
       "      <td>7</td>\n",
       "      <td>1.142857</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>7</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>7492.924286</td>\n",
       "      <td>12815.010</td>\n",
       "      <td>6605.910</td>\n",
       "      <td>52450.470</td>\n",
       "      <td>7</td>\n",
       "      <td>7492.924286</td>\n",
       "      <td>12815.010</td>\n",
       "      <td>6605.910</td>\n",
       "      <td>52450.470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>339583</th>\n",
       "      <td>456252</td>\n",
       "      <td>6</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>10069.867500</td>\n",
       "      <td>10074.465</td>\n",
       "      <td>10046.880</td>\n",
       "      <td>60419.205</td>\n",
       "      <td>6</td>\n",
       "      <td>10069.867500</td>\n",
       "      <td>10074.465</td>\n",
       "      <td>10046.880</td>\n",
       "      <td>60419.205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>339584</th>\n",
       "      <td>456253</td>\n",
       "      <td>14</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>14</td>\n",
       "      <td>4.785714</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>14</td>\n",
       "      <td>4399.707857</td>\n",
       "      <td>5575.185</td>\n",
       "      <td>2754.450</td>\n",
       "      <td>61595.910</td>\n",
       "      <td>14</td>\n",
       "      <td>4115.915357</td>\n",
       "      <td>5575.185</td>\n",
       "      <td>27.270</td>\n",
       "      <td>57622.815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>339585</th>\n",
       "      <td>456254</td>\n",
       "      <td>19</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>19</td>\n",
       "      <td>5.263158</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>19</td>\n",
       "      <td>10239.832895</td>\n",
       "      <td>19065.825</td>\n",
       "      <td>2296.440</td>\n",
       "      <td>194556.825</td>\n",
       "      <td>19</td>\n",
       "      <td>10239.832895</td>\n",
       "      <td>19065.825</td>\n",
       "      <td>2296.440</td>\n",
       "      <td>194556.825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>339586</th>\n",
       "      <td>456255</td>\n",
       "      <td>74</td>\n",
       "      <td>1.824324</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>135.0</td>\n",
       "      <td>74</td>\n",
       "      <td>8.851351</td>\n",
       "      <td>24</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>74</td>\n",
       "      <td>41464.713649</td>\n",
       "      <td>615229.515</td>\n",
       "      <td>11090.835</td>\n",
       "      <td>3068388.810</td>\n",
       "      <td>74</td>\n",
       "      <td>47646.215878</td>\n",
       "      <td>669251.655</td>\n",
       "      <td>34.965</td>\n",
       "      <td>3525819.975</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>339587 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        SK_ID_CURR  credit_card_balance_NUM_INSTALMENT_VERSION_count   \n",
       "0           100001                                                 7  \\\n",
       "1           100002                                                19   \n",
       "2           100003                                                25   \n",
       "3           100004                                                 3   \n",
       "4           100005                                                 9   \n",
       "...            ...                                               ...   \n",
       "339582      456251                                                 7   \n",
       "339583      456252                                                 6   \n",
       "339584      456253                                                14   \n",
       "339585      456254                                                19   \n",
       "339586      456255                                                74   \n",
       "\n",
       "        credit_card_balance_NUM_INSTALMENT_VERSION_mean   \n",
       "0                                              1.142857  \\\n",
       "1                                              1.052632   \n",
       "2                                              1.040000   \n",
       "3                                              1.333333   \n",
       "4                                              1.111111   \n",
       "...                                                 ...   \n",
       "339582                                         1.142857   \n",
       "339583                                         1.000000   \n",
       "339584                                         1.000000   \n",
       "339585                                         1.000000   \n",
       "339586                                         1.824324   \n",
       "\n",
       "        credit_card_balance_NUM_INSTALMENT_VERSION_max   \n",
       "0                                                  2.0  \\\n",
       "1                                                  2.0   \n",
       "2                                                  2.0   \n",
       "3                                                  2.0   \n",
       "4                                                  2.0   \n",
       "...                                                ...   \n",
       "339582                                             2.0   \n",
       "339583                                             1.0   \n",
       "339584                                             1.0   \n",
       "339585                                             1.0   \n",
       "339586                                             4.0   \n",
       "\n",
       "        credit_card_balance_NUM_INSTALMENT_VERSION_min   \n",
       "0                                                  1.0  \\\n",
       "1                                                  1.0   \n",
       "2                                                  1.0   \n",
       "3                                                  1.0   \n",
       "4                                                  1.0   \n",
       "...                                                ...   \n",
       "339582                                             1.0   \n",
       "339583                                             1.0   \n",
       "339584                                             1.0   \n",
       "339585                                             1.0   \n",
       "339586                                             1.0   \n",
       "\n",
       "        credit_card_balance_NUM_INSTALMENT_VERSION_sum   \n",
       "0                                                  8.0  \\\n",
       "1                                                 20.0   \n",
       "2                                                 26.0   \n",
       "3                                                  4.0   \n",
       "4                                                 10.0   \n",
       "...                                                ...   \n",
       "339582                                             8.0   \n",
       "339583                                             6.0   \n",
       "339584                                            14.0   \n",
       "339585                                            19.0   \n",
       "339586                                           135.0   \n",
       "\n",
       "        credit_card_balance_NUM_INSTALMENT_NUMBER_count   \n",
       "0                                                     7  \\\n",
       "1                                                    19   \n",
       "2                                                    25   \n",
       "3                                                     3   \n",
       "4                                                     9   \n",
       "...                                                 ...   \n",
       "339582                                                7   \n",
       "339583                                                6   \n",
       "339584                                               14   \n",
       "339585                                               19   \n",
       "339586                                               74   \n",
       "\n",
       "        credit_card_balance_NUM_INSTALMENT_NUMBER_mean   \n",
       "0                                             2.714286  \\\n",
       "1                                            10.000000   \n",
       "2                                             5.080000   \n",
       "3                                             2.000000   \n",
       "4                                             5.000000   \n",
       "...                                                ...   \n",
       "339582                                        4.000000   \n",
       "339583                                        3.500000   \n",
       "339584                                        4.785714   \n",
       "339585                                        5.263158   \n",
       "339586                                        8.851351   \n",
       "\n",
       "        credit_card_balance_NUM_INSTALMENT_NUMBER_max   \n",
       "0                                                   4  \\\n",
       "1                                                  19   \n",
       "2                                                  12   \n",
       "3                                                   3   \n",
       "4                                                   9   \n",
       "...                                               ...   \n",
       "339582                                              7   \n",
       "339583                                              6   \n",
       "339584                                             12   \n",
       "339585                                             10   \n",
       "339586                                             24   \n",
       "\n",
       "        credit_card_balance_NUM_INSTALMENT_NUMBER_min  ...   \n",
       "0                                                   1  ...  \\\n",
       "1                                                   1  ...   \n",
       "2                                                   1  ...   \n",
       "3                                                   1  ...   \n",
       "4                                                   1  ...   \n",
       "...                                               ...  ...   \n",
       "339582                                              1  ...   \n",
       "339583                                              1  ...   \n",
       "339584                                              1  ...   \n",
       "339585                                              1  ...   \n",
       "339586                                              1  ...   \n",
       "\n",
       "        credit_card_balance_AMT_INSTALMENT_count   \n",
       "0                                              7  \\\n",
       "1                                             19   \n",
       "2                                             25   \n",
       "3                                              3   \n",
       "4                                              9   \n",
       "...                                          ...   \n",
       "339582                                         7   \n",
       "339583                                         6   \n",
       "339584                                        14   \n",
       "339585                                        19   \n",
       "339586                                        74   \n",
       "\n",
       "        credit_card_balance_AMT_INSTALMENT_mean   \n",
       "0                                   5885.132143  \\\n",
       "1                                  11559.247105   \n",
       "2                                  64754.586000   \n",
       "3                                   7096.155000   \n",
       "4                                   6240.205000   \n",
       "...                                         ...   \n",
       "339582                              7492.924286   \n",
       "339583                             10069.867500   \n",
       "339584                              4399.707857   \n",
       "339585                             10239.832895   \n",
       "339586                             41464.713649   \n",
       "\n",
       "        credit_card_balance_AMT_INSTALMENT_max   \n",
       "0                                    17397.900  \\\n",
       "1                                    53093.745   \n",
       "2                                   560835.360   \n",
       "3                                    10573.965   \n",
       "4                                    17656.245   \n",
       "...                                        ...   \n",
       "339582                               12815.010   \n",
       "339583                               10074.465   \n",
       "339584                                5575.185   \n",
       "339585                               19065.825   \n",
       "339586                              615229.515   \n",
       "\n",
       "        credit_card_balance_AMT_INSTALMENT_min   \n",
       "0                                     3951.000  \\\n",
       "1                                     9251.775   \n",
       "2                                     6662.970   \n",
       "3                                     5357.250   \n",
       "4                                     4813.200   \n",
       "...                                        ...   \n",
       "339582                                6605.910   \n",
       "339583                               10046.880   \n",
       "339584                                2754.450   \n",
       "339585                                2296.440   \n",
       "339586                               11090.835   \n",
       "\n",
       "        credit_card_balance_AMT_INSTALMENT_sum   \n",
       "0                                    41195.925  \\\n",
       "1                                   219625.695   \n",
       "2                                  1618864.650   \n",
       "3                                    21288.465   \n",
       "4                                    56161.845   \n",
       "...                                        ...   \n",
       "339582                               52450.470   \n",
       "339583                               60419.205   \n",
       "339584                               61595.910   \n",
       "339585                              194556.825   \n",
       "339586                             3068388.810   \n",
       "\n",
       "        credit_card_balance_AMT_PAYMENT_count   \n",
       "0                                           7  \\\n",
       "1                                          19   \n",
       "2                                          25   \n",
       "3                                           3   \n",
       "4                                           9   \n",
       "...                                       ...   \n",
       "339582                                      7   \n",
       "339583                                      6   \n",
       "339584                                     14   \n",
       "339585                                     19   \n",
       "339586                                     74   \n",
       "\n",
       "        credit_card_balance_AMT_PAYMENT_mean   \n",
       "0                                5885.132143  \\\n",
       "1                               11559.247105   \n",
       "2                               64754.586000   \n",
       "3                                7096.155000   \n",
       "4                                6240.205000   \n",
       "...                                      ...   \n",
       "339582                           7492.924286   \n",
       "339583                          10069.867500   \n",
       "339584                           4115.915357   \n",
       "339585                          10239.832895   \n",
       "339586                          47646.215878   \n",
       "\n",
       "        credit_card_balance_AMT_PAYMENT_max   \n",
       "0                                 17397.900  \\\n",
       "1                                 53093.745   \n",
       "2                                560835.360   \n",
       "3                                 10573.965   \n",
       "4                                 17656.245   \n",
       "...                                     ...   \n",
       "339582                            12815.010   \n",
       "339583                            10074.465   \n",
       "339584                             5575.185   \n",
       "339585                            19065.825   \n",
       "339586                           669251.655   \n",
       "\n",
       "        credit_card_balance_AMT_PAYMENT_min   \n",
       "0                                  3951.000  \\\n",
       "1                                  9251.775   \n",
       "2                                  6662.970   \n",
       "3                                  5357.250   \n",
       "4                                  4813.200   \n",
       "...                                     ...   \n",
       "339582                             6605.910   \n",
       "339583                            10046.880   \n",
       "339584                               27.270   \n",
       "339585                             2296.440   \n",
       "339586                               34.965   \n",
       "\n",
       "        credit_card_balance_AMT_PAYMENT_sum  \n",
       "0                                 41195.925  \n",
       "1                                219625.695  \n",
       "2                               1618864.650  \n",
       "3                                 21288.465  \n",
       "4                                 56161.845  \n",
       "...                                     ...  \n",
       "339582                            52450.470  \n",
       "339583                            60419.205  \n",
       "339584                            57622.815  \n",
       "339585                           194556.825  \n",
       "339586                          3525819.975  \n",
       "\n",
       "[339587 rows x 31 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "installments_payments_num_agg_SK_ID_CURR = agg_numeric(installments_payments.drop(columns=['SK_ID_PREV']), group_var='SK_ID_CURR', df_name='credit_card_balance')\n",
    "installments_payments_num_agg_SK_ID_CURR"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cec825ca",
   "metadata": {},
   "source": [
    "### Feature names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1b12def0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# installments_payments_num_agg_SK_ID_CURR"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8b9b8c0",
   "metadata": {},
   "source": [
    "## Merge des DataFrames"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dad9f89",
   "metadata": {},
   "source": [
    "Le plus long est installments_payments_num_agg_SK_ID_CURR et étant donné que l'on va réaliser des merge left on va commencer par celui ci pour ne pas perdre de données."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62eb1348",
   "metadata": {},
   "source": [
    "## Liste DataFrames à merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4da55551",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs_to_merge = [installments_payments_num_agg_SK_ID_CURR, \n",
    "                previous_application_num_agg_SK_ID_CURR, previous_application_cat_agg_SK_ID_CURR, \n",
    "                POS_CASH_balance_num_agg_SK_ID_CURR, POS_CASH_balance_cat_agg_SK_ID_CURR, \n",
    "                credit_card_balance_num_agg_SK_ID_CURR, credit_card_balance_cat_agg_SK_ID_CURR]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "384b55a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 339587 entries, 0 to 339586\n",
      "Columns: 569 entries, SK_ID_CURR to credit_card_balance_NAME_CONTRACT_STATUS_Signed_count_norm\n",
      "dtypes: float64(559), int64(10)\n",
      "memory usage: 1.4 GB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "merge_key = 'SK_ID_CURR'\n",
    "\n",
    "merge_function = lambda left_df, right_df: pd.merge(left_df, right_df, on=merge_key, how='left')\n",
    "features_func_from_last_four = reduce(merge_function, dfs_to_merge)\n",
    "\n",
    "print(features_func_from_last_four.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "87ad17d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SK_ID_CURR</th>\n",
       "      <th>credit_card_balance_NUM_INSTALMENT_VERSION_count</th>\n",
       "      <th>credit_card_balance_NUM_INSTALMENT_VERSION_mean</th>\n",
       "      <th>credit_card_balance_NUM_INSTALMENT_VERSION_max</th>\n",
       "      <th>credit_card_balance_NUM_INSTALMENT_VERSION_min</th>\n",
       "      <th>credit_card_balance_NUM_INSTALMENT_VERSION_sum</th>\n",
       "      <th>credit_card_balance_NUM_INSTALMENT_NUMBER_count</th>\n",
       "      <th>credit_card_balance_NUM_INSTALMENT_NUMBER_mean</th>\n",
       "      <th>credit_card_balance_NUM_INSTALMENT_NUMBER_max</th>\n",
       "      <th>credit_card_balance_NUM_INSTALMENT_NUMBER_min</th>\n",
       "      <th>...</th>\n",
       "      <th>credit_card_balance_NAME_CONTRACT_STATUS_Completed_count</th>\n",
       "      <th>credit_card_balance_NAME_CONTRACT_STATUS_Completed_count_norm</th>\n",
       "      <th>credit_card_balance_NAME_CONTRACT_STATUS_Demand_count</th>\n",
       "      <th>credit_card_balance_NAME_CONTRACT_STATUS_Demand_count_norm</th>\n",
       "      <th>credit_card_balance_NAME_CONTRACT_STATUS_Refused_count</th>\n",
       "      <th>credit_card_balance_NAME_CONTRACT_STATUS_Refused_count_norm</th>\n",
       "      <th>credit_card_balance_NAME_CONTRACT_STATUS_Sent proposal_count</th>\n",
       "      <th>credit_card_balance_NAME_CONTRACT_STATUS_Sent proposal_count_norm</th>\n",
       "      <th>credit_card_balance_NAME_CONTRACT_STATUS_Signed_count</th>\n",
       "      <th>credit_card_balance_NAME_CONTRACT_STATUS_Signed_count_norm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100001</td>\n",
       "      <td>7</td>\n",
       "      <td>1.142857</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>7</td>\n",
       "      <td>2.714286</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100002</td>\n",
       "      <td>19</td>\n",
       "      <td>1.052632</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>19</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>19</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100003</td>\n",
       "      <td>25</td>\n",
       "      <td>1.040000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>25</td>\n",
       "      <td>5.080000</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100004</td>\n",
       "      <td>3</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>100005</td>\n",
       "      <td>9</td>\n",
       "      <td>1.111111</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>9</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>339582</th>\n",
       "      <td>456251</td>\n",
       "      <td>7</td>\n",
       "      <td>1.142857</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>7</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>339583</th>\n",
       "      <td>456252</td>\n",
       "      <td>6</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>339584</th>\n",
       "      <td>456253</td>\n",
       "      <td>14</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>14</td>\n",
       "      <td>4.785714</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>339585</th>\n",
       "      <td>456254</td>\n",
       "      <td>19</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>19</td>\n",
       "      <td>5.263158</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>339586</th>\n",
       "      <td>456255</td>\n",
       "      <td>74</td>\n",
       "      <td>1.824324</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>135.0</td>\n",
       "      <td>74</td>\n",
       "      <td>8.851351</td>\n",
       "      <td>24</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>339587 rows × 569 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        SK_ID_CURR  credit_card_balance_NUM_INSTALMENT_VERSION_count   \n",
       "0           100001                                                 7  \\\n",
       "1           100002                                                19   \n",
       "2           100003                                                25   \n",
       "3           100004                                                 3   \n",
       "4           100005                                                 9   \n",
       "...            ...                                               ...   \n",
       "339582      456251                                                 7   \n",
       "339583      456252                                                 6   \n",
       "339584      456253                                                14   \n",
       "339585      456254                                                19   \n",
       "339586      456255                                                74   \n",
       "\n",
       "        credit_card_balance_NUM_INSTALMENT_VERSION_mean   \n",
       "0                                              1.142857  \\\n",
       "1                                              1.052632   \n",
       "2                                              1.040000   \n",
       "3                                              1.333333   \n",
       "4                                              1.111111   \n",
       "...                                                 ...   \n",
       "339582                                         1.142857   \n",
       "339583                                         1.000000   \n",
       "339584                                         1.000000   \n",
       "339585                                         1.000000   \n",
       "339586                                         1.824324   \n",
       "\n",
       "        credit_card_balance_NUM_INSTALMENT_VERSION_max   \n",
       "0                                                  2.0  \\\n",
       "1                                                  2.0   \n",
       "2                                                  2.0   \n",
       "3                                                  2.0   \n",
       "4                                                  2.0   \n",
       "...                                                ...   \n",
       "339582                                             2.0   \n",
       "339583                                             1.0   \n",
       "339584                                             1.0   \n",
       "339585                                             1.0   \n",
       "339586                                             4.0   \n",
       "\n",
       "        credit_card_balance_NUM_INSTALMENT_VERSION_min   \n",
       "0                                                  1.0  \\\n",
       "1                                                  1.0   \n",
       "2                                                  1.0   \n",
       "3                                                  1.0   \n",
       "4                                                  1.0   \n",
       "...                                                ...   \n",
       "339582                                             1.0   \n",
       "339583                                             1.0   \n",
       "339584                                             1.0   \n",
       "339585                                             1.0   \n",
       "339586                                             1.0   \n",
       "\n",
       "        credit_card_balance_NUM_INSTALMENT_VERSION_sum   \n",
       "0                                                  8.0  \\\n",
       "1                                                 20.0   \n",
       "2                                                 26.0   \n",
       "3                                                  4.0   \n",
       "4                                                 10.0   \n",
       "...                                                ...   \n",
       "339582                                             8.0   \n",
       "339583                                             6.0   \n",
       "339584                                            14.0   \n",
       "339585                                            19.0   \n",
       "339586                                           135.0   \n",
       "\n",
       "        credit_card_balance_NUM_INSTALMENT_NUMBER_count   \n",
       "0                                                     7  \\\n",
       "1                                                    19   \n",
       "2                                                    25   \n",
       "3                                                     3   \n",
       "4                                                     9   \n",
       "...                                                 ...   \n",
       "339582                                                7   \n",
       "339583                                                6   \n",
       "339584                                               14   \n",
       "339585                                               19   \n",
       "339586                                               74   \n",
       "\n",
       "        credit_card_balance_NUM_INSTALMENT_NUMBER_mean   \n",
       "0                                             2.714286  \\\n",
       "1                                            10.000000   \n",
       "2                                             5.080000   \n",
       "3                                             2.000000   \n",
       "4                                             5.000000   \n",
       "...                                                ...   \n",
       "339582                                        4.000000   \n",
       "339583                                        3.500000   \n",
       "339584                                        4.785714   \n",
       "339585                                        5.263158   \n",
       "339586                                        8.851351   \n",
       "\n",
       "        credit_card_balance_NUM_INSTALMENT_NUMBER_max   \n",
       "0                                                   4  \\\n",
       "1                                                  19   \n",
       "2                                                  12   \n",
       "3                                                   3   \n",
       "4                                                   9   \n",
       "...                                               ...   \n",
       "339582                                              7   \n",
       "339583                                              6   \n",
       "339584                                             12   \n",
       "339585                                             10   \n",
       "339586                                             24   \n",
       "\n",
       "        credit_card_balance_NUM_INSTALMENT_NUMBER_min  ...   \n",
       "0                                                   1  ...  \\\n",
       "1                                                   1  ...   \n",
       "2                                                   1  ...   \n",
       "3                                                   1  ...   \n",
       "4                                                   1  ...   \n",
       "...                                               ...  ...   \n",
       "339582                                              1  ...   \n",
       "339583                                              1  ...   \n",
       "339584                                              1  ...   \n",
       "339585                                              1  ...   \n",
       "339586                                              1  ...   \n",
       "\n",
       "        credit_card_balance_NAME_CONTRACT_STATUS_Completed_count   \n",
       "0                                                            NaN  \\\n",
       "1                                                            NaN   \n",
       "2                                                            NaN   \n",
       "3                                                            NaN   \n",
       "4                                                            NaN   \n",
       "...                                                          ...   \n",
       "339582                                                       NaN   \n",
       "339583                                                       NaN   \n",
       "339584                                                       NaN   \n",
       "339585                                                       NaN   \n",
       "339586                                                       NaN   \n",
       "\n",
       "        credit_card_balance_NAME_CONTRACT_STATUS_Completed_count_norm   \n",
       "0                                                                 NaN  \\\n",
       "1                                                                 NaN   \n",
       "2                                                                 NaN   \n",
       "3                                                                 NaN   \n",
       "4                                                                 NaN   \n",
       "...                                                               ...   \n",
       "339582                                                            NaN   \n",
       "339583                                                            NaN   \n",
       "339584                                                            NaN   \n",
       "339585                                                            NaN   \n",
       "339586                                                            NaN   \n",
       "\n",
       "        credit_card_balance_NAME_CONTRACT_STATUS_Demand_count   \n",
       "0                                                         NaN  \\\n",
       "1                                                         NaN   \n",
       "2                                                         NaN   \n",
       "3                                                         NaN   \n",
       "4                                                         NaN   \n",
       "...                                                       ...   \n",
       "339582                                                    NaN   \n",
       "339583                                                    NaN   \n",
       "339584                                                    NaN   \n",
       "339585                                                    NaN   \n",
       "339586                                                    NaN   \n",
       "\n",
       "        credit_card_balance_NAME_CONTRACT_STATUS_Demand_count_norm   \n",
       "0                                                              NaN  \\\n",
       "1                                                              NaN   \n",
       "2                                                              NaN   \n",
       "3                                                              NaN   \n",
       "4                                                              NaN   \n",
       "...                                                            ...   \n",
       "339582                                                         NaN   \n",
       "339583                                                         NaN   \n",
       "339584                                                         NaN   \n",
       "339585                                                         NaN   \n",
       "339586                                                         NaN   \n",
       "\n",
       "        credit_card_balance_NAME_CONTRACT_STATUS_Refused_count   \n",
       "0                                                          NaN  \\\n",
       "1                                                          NaN   \n",
       "2                                                          NaN   \n",
       "3                                                          NaN   \n",
       "4                                                          NaN   \n",
       "...                                                        ...   \n",
       "339582                                                     NaN   \n",
       "339583                                                     NaN   \n",
       "339584                                                     NaN   \n",
       "339585                                                     NaN   \n",
       "339586                                                     NaN   \n",
       "\n",
       "        credit_card_balance_NAME_CONTRACT_STATUS_Refused_count_norm   \n",
       "0                                                               NaN  \\\n",
       "1                                                               NaN   \n",
       "2                                                               NaN   \n",
       "3                                                               NaN   \n",
       "4                                                               NaN   \n",
       "...                                                             ...   \n",
       "339582                                                          NaN   \n",
       "339583                                                          NaN   \n",
       "339584                                                          NaN   \n",
       "339585                                                          NaN   \n",
       "339586                                                          NaN   \n",
       "\n",
       "        credit_card_balance_NAME_CONTRACT_STATUS_Sent proposal_count   \n",
       "0                                                                NaN  \\\n",
       "1                                                                NaN   \n",
       "2                                                                NaN   \n",
       "3                                                                NaN   \n",
       "4                                                                NaN   \n",
       "...                                                              ...   \n",
       "339582                                                           NaN   \n",
       "339583                                                           NaN   \n",
       "339584                                                           NaN   \n",
       "339585                                                           NaN   \n",
       "339586                                                           NaN   \n",
       "\n",
       "        credit_card_balance_NAME_CONTRACT_STATUS_Sent proposal_count_norm   \n",
       "0                                                                     NaN  \\\n",
       "1                                                                     NaN   \n",
       "2                                                                     NaN   \n",
       "3                                                                     NaN   \n",
       "4                                                                     NaN   \n",
       "...                                                                   ...   \n",
       "339582                                                                NaN   \n",
       "339583                                                                NaN   \n",
       "339584                                                                NaN   \n",
       "339585                                                                NaN   \n",
       "339586                                                                NaN   \n",
       "\n",
       "        credit_card_balance_NAME_CONTRACT_STATUS_Signed_count   \n",
       "0                                                         NaN  \\\n",
       "1                                                         NaN   \n",
       "2                                                         NaN   \n",
       "3                                                         NaN   \n",
       "4                                                         NaN   \n",
       "...                                                       ...   \n",
       "339582                                                    NaN   \n",
       "339583                                                    NaN   \n",
       "339584                                                    NaN   \n",
       "339585                                                    NaN   \n",
       "339586                                                    NaN   \n",
       "\n",
       "        credit_card_balance_NAME_CONTRACT_STATUS_Signed_count_norm  \n",
       "0                                                              NaN  \n",
       "1                                                              NaN  \n",
       "2                                                              NaN  \n",
       "3                                                              NaN  \n",
       "4                                                              NaN  \n",
       "...                                                            ...  \n",
       "339582                                                         NaN  \n",
       "339583                                                         NaN  \n",
       "339584                                                         NaN  \n",
       "339585                                                         NaN  \n",
       "339586                                                         NaN  \n",
       "\n",
       "[339587 rows x 569 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_func_from_last_four"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a1a575c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>SK_ID_CURR</th>\n",
       "      <th>NAME_CONTRACT_TYPE</th>\n",
       "      <th>FLAG_OWN_CAR</th>\n",
       "      <th>FLAG_OWN_REALTY</th>\n",
       "      <th>CNT_CHILDREN</th>\n",
       "      <th>AMT_INCOME_TOTAL</th>\n",
       "      <th>AMT_CREDIT</th>\n",
       "      <th>AMT_ANNUITY</th>\n",
       "      <th>AMT_GOODS_PRICE</th>\n",
       "      <th>...</th>\n",
       "      <th>client_bureau_balance_LOAN_TYPE_Long Term_count</th>\n",
       "      <th>client_bureau_balance_LOAN_TYPE_Long Term_mean</th>\n",
       "      <th>client_bureau_balance_LOAN_TYPE_Long Term_max</th>\n",
       "      <th>client_bureau_balance_LOAN_TYPE_Long Term_min</th>\n",
       "      <th>client_bureau_balance_LOAN_TYPE_Long Term_sum</th>\n",
       "      <th>client_bureau_balance_LOAN_TYPE_Short Term_count</th>\n",
       "      <th>client_bureau_balance_LOAN_TYPE_Short Term_mean</th>\n",
       "      <th>client_bureau_balance_LOAN_TYPE_Short Term_max</th>\n",
       "      <th>client_bureau_balance_LOAN_TYPE_Short Term_min</th>\n",
       "      <th>client_bureau_balance_LOAN_TYPE_Short Term_sum</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>100002</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>202500.0</td>\n",
       "      <td>406597.5</td>\n",
       "      <td>24700.5</td>\n",
       "      <td>351000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>100003</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>270000.0</td>\n",
       "      <td>1293502.5</td>\n",
       "      <td>35698.5</td>\n",
       "      <td>1129500.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>100004</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>67500.0</td>\n",
       "      <td>135000.0</td>\n",
       "      <td>6750.0</td>\n",
       "      <td>135000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>100006</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>135000.0</td>\n",
       "      <td>312682.5</td>\n",
       "      <td>29686.5</td>\n",
       "      <td>297000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>100007</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>121500.0</td>\n",
       "      <td>513000.0</td>\n",
       "      <td>21865.5</td>\n",
       "      <td>513000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>307506</th>\n",
       "      <td>307506</td>\n",
       "      <td>456251</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>157500.0</td>\n",
       "      <td>254700.0</td>\n",
       "      <td>27558.0</td>\n",
       "      <td>225000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>307507</th>\n",
       "      <td>307507</td>\n",
       "      <td>456252</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>72000.0</td>\n",
       "      <td>269550.0</td>\n",
       "      <td>12001.5</td>\n",
       "      <td>225000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>307508</th>\n",
       "      <td>307508</td>\n",
       "      <td>456253</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>153000.0</td>\n",
       "      <td>677664.0</td>\n",
       "      <td>29979.0</td>\n",
       "      <td>585000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>307509</th>\n",
       "      <td>307509</td>\n",
       "      <td>456254</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>171000.0</td>\n",
       "      <td>370107.0</td>\n",
       "      <td>20205.0</td>\n",
       "      <td>319500.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>307510</th>\n",
       "      <td>307510</td>\n",
       "      <td>456255</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>157500.0</td>\n",
       "      <td>675000.0</td>\n",
       "      <td>49117.5</td>\n",
       "      <td>675000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.181818</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>307511 rows × 574 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Unnamed: 0  SK_ID_CURR  NAME_CONTRACT_TYPE  FLAG_OWN_CAR   \n",
       "0                0      100002                   0             0  \\\n",
       "1                1      100003                   0             0   \n",
       "2                2      100004                   1             1   \n",
       "3                3      100006                   0             0   \n",
       "4                4      100007                   0             0   \n",
       "...            ...         ...                 ...           ...   \n",
       "307506      307506      456251                   0             0   \n",
       "307507      307507      456252                   0             0   \n",
       "307508      307508      456253                   0             0   \n",
       "307509      307509      456254                   0             0   \n",
       "307510      307510      456255                   0             0   \n",
       "\n",
       "        FLAG_OWN_REALTY  CNT_CHILDREN  AMT_INCOME_TOTAL  AMT_CREDIT   \n",
       "0                     1             0          202500.0    406597.5  \\\n",
       "1                     0             0          270000.0   1293502.5   \n",
       "2                     1             0           67500.0    135000.0   \n",
       "3                     1             0          135000.0    312682.5   \n",
       "4                     1             0          121500.0    513000.0   \n",
       "...                 ...           ...               ...         ...   \n",
       "307506                0             0          157500.0    254700.0   \n",
       "307507                1             0           72000.0    269550.0   \n",
       "307508                1             0          153000.0    677664.0   \n",
       "307509                1             0          171000.0    370107.0   \n",
       "307510                0             0          157500.0    675000.0   \n",
       "\n",
       "        AMT_ANNUITY  AMT_GOODS_PRICE  ...   \n",
       "0           24700.5         351000.0  ...  \\\n",
       "1           35698.5        1129500.0  ...   \n",
       "2            6750.0         135000.0  ...   \n",
       "3           29686.5         297000.0  ...   \n",
       "4           21865.5         513000.0  ...   \n",
       "...             ...              ...  ...   \n",
       "307506      27558.0         225000.0  ...   \n",
       "307507      12001.5         225000.0  ...   \n",
       "307508      29979.0         585000.0  ...   \n",
       "307509      20205.0         319500.0  ...   \n",
       "307510      49117.5         675000.0  ...   \n",
       "\n",
       "        client_bureau_balance_LOAN_TYPE_Long Term_count   \n",
       "0                                                   8.0  \\\n",
       "1                                                   NaN   \n",
       "2                                                   NaN   \n",
       "3                                                   NaN   \n",
       "4                                                   NaN   \n",
       "...                                                 ...   \n",
       "307506                                              NaN   \n",
       "307507                                              NaN   \n",
       "307508                                              4.0   \n",
       "307509                                              1.0   \n",
       "307510                                             11.0   \n",
       "\n",
       "        client_bureau_balance_LOAN_TYPE_Long Term_mean   \n",
       "0                                             0.000000  \\\n",
       "1                                                  NaN   \n",
       "2                                                  NaN   \n",
       "3                                                  NaN   \n",
       "4                                                  NaN   \n",
       "...                                                ...   \n",
       "307506                                             NaN   \n",
       "307507                                             NaN   \n",
       "307508                                        0.000000   \n",
       "307509                                        0.000000   \n",
       "307510                                        0.181818   \n",
       "\n",
       "        client_bureau_balance_LOAN_TYPE_Long Term_max   \n",
       "0                                                 0.0  \\\n",
       "1                                                 NaN   \n",
       "2                                                 NaN   \n",
       "3                                                 NaN   \n",
       "4                                                 NaN   \n",
       "...                                               ...   \n",
       "307506                                            NaN   \n",
       "307507                                            NaN   \n",
       "307508                                            0.0   \n",
       "307509                                            0.0   \n",
       "307510                                            1.0   \n",
       "\n",
       "        client_bureau_balance_LOAN_TYPE_Long Term_min   \n",
       "0                                                 0.0  \\\n",
       "1                                                 NaN   \n",
       "2                                                 NaN   \n",
       "3                                                 NaN   \n",
       "4                                                 NaN   \n",
       "...                                               ...   \n",
       "307506                                            NaN   \n",
       "307507                                            NaN   \n",
       "307508                                            0.0   \n",
       "307509                                            0.0   \n",
       "307510                                            0.0   \n",
       "\n",
       "        client_bureau_balance_LOAN_TYPE_Long Term_sum   \n",
       "0                                                 0.0  \\\n",
       "1                                                 NaN   \n",
       "2                                                 NaN   \n",
       "3                                                 NaN   \n",
       "4                                                 NaN   \n",
       "...                                               ...   \n",
       "307506                                            NaN   \n",
       "307507                                            NaN   \n",
       "307508                                            0.0   \n",
       "307509                                            0.0   \n",
       "307510                                            2.0   \n",
       "\n",
       "        client_bureau_balance_LOAN_TYPE_Short Term_count   \n",
       "0                                                    8.0  \\\n",
       "1                                                    NaN   \n",
       "2                                                    NaN   \n",
       "3                                                    NaN   \n",
       "4                                                    NaN   \n",
       "...                                                  ...   \n",
       "307506                                               NaN   \n",
       "307507                                               NaN   \n",
       "307508                                               4.0   \n",
       "307509                                               1.0   \n",
       "307510                                              11.0   \n",
       "\n",
       "        client_bureau_balance_LOAN_TYPE_Short Term_mean   \n",
       "0                                              1.000000  \\\n",
       "1                                                   NaN   \n",
       "2                                                   NaN   \n",
       "3                                                   NaN   \n",
       "4                                                   NaN   \n",
       "...                                                 ...   \n",
       "307506                                              NaN   \n",
       "307507                                              NaN   \n",
       "307508                                         1.000000   \n",
       "307509                                         1.000000   \n",
       "307510                                         0.818182   \n",
       "\n",
       "        client_bureau_balance_LOAN_TYPE_Short Term_max   \n",
       "0                                                  1.0  \\\n",
       "1                                                  NaN   \n",
       "2                                                  NaN   \n",
       "3                                                  NaN   \n",
       "4                                                  NaN   \n",
       "...                                                ...   \n",
       "307506                                             NaN   \n",
       "307507                                             NaN   \n",
       "307508                                             1.0   \n",
       "307509                                             1.0   \n",
       "307510                                             1.0   \n",
       "\n",
       "        client_bureau_balance_LOAN_TYPE_Short Term_min   \n",
       "0                                                  1.0  \\\n",
       "1                                                  NaN   \n",
       "2                                                  NaN   \n",
       "3                                                  NaN   \n",
       "4                                                  NaN   \n",
       "...                                                ...   \n",
       "307506                                             NaN   \n",
       "307507                                             NaN   \n",
       "307508                                             1.0   \n",
       "307509                                             1.0   \n",
       "307510                                             0.0   \n",
       "\n",
       "        client_bureau_balance_LOAN_TYPE_Short Term_sum  \n",
       "0                                                  8.0  \n",
       "1                                                  NaN  \n",
       "2                                                  NaN  \n",
       "3                                                  NaN  \n",
       "4                                                  NaN  \n",
       "...                                                ...  \n",
       "307506                                             NaN  \n",
       "307507                                             NaN  \n",
       "307508                                             4.0  \n",
       "307509                                             1.0  \n",
       "307510                                             9.0  \n",
       "\n",
       "[307511 rows x 574 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_manual_and_func_from_first_three_with_app_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f4d4c2db",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_manual_and_func_from_first_three_with_app_train.drop(columns=['Unnamed: 0'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a400a78c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SK_ID_CURR</th>\n",
       "      <th>NAME_CONTRACT_TYPE</th>\n",
       "      <th>FLAG_OWN_CAR</th>\n",
       "      <th>FLAG_OWN_REALTY</th>\n",
       "      <th>CNT_CHILDREN</th>\n",
       "      <th>AMT_INCOME_TOTAL</th>\n",
       "      <th>AMT_CREDIT</th>\n",
       "      <th>AMT_ANNUITY</th>\n",
       "      <th>AMT_GOODS_PRICE</th>\n",
       "      <th>REGION_POPULATION_RELATIVE</th>\n",
       "      <th>...</th>\n",
       "      <th>credit_card_balance_NAME_CONTRACT_STATUS_Completed_count</th>\n",
       "      <th>credit_card_balance_NAME_CONTRACT_STATUS_Completed_count_norm</th>\n",
       "      <th>credit_card_balance_NAME_CONTRACT_STATUS_Demand_count</th>\n",
       "      <th>credit_card_balance_NAME_CONTRACT_STATUS_Demand_count_norm</th>\n",
       "      <th>credit_card_balance_NAME_CONTRACT_STATUS_Refused_count</th>\n",
       "      <th>credit_card_balance_NAME_CONTRACT_STATUS_Refused_count_norm</th>\n",
       "      <th>credit_card_balance_NAME_CONTRACT_STATUS_Sent proposal_count</th>\n",
       "      <th>credit_card_balance_NAME_CONTRACT_STATUS_Sent proposal_count_norm</th>\n",
       "      <th>credit_card_balance_NAME_CONTRACT_STATUS_Signed_count</th>\n",
       "      <th>credit_card_balance_NAME_CONTRACT_STATUS_Signed_count_norm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100002</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>202500.0</td>\n",
       "      <td>406597.5</td>\n",
       "      <td>24700.5</td>\n",
       "      <td>351000.0</td>\n",
       "      <td>0.018801</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100003</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>270000.0</td>\n",
       "      <td>1293502.5</td>\n",
       "      <td>35698.5</td>\n",
       "      <td>1129500.0</td>\n",
       "      <td>0.003541</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100004</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>67500.0</td>\n",
       "      <td>135000.0</td>\n",
       "      <td>6750.0</td>\n",
       "      <td>135000.0</td>\n",
       "      <td>0.010032</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100006</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>135000.0</td>\n",
       "      <td>312682.5</td>\n",
       "      <td>29686.5</td>\n",
       "      <td>297000.0</td>\n",
       "      <td>0.008019</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>100007</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>121500.0</td>\n",
       "      <td>513000.0</td>\n",
       "      <td>21865.5</td>\n",
       "      <td>513000.0</td>\n",
       "      <td>0.028663</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>307506</th>\n",
       "      <td>456251</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>157500.0</td>\n",
       "      <td>254700.0</td>\n",
       "      <td>27558.0</td>\n",
       "      <td>225000.0</td>\n",
       "      <td>0.032561</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>307507</th>\n",
       "      <td>456252</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>72000.0</td>\n",
       "      <td>269550.0</td>\n",
       "      <td>12001.5</td>\n",
       "      <td>225000.0</td>\n",
       "      <td>0.025164</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>307508</th>\n",
       "      <td>456253</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>153000.0</td>\n",
       "      <td>677664.0</td>\n",
       "      <td>29979.0</td>\n",
       "      <td>585000.0</td>\n",
       "      <td>0.005002</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>307509</th>\n",
       "      <td>456254</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>171000.0</td>\n",
       "      <td>370107.0</td>\n",
       "      <td>20205.0</td>\n",
       "      <td>319500.0</td>\n",
       "      <td>0.005313</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>307510</th>\n",
       "      <td>456255</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>157500.0</td>\n",
       "      <td>675000.0</td>\n",
       "      <td>49117.5</td>\n",
       "      <td>675000.0</td>\n",
       "      <td>0.046220</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>307511 rows × 1141 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        SK_ID_CURR  NAME_CONTRACT_TYPE  FLAG_OWN_CAR  FLAG_OWN_REALTY   \n",
       "0           100002                   0             0                1  \\\n",
       "1           100003                   0             0                0   \n",
       "2           100004                   1             1                1   \n",
       "3           100006                   0             0                1   \n",
       "4           100007                   0             0                1   \n",
       "...            ...                 ...           ...              ...   \n",
       "307506      456251                   0             0                0   \n",
       "307507      456252                   0             0                1   \n",
       "307508      456253                   0             0                1   \n",
       "307509      456254                   0             0                1   \n",
       "307510      456255                   0             0                0   \n",
       "\n",
       "        CNT_CHILDREN  AMT_INCOME_TOTAL  AMT_CREDIT  AMT_ANNUITY   \n",
       "0                  0          202500.0    406597.5      24700.5  \\\n",
       "1                  0          270000.0   1293502.5      35698.5   \n",
       "2                  0           67500.0    135000.0       6750.0   \n",
       "3                  0          135000.0    312682.5      29686.5   \n",
       "4                  0          121500.0    513000.0      21865.5   \n",
       "...              ...               ...         ...          ...   \n",
       "307506             0          157500.0    254700.0      27558.0   \n",
       "307507             0           72000.0    269550.0      12001.5   \n",
       "307508             0          153000.0    677664.0      29979.0   \n",
       "307509             0          171000.0    370107.0      20205.0   \n",
       "307510             0          157500.0    675000.0      49117.5   \n",
       "\n",
       "        AMT_GOODS_PRICE  REGION_POPULATION_RELATIVE  ...   \n",
       "0              351000.0                    0.018801  ...  \\\n",
       "1             1129500.0                    0.003541  ...   \n",
       "2              135000.0                    0.010032  ...   \n",
       "3              297000.0                    0.008019  ...   \n",
       "4              513000.0                    0.028663  ...   \n",
       "...                 ...                         ...  ...   \n",
       "307506         225000.0                    0.032561  ...   \n",
       "307507         225000.0                    0.025164  ...   \n",
       "307508         585000.0                    0.005002  ...   \n",
       "307509         319500.0                    0.005313  ...   \n",
       "307510         675000.0                    0.046220  ...   \n",
       "\n",
       "        credit_card_balance_NAME_CONTRACT_STATUS_Completed_count   \n",
       "0                                                            NaN  \\\n",
       "1                                                            NaN   \n",
       "2                                                            NaN   \n",
       "3                                                            0.0   \n",
       "4                                                            NaN   \n",
       "...                                                          ...   \n",
       "307506                                                       NaN   \n",
       "307507                                                       NaN   \n",
       "307508                                                       NaN   \n",
       "307509                                                       NaN   \n",
       "307510                                                       NaN   \n",
       "\n",
       "        credit_card_balance_NAME_CONTRACT_STATUS_Completed_count_norm   \n",
       "0                                                                 NaN  \\\n",
       "1                                                                 NaN   \n",
       "2                                                                 NaN   \n",
       "3                                                                 0.0   \n",
       "4                                                                 NaN   \n",
       "...                                                               ...   \n",
       "307506                                                            NaN   \n",
       "307507                                                            NaN   \n",
       "307508                                                            NaN   \n",
       "307509                                                            NaN   \n",
       "307510                                                            NaN   \n",
       "\n",
       "        credit_card_balance_NAME_CONTRACT_STATUS_Demand_count   \n",
       "0                                                         NaN  \\\n",
       "1                                                         NaN   \n",
       "2                                                         NaN   \n",
       "3                                                         0.0   \n",
       "4                                                         NaN   \n",
       "...                                                       ...   \n",
       "307506                                                    NaN   \n",
       "307507                                                    NaN   \n",
       "307508                                                    NaN   \n",
       "307509                                                    NaN   \n",
       "307510                                                    NaN   \n",
       "\n",
       "        credit_card_balance_NAME_CONTRACT_STATUS_Demand_count_norm   \n",
       "0                                                              NaN  \\\n",
       "1                                                              NaN   \n",
       "2                                                              NaN   \n",
       "3                                                              0.0   \n",
       "4                                                              NaN   \n",
       "...                                                            ...   \n",
       "307506                                                         NaN   \n",
       "307507                                                         NaN   \n",
       "307508                                                         NaN   \n",
       "307509                                                         NaN   \n",
       "307510                                                         NaN   \n",
       "\n",
       "        credit_card_balance_NAME_CONTRACT_STATUS_Refused_count   \n",
       "0                                                          NaN  \\\n",
       "1                                                          NaN   \n",
       "2                                                          NaN   \n",
       "3                                                          0.0   \n",
       "4                                                          NaN   \n",
       "...                                                        ...   \n",
       "307506                                                     NaN   \n",
       "307507                                                     NaN   \n",
       "307508                                                     NaN   \n",
       "307509                                                     NaN   \n",
       "307510                                                     NaN   \n",
       "\n",
       "        credit_card_balance_NAME_CONTRACT_STATUS_Refused_count_norm   \n",
       "0                                                               NaN  \\\n",
       "1                                                               NaN   \n",
       "2                                                               NaN   \n",
       "3                                                               0.0   \n",
       "4                                                               NaN   \n",
       "...                                                             ...   \n",
       "307506                                                          NaN   \n",
       "307507                                                          NaN   \n",
       "307508                                                          NaN   \n",
       "307509                                                          NaN   \n",
       "307510                                                          NaN   \n",
       "\n",
       "        credit_card_balance_NAME_CONTRACT_STATUS_Sent proposal_count   \n",
       "0                                                                NaN  \\\n",
       "1                                                                NaN   \n",
       "2                                                                NaN   \n",
       "3                                                                0.0   \n",
       "4                                                                NaN   \n",
       "...                                                              ...   \n",
       "307506                                                           NaN   \n",
       "307507                                                           NaN   \n",
       "307508                                                           NaN   \n",
       "307509                                                           NaN   \n",
       "307510                                                           NaN   \n",
       "\n",
       "        credit_card_balance_NAME_CONTRACT_STATUS_Sent proposal_count_norm   \n",
       "0                                                                     NaN  \\\n",
       "1                                                                     NaN   \n",
       "2                                                                     NaN   \n",
       "3                                                                     0.0   \n",
       "4                                                                     NaN   \n",
       "...                                                                   ...   \n",
       "307506                                                                NaN   \n",
       "307507                                                                NaN   \n",
       "307508                                                                NaN   \n",
       "307509                                                                NaN   \n",
       "307510                                                                NaN   \n",
       "\n",
       "        credit_card_balance_NAME_CONTRACT_STATUS_Signed_count   \n",
       "0                                                         NaN  \\\n",
       "1                                                         NaN   \n",
       "2                                                         NaN   \n",
       "3                                                         0.0   \n",
       "4                                                         NaN   \n",
       "...                                                       ...   \n",
       "307506                                                    NaN   \n",
       "307507                                                    NaN   \n",
       "307508                                                    NaN   \n",
       "307509                                                    NaN   \n",
       "307510                                                    NaN   \n",
       "\n",
       "        credit_card_balance_NAME_CONTRACT_STATUS_Signed_count_norm  \n",
       "0                                                              NaN  \n",
       "1                                                              NaN  \n",
       "2                                                              NaN  \n",
       "3                                                              0.0  \n",
       "4                                                              NaN  \n",
       "...                                                            ...  \n",
       "307506                                                         NaN  \n",
       "307507                                                         NaN  \n",
       "307508                                                         NaN  \n",
       "307509                                                         NaN  \n",
       "307510                                                         NaN  \n",
       "\n",
       "[307511 rows x 1141 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.merge(left=features_manual_and_func_from_first_three_with_app_train, right=features_func_from_last_four, how='left', on='SK_ID_CURR')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "12047b48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TARGET\n",
       "0    282686\n",
       "1     24825\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_data = pd.merge(left=features_manual_and_func_from_first_three_with_app_train, right=features_func_from_last_four, how='left', on='SK_ID_CURR')\n",
    "full_data['TARGET'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47b87f57",
   "metadata": {},
   "source": [
    "# Création de la fonction pour calculer la variable métier qui va nous permettre de comparer les modèles"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cd83308",
   "metadata": {},
   "source": [
    "On va supposer que le coût d'un FN est 10x supérieur au coût d'un FP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "2c81ae8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_business_cost(y_true, y_pred, cost_fn=10, cost_tn=(-1), cost_fp=1):\n",
    "    \"\"\"\n",
    "    Calculates the total business cost based on a confusion matrix.\n",
    "    Assumes class 1 is the positive class (default).\n",
    "    \"\"\"\n",
    "    tn, fp, fn, tp = confusion_matrix(y_true, y_pred, labels=[0, 1]).ravel()\n",
    "    total_cost = (fn * cost_fn) + (fp * cost_fp) + (tn * cost_tn)\n",
    "    return total_cost"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "744e1f18",
   "metadata": {},
   "source": [
    "The confusion_matrix returns a 2x2 NumPy array:\n",
    "[[TN, FP],\n",
    " [FN, TP]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "508210ae",
   "metadata": {},
   "source": [
    ".ravel(): This NumPy method flattens the 2x2 matrix into a 1D array: [TN, FP, FN, TP].\n",
    "tn, fp, fn, tp = ...: This unpacks the flattened array into individual variables."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81bd63b2",
   "metadata": {},
   "source": [
    "# Run LightGBM avec ce nouveau DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ea61b6fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Selection features et TARGET \n",
    "\n",
    "features_all = [col for col in full_data.columns if col not in ['TARGET', 'SK_ID_CURR']]\n",
    "X = full_data[features_all]\n",
    "y = full_data['TARGET']\n",
    "\n",
    "# --- Split data\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "aa2b57c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sanitizing final X_train and X_val column names...\n"
     ]
    }
   ],
   "source": [
    "def sanitize_lgbm_colname(colname):\n",
    "    \"\"\"More robust sanitization for LightGBM.\"\"\"\n",
    "    # Convert to string first\n",
    "    colname_str = str(colname)\n",
    "    # Replace common problematic characters (including ., ', etc.) with underscore\n",
    "    sanitized = re.sub(r'[\\[\\]{}\":\\',.<>\\s/?!@#$%^&*()+=-]+', '_', colname_str)\n",
    "    # Replace multiple underscores with single underscore\n",
    "    sanitized = re.sub(r'_+', '_', sanitized)\n",
    "    # Remove leading/trailing underscores\n",
    "    sanitized = sanitized.strip('_')\n",
    "    # Ensure it's not empty\n",
    "    if not sanitized:\n",
    "        sanitized = f\"col_{hash(colname_str)}\"\n",
    "    # Ensure it doesn't start with a number (optional, but good practice)\n",
    "    if sanitized[0].isdigit():\n",
    "        sanitized = '_' + sanitized\n",
    "    return sanitized\n",
    "\n",
    "# --- Apply Sanitization and Alignment ---\n",
    "print(\"Sanitizing final X_train and X_val column names...\")\n",
    "\n",
    "# --- Sanitize X_train ---\n",
    "original_train_cols = X_train.columns.tolist()\n",
    "new_train_cols = [sanitize_lgbm_colname(col) for col in original_train_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "2612bfbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.columns = new_train_cols\n",
    "X_val.columns = new_train_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "6c219813",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NAME_CONTRACT_TYPE</th>\n",
       "      <th>FLAG_OWN_CAR</th>\n",
       "      <th>FLAG_OWN_REALTY</th>\n",
       "      <th>CNT_CHILDREN</th>\n",
       "      <th>AMT_INCOME_TOTAL</th>\n",
       "      <th>AMT_CREDIT</th>\n",
       "      <th>AMT_ANNUITY</th>\n",
       "      <th>AMT_GOODS_PRICE</th>\n",
       "      <th>REGION_POPULATION_RELATIVE</th>\n",
       "      <th>DAYS_BIRTH</th>\n",
       "      <th>...</th>\n",
       "      <th>credit_card_balance_NAME_CONTRACT_STATUS_Completed_count</th>\n",
       "      <th>credit_card_balance_NAME_CONTRACT_STATUS_Completed_count_norm</th>\n",
       "      <th>credit_card_balance_NAME_CONTRACT_STATUS_Demand_count</th>\n",
       "      <th>credit_card_balance_NAME_CONTRACT_STATUS_Demand_count_norm</th>\n",
       "      <th>credit_card_balance_NAME_CONTRACT_STATUS_Refused_count</th>\n",
       "      <th>credit_card_balance_NAME_CONTRACT_STATUS_Refused_count_norm</th>\n",
       "      <th>credit_card_balance_NAME_CONTRACT_STATUS_Sent_proposal_count</th>\n",
       "      <th>credit_card_balance_NAME_CONTRACT_STATUS_Sent_proposal_count_norm</th>\n",
       "      <th>credit_card_balance_NAME_CONTRACT_STATUS_Signed_count</th>\n",
       "      <th>credit_card_balance_NAME_CONTRACT_STATUS_Signed_count_norm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>181648</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>90000.0</td>\n",
       "      <td>227520.0</td>\n",
       "      <td>13189.5</td>\n",
       "      <td>180000.0</td>\n",
       "      <td>0.008230</td>\n",
       "      <td>-12298</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>229245</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>90000.0</td>\n",
       "      <td>161730.0</td>\n",
       "      <td>13095.0</td>\n",
       "      <td>135000.0</td>\n",
       "      <td>0.003069</td>\n",
       "      <td>-15375</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122525</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>135000.0</td>\n",
       "      <td>728847.0</td>\n",
       "      <td>26307.0</td>\n",
       "      <td>553500.0</td>\n",
       "      <td>0.020713</td>\n",
       "      <td>-19307</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>306311</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>135000.0</td>\n",
       "      <td>474183.0</td>\n",
       "      <td>34636.5</td>\n",
       "      <td>391500.0</td>\n",
       "      <td>0.011703</td>\n",
       "      <td>-17791</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300658</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>180000.0</td>\n",
       "      <td>254700.0</td>\n",
       "      <td>27558.0</td>\n",
       "      <td>225000.0</td>\n",
       "      <td>0.006629</td>\n",
       "      <td>-8486</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31304</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>135000.0</td>\n",
       "      <td>405000.0</td>\n",
       "      <td>20250.0</td>\n",
       "      <td>405000.0</td>\n",
       "      <td>0.035792</td>\n",
       "      <td>-15374</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121193</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>157500.0</td>\n",
       "      <td>272520.0</td>\n",
       "      <td>21528.0</td>\n",
       "      <td>225000.0</td>\n",
       "      <td>0.018801</td>\n",
       "      <td>-19035</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>248504</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>90000.0</td>\n",
       "      <td>246357.0</td>\n",
       "      <td>24493.5</td>\n",
       "      <td>234000.0</td>\n",
       "      <td>0.025164</td>\n",
       "      <td>-23088</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175469</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>112500.0</td>\n",
       "      <td>810000.0</td>\n",
       "      <td>26901.0</td>\n",
       "      <td>810000.0</td>\n",
       "      <td>0.018209</td>\n",
       "      <td>-22148</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>285162</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>126000.0</td>\n",
       "      <td>1051245.0</td>\n",
       "      <td>27859.5</td>\n",
       "      <td>877500.0</td>\n",
       "      <td>0.018850</td>\n",
       "      <td>-22079</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>246008 rows × 1139 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        NAME_CONTRACT_TYPE  FLAG_OWN_CAR  FLAG_OWN_REALTY  CNT_CHILDREN   \n",
       "181648                   0             0                0             2  \\\n",
       "229245                   0             1                1             0   \n",
       "122525                   0             0                1             0   \n",
       "306311                   0             0                0             0   \n",
       "300658                   0             0                1             0   \n",
       "...                    ...           ...              ...           ...   \n",
       "31304                    1             0                1             1   \n",
       "121193                   0             0                0             0   \n",
       "248504                   0             0                0             0   \n",
       "175469                   0             0                1             0   \n",
       "285162                   0             1                1             0   \n",
       "\n",
       "        AMT_INCOME_TOTAL  AMT_CREDIT  AMT_ANNUITY  AMT_GOODS_PRICE   \n",
       "181648           90000.0    227520.0      13189.5         180000.0  \\\n",
       "229245           90000.0    161730.0      13095.0         135000.0   \n",
       "122525          135000.0    728847.0      26307.0         553500.0   \n",
       "306311          135000.0    474183.0      34636.5         391500.0   \n",
       "300658          180000.0    254700.0      27558.0         225000.0   \n",
       "...                  ...         ...          ...              ...   \n",
       "31304           135000.0    405000.0      20250.0         405000.0   \n",
       "121193          157500.0    272520.0      21528.0         225000.0   \n",
       "248504           90000.0    246357.0      24493.5         234000.0   \n",
       "175469          112500.0    810000.0      26901.0         810000.0   \n",
       "285162          126000.0   1051245.0      27859.5         877500.0   \n",
       "\n",
       "        REGION_POPULATION_RELATIVE  DAYS_BIRTH  ...   \n",
       "181648                    0.008230      -12298  ...  \\\n",
       "229245                    0.003069      -15375  ...   \n",
       "122525                    0.020713      -19307  ...   \n",
       "306311                    0.011703      -17791  ...   \n",
       "300658                    0.006629       -8486  ...   \n",
       "...                            ...         ...  ...   \n",
       "31304                     0.035792      -15374  ...   \n",
       "121193                    0.018801      -19035  ...   \n",
       "248504                    0.025164      -23088  ...   \n",
       "175469                    0.018209      -22148  ...   \n",
       "285162                    0.018850      -22079  ...   \n",
       "\n",
       "        credit_card_balance_NAME_CONTRACT_STATUS_Completed_count   \n",
       "181648                                                       0.0  \\\n",
       "229245                                                       NaN   \n",
       "122525                                                       NaN   \n",
       "306311                                                       NaN   \n",
       "300658                                                       NaN   \n",
       "...                                                          ...   \n",
       "31304                                                        NaN   \n",
       "121193                                                       0.0   \n",
       "248504                                                       NaN   \n",
       "175469                                                       NaN   \n",
       "285162                                                       0.0   \n",
       "\n",
       "        credit_card_balance_NAME_CONTRACT_STATUS_Completed_count_norm   \n",
       "181648                                                            0.0  \\\n",
       "229245                                                            NaN   \n",
       "122525                                                            NaN   \n",
       "306311                                                            NaN   \n",
       "300658                                                            NaN   \n",
       "...                                                               ...   \n",
       "31304                                                             NaN   \n",
       "121193                                                            0.0   \n",
       "248504                                                            NaN   \n",
       "175469                                                            NaN   \n",
       "285162                                                            0.0   \n",
       "\n",
       "        credit_card_balance_NAME_CONTRACT_STATUS_Demand_count   \n",
       "181648                                                    0.0  \\\n",
       "229245                                                    NaN   \n",
       "122525                                                    NaN   \n",
       "306311                                                    NaN   \n",
       "300658                                                    NaN   \n",
       "...                                                       ...   \n",
       "31304                                                     NaN   \n",
       "121193                                                    0.0   \n",
       "248504                                                    NaN   \n",
       "175469                                                    NaN   \n",
       "285162                                                    0.0   \n",
       "\n",
       "        credit_card_balance_NAME_CONTRACT_STATUS_Demand_count_norm   \n",
       "181648                                                         0.0  \\\n",
       "229245                                                         NaN   \n",
       "122525                                                         NaN   \n",
       "306311                                                         NaN   \n",
       "300658                                                         NaN   \n",
       "...                                                            ...   \n",
       "31304                                                          NaN   \n",
       "121193                                                         0.0   \n",
       "248504                                                         NaN   \n",
       "175469                                                         NaN   \n",
       "285162                                                         0.0   \n",
       "\n",
       "        credit_card_balance_NAME_CONTRACT_STATUS_Refused_count   \n",
       "181648                                                     0.0  \\\n",
       "229245                                                     NaN   \n",
       "122525                                                     NaN   \n",
       "306311                                                     NaN   \n",
       "300658                                                     NaN   \n",
       "...                                                        ...   \n",
       "31304                                                      NaN   \n",
       "121193                                                     0.0   \n",
       "248504                                                     NaN   \n",
       "175469                                                     NaN   \n",
       "285162                                                     0.0   \n",
       "\n",
       "        credit_card_balance_NAME_CONTRACT_STATUS_Refused_count_norm   \n",
       "181648                                                          0.0  \\\n",
       "229245                                                          NaN   \n",
       "122525                                                          NaN   \n",
       "306311                                                          NaN   \n",
       "300658                                                          NaN   \n",
       "...                                                             ...   \n",
       "31304                                                           NaN   \n",
       "121193                                                          0.0   \n",
       "248504                                                          NaN   \n",
       "175469                                                          NaN   \n",
       "285162                                                          0.0   \n",
       "\n",
       "        credit_card_balance_NAME_CONTRACT_STATUS_Sent_proposal_count   \n",
       "181648                                                           0.0  \\\n",
       "229245                                                           NaN   \n",
       "122525                                                           NaN   \n",
       "306311                                                           NaN   \n",
       "300658                                                           NaN   \n",
       "...                                                              ...   \n",
       "31304                                                            NaN   \n",
       "121193                                                           0.0   \n",
       "248504                                                           NaN   \n",
       "175469                                                           NaN   \n",
       "285162                                                           0.0   \n",
       "\n",
       "        credit_card_balance_NAME_CONTRACT_STATUS_Sent_proposal_count_norm   \n",
       "181648                                                                0.0  \\\n",
       "229245                                                                NaN   \n",
       "122525                                                                NaN   \n",
       "306311                                                                NaN   \n",
       "300658                                                                NaN   \n",
       "...                                                                   ...   \n",
       "31304                                                                 NaN   \n",
       "121193                                                                0.0   \n",
       "248504                                                                NaN   \n",
       "175469                                                                NaN   \n",
       "285162                                                                0.0   \n",
       "\n",
       "        credit_card_balance_NAME_CONTRACT_STATUS_Signed_count   \n",
       "181648                                                    0.0  \\\n",
       "229245                                                    NaN   \n",
       "122525                                                    NaN   \n",
       "306311                                                    NaN   \n",
       "300658                                                    NaN   \n",
       "...                                                       ...   \n",
       "31304                                                     NaN   \n",
       "121193                                                    0.0   \n",
       "248504                                                    NaN   \n",
       "175469                                                    NaN   \n",
       "285162                                                    0.0   \n",
       "\n",
       "        credit_card_balance_NAME_CONTRACT_STATUS_Signed_count_norm  \n",
       "181648                                                         0.0  \n",
       "229245                                                         NaN  \n",
       "122525                                                         NaN  \n",
       "306311                                                         NaN  \n",
       "300658                                                         NaN  \n",
       "...                                                            ...  \n",
       "31304                                                          NaN  \n",
       "121193                                                         0.0  \n",
       "248504                                                         NaN  \n",
       "175469                                                         NaN  \n",
       "285162                                                         0.0  \n",
       "\n",
       "[246008 rows x 1139 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "67f1421a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'# --- MLflow Experiment Run ---\\nmlflow.set_experiment(\"business_cost Full Data LightGBM\") # To organize runs into experiments\\n\\nwith mlflow.start_run(run_name=\"First Run with full data and business cost\"): #Utile plus tard pour fine tuning\\n    \\n    # --- Define Model & Pipeline ---\\n    pipeline_lgbm = make_pipeline(\\n        StandardScaler(), # Scaling is still generally recommended for LGBM, though less critical than for LogReg\\n        lgb.LGBMClassifier(\\n            \\n        # --- Core Speed Parameters ---\\n        n_estimators=2000,         # number of trees. Default is 100.\\n        learning_rate=0.005,       # learning rate of 0.05 with 2000 estimators is a common strategy coupled with early stopping qu\\'on va mettre dans le .fit()\\n        num_leaves=31,           # LOW number. Default is 31. Fewer leaves = simpler trees = faster. Increase later (e.g., 31, 63).\\n        max_depth=-1,            # Default (-1 means no limit). You could limit (e.g., 5 or 7) for speed, but num_leaves often controls complexity better.\\n\\n        # --- Subsampling Parameters (can significantly speed up) ---\\n        subsample=0.9,           # Use only 70% of data rows per tree. Default is 1.0.\\n        colsample_bytree=0.9,    # Use only 70% of features per tree. Default is 1.0.\\n        # subsample_freq=1,      # How often to subsample (every 1 iteration here). Default is 0 (disabled), set to >0 to enable row subsampling.\\n\\n        # --- Regularization parameters help prevent overfitting\\n\\n        reg_alpha=0.1,            # Added small L1 regularization\\n        reg_lambda=0.1,           # Added small L2 regularization\\n\\n        # --- Other Important Parameters ---\\n        class_weight=\\'balanced\\', # Keep this for imbalance.\\n        random_state=42,\\n        n_jobs=-1,               # Use all available CPU cores. Default.\\n        # objective=\\'binary\\',    # Default for classifier, no need to set usually.\\n        # metric=\\'auc\\',          # Default is usually logloss/binary_logloss. AUC is good for evaluation.\\n        )\\n    )\\n    \\n    nan_handling_strategy = \"LGBM_internal\" # On laisse LightGBM gérer les NaNs\\n\\n\\n    # --- Log Parameters ---\\n    mlflow.log_param(\"model_type\", \"LightGBM\") # Updated\\n    mlflow.log_param(\"imputation_merge_nans\", \"ZeroFill\") # Example for merge NaNs\\n    mlflow.log_param(\"nan_handling_model\", nan_handling_strategy) # Log NaN strategy\\n    mlflow.log_param(\"scaling\", \"StandardScaler\")\\n    mlflow.log_param(\"class_weight\", \"balanced\")\\n    mlflow.log_param(\"random_state\", 42)\\n    mlflow.log_param(\"train_val_split\", 0.2)\\n    \\n    # --- key LGBM params ---\\n    mlflow.log_param(\"lgbm_n_estimators\", 2000) \\n    mlflow.log_param(\"lgbm_learning_rate\", 0.005)              \\n    mlflow.log_param(\"lgbm_num_leaves\", 31)       \\n    mlflow.log_param(\"lgbm_max_depth\", -1) \\n    mlflow.log_param(\"lgbm_subsample\", 0.9)\\n    mlflow.log_param(\"lgbm_colsample_bytree\", 0.9)  \\n    mlflow.log_param(\"lgbm_n_jobs\", -1)\\n    mlflow.log_param(\"reg_alpha\", 0.1)\\n    mlflow.log_param(\"reg_lambda\", 0.1) \\n\\n    # --- Definition des callbacks ---\\n\\n    stopping_rounds=200\\n    verbose=100\\n    early_stopping_metric = \\'auc\\'\\n\\n    #liste de callbacks qu\\'on va mettre dans le fit pour dire quels callbacks notre modèle doit utiliser durant l\\'entrainement\\n    callbacks_list = [lgb.early_stopping(stopping_rounds=stopping_rounds, verbose=verbose)] # Stop if val AUC doesn\\'t improve for 50 rounds, print every 100 rounds\\n\\n    # --- IMPORTANT --- Meme si LightGBM utilise par défaut binary logloss ici on va utiliser ROC AUC car :\\n    # Log loss can sometimes be sensitive to outliers or poorly calibrated probabilities. It might not perfectly align with the final business metric you care about (which might be AUC, F1, precision, recall, etc.).\\n    # ROC AUX a aussi ses désavantages : Cons: AUC is threshold-independent, so stopping based on it doesn\\'t guarantee optimal performance at the specific threshold you might choose later (though it\\'s usually highly correlated).\\n    # Mais globalement AUC is a common and robust metric for evaluating binary classifier performance, especially with imbalanced datasets. It measures the model\\'s ability to rank positive instances higher than negative ones, irrespective of the specific threshold. \\n    # Stopping based on validation AUC ensures you stop when this ranking ability stops improving. Often aligns better with overall classification quality goals than log loss.\\n    # Le seul vrai avantage d\\'utiliser la même métrique que celle que le modèle regarde pendant son entrainement ici la log loss c\\'est que :\\n    # Directly related to the function the model is optimizing. Stopping based on validation log loss ensures you stop when the model\\'s probabilistic predictions stop improving on unseen data according to that specific loss function.\\n\\n    # Define the validation set for early stopping\\n    eval_set = [(X_val, y_val)]\\n\\n    # --- Train model ---\\n    pipeline_lgbm.fit(\\n        X_train, y_train,\\n        # Pass eval_set for early stopping\\n        lgbmclassifier__eval_set=eval_set, #eval_set est une liste contenant des validation sets (as tuples of (X_val, y_val)) pour controler/monitor performances. Early stopping uses this to decide when to stop.\\n        lgbmclassifier__eval_metric=\\'auc\\',  # <--- Specify AUC here\\n        # Use callbacks argument for early stopping\\n        lgbmclassifier__callbacks=callbacks_list\\n        )\\n    \\n    # --- Log Callbacks parameters\\n\\n    mlflow.log_param(\"early_stopping_enabled\", True)\\n    mlflow.log_param(\"early_stopping_rounds\", stopping_rounds)\\n    mlflow.log_param(\"early_stopping_metric\", early_stopping_metric)\\n\\n    # --- After fitting ---\\n    \\n    #  --- IMPORTANT ---best_iteration as a metric tells us how many trees were actually used in the final model selected by early stopping\\n    fitted_lgbm = pipeline_lgbm.named_steps[\\'lgbmclassifier\\']\\n    if fitted_lgbm.best_iteration_:\\n        mlflow.log_metric(\"best_iteration\", fitted_lgbm.best_iteration_)\\n        # Optional: Update the n_estimators param if you want to reflect the stopped value\\n        # mlflow.log_param(\"actual_n_estimators\", fitted_lgbm.best_iteration_)\\n    else:\\n        # Log if early stopping didn\\'t trigger (ran full n_estimators)\\n        mlflow.log_metric(\"best_iteration\", fitted_lgbm.n_estimators)\\n        # mlflow.log_param(\"actual_n_estimators\", fitted_lgbm.n_estimators)\\n\\n    # --- Predict & Calcul des métriques ---\\n    y_pred = pipeline_lgbm.predict(X_val)\\n    y_proba = pipeline_lgbm.predict_proba(X_val)[:, 1] # Probabilities for class 1\\n\\n    business_cost = calculate_business_cost(y_val, y_pred, cost_fn=10, cost_tn=(-1), cost_fp=1)\\n    accuracy = accuracy_score(y_val, y_pred)\\n    f1 = f1_score(y_val, y_pred) # Default F1 for class 1\\n    roc_auc = roc_auc_score(y_val, y_proba)\\n    report = classification_report(y_val, y_pred, output_dict=True) # Get report as dict\\n\\n    # --- Log métriques ---\\n    mlflow.log_metric(\"business_cost\", business_cost)\\n    mlflow.log_metric(\"val_accuracy\", accuracy)\\n    mlflow.log_metric(\"val_f1_score\", f1)\\n    mlflow.log_metric(\"val_roc_auc\", roc_auc)\\n    # metrics from classification report\\n    mlflow.log_metric(\"val_precision_0\", report[\\'0\\'][\\'precision\\'])\\n    mlflow.log_metric(\"val_recall_0\", report[\\'0\\'][\\'recall\\'])\\n    mlflow.log_metric(\"val_f1_0\", report[\\'0\\'][\\'f1-score\\'])\\n    mlflow.log_metric(\"val_precision_1\", report[\\'1\\'][\\'precision\\'])\\n    mlflow.log_metric(\"val_recall_1\", report[\\'1\\'][\\'recall\\'])\\n    mlflow.log_metric(\"val_f1_1\", report[\\'1\\'][\\'f1-score\\'])\\n\\n    # --- Input Example ---\\n    input_example = X_train.head(5) #Input example = small sample of valid input data (like one or a few rows from X_train or X_val DataFrame) that demonstrates the expected format.\\n    #Sert a si jamais on souhaite se resservir du modèle à ce qu\\'il vérifie que les données d\\'entrée aient le format attendu ici DataFrame Pandas\\n\\n    # --- Log Model ---\\n    mlflow.lightgbm.log_model(\\n        lgb_model=pipeline_lgbm.named_steps[\\'lgbmclassifier\\'], # Log the LGBM step\\n        artifact_path=\"lightgbm_model\",\\n        input_example=X_train.head(5) # Provide example\\n        )\\n\\n\\n    # --- Log Artifacts (Example: Confusion Matrix) ---\\n    cm = confusion_matrix(y_val, y_pred, labels=pipeline_lgbm.classes_)\\n    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=pipeline_lgbm.classes_)\\n    disp.plot()\\n    plt.title(f\"Confusion Matrix LGBM (Validation Set)\")\\n    cm_path = \"confusion_matrix_lgbm_val.png\"\\n    plt.savefig(cm_path)\\n    mlflow.log_artifact(cm_path)\\n    plt.close() # Close the plot to prevent display in notebook output if desired\\n\\n    print(f\"Run ID: {mlflow.active_run().info.run_id} logged.\")\\n    print(f\"Validation ROC-AUC: {roc_auc:.4f}\")\\n    print(f\"Business cost: {business_cost}\")\\n    print(classification_report(y_val, y_pred))'"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"# --- MLflow Experiment Run ---\n",
    "mlflow.set_experiment(\"business_cost Full Data LightGBM\") # To organize runs into experiments\n",
    "\n",
    "with mlflow.start_run(run_name=\"First Run with full data and business cost\"): #Utile plus tard pour fine tuning\n",
    "    \n",
    "    # --- Define Model & Pipeline ---\n",
    "    pipeline_lgbm = make_pipeline(\n",
    "        StandardScaler(), # Scaling is still generally recommended for LGBM, though less critical than for LogReg\n",
    "        lgb.LGBMClassifier(\n",
    "            \n",
    "        # --- Core Speed Parameters ---\n",
    "        n_estimators=2000,         # number of trees. Default is 100.\n",
    "        learning_rate=0.005,       # learning rate of 0.05 with 2000 estimators is a common strategy coupled with early stopping qu'on va mettre dans le .fit()\n",
    "        num_leaves=31,           # LOW number. Default is 31. Fewer leaves = simpler trees = faster. Increase later (e.g., 31, 63).\n",
    "        max_depth=-1,            # Default (-1 means no limit). You could limit (e.g., 5 or 7) for speed, but num_leaves often controls complexity better.\n",
    "\n",
    "        # --- Subsampling Parameters (can significantly speed up) ---\n",
    "        subsample=0.9,           # Use only 70% of data rows per tree. Default is 1.0.\n",
    "        colsample_bytree=0.9,    # Use only 70% of features per tree. Default is 1.0.\n",
    "        # subsample_freq=1,      # How often to subsample (every 1 iteration here). Default is 0 (disabled), set to >0 to enable row subsampling.\n",
    "\n",
    "        # --- Regularization parameters help prevent overfitting\n",
    "\n",
    "        reg_alpha=0.1,            # Added small L1 regularization\n",
    "        reg_lambda=0.1,           # Added small L2 regularization\n",
    "\n",
    "        # --- Other Important Parameters ---\n",
    "        class_weight='balanced', # Keep this for imbalance.\n",
    "        random_state=42,\n",
    "        n_jobs=-1,               # Use all available CPU cores. Default.\n",
    "        # objective='binary',    # Default for classifier, no need to set usually.\n",
    "        # metric='auc',          # Default is usually logloss/binary_logloss. AUC is good for evaluation.\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    nan_handling_strategy = \"LGBM_internal\" # On laisse LightGBM gérer les NaNs\n",
    "\n",
    "\n",
    "    # --- Log Parameters ---\n",
    "    mlflow.log_param(\"model_type\", \"LightGBM\") # Updated\n",
    "    mlflow.log_param(\"imputation_merge_nans\", \"ZeroFill\") # Example for merge NaNs\n",
    "    mlflow.log_param(\"nan_handling_model\", nan_handling_strategy) # Log NaN strategy\n",
    "    mlflow.log_param(\"scaling\", \"StandardScaler\")\n",
    "    mlflow.log_param(\"class_weight\", \"balanced\")\n",
    "    mlflow.log_param(\"random_state\", 42)\n",
    "    mlflow.log_param(\"train_val_split\", 0.2)\n",
    "    \n",
    "    # --- key LGBM params ---\n",
    "    mlflow.log_param(\"lgbm_n_estimators\", 2000) \n",
    "    mlflow.log_param(\"lgbm_learning_rate\", 0.005)              \n",
    "    mlflow.log_param(\"lgbm_num_leaves\", 31)       \n",
    "    mlflow.log_param(\"lgbm_max_depth\", -1) \n",
    "    mlflow.log_param(\"lgbm_subsample\", 0.9)\n",
    "    mlflow.log_param(\"lgbm_colsample_bytree\", 0.9)  \n",
    "    mlflow.log_param(\"lgbm_n_jobs\", -1)\n",
    "    mlflow.log_param(\"reg_alpha\", 0.1)\n",
    "    mlflow.log_param(\"reg_lambda\", 0.1) \n",
    "\n",
    "    # --- Definition des callbacks ---\n",
    "\n",
    "    stopping_rounds=200\n",
    "    verbose=100\n",
    "    early_stopping_metric = 'auc'\n",
    "\n",
    "    #liste de callbacks qu'on va mettre dans le fit pour dire quels callbacks notre modèle doit utiliser durant l'entrainement\n",
    "    callbacks_list = [lgb.early_stopping(stopping_rounds=stopping_rounds, verbose=verbose)] # Stop if val AUC doesn't improve for 50 rounds, print every 100 rounds\n",
    "\n",
    "    # --- IMPORTANT --- Meme si LightGBM utilise par défaut binary logloss ici on va utiliser ROC AUC car :\n",
    "    # Log loss can sometimes be sensitive to outliers or poorly calibrated probabilities. It might not perfectly align with the final business metric you care about (which might be AUC, F1, precision, recall, etc.).\n",
    "    # ROC AUX a aussi ses désavantages : Cons: AUC is threshold-independent, so stopping based on it doesn't guarantee optimal performance at the specific threshold you might choose later (though it's usually highly correlated).\n",
    "    # Mais globalement AUC is a common and robust metric for evaluating binary classifier performance, especially with imbalanced datasets. It measures the model's ability to rank positive instances higher than negative ones, irrespective of the specific threshold. \n",
    "    # Stopping based on validation AUC ensures you stop when this ranking ability stops improving. Often aligns better with overall classification quality goals than log loss.\n",
    "    # Le seul vrai avantage d'utiliser la même métrique que celle que le modèle regarde pendant son entrainement ici la log loss c'est que :\n",
    "    # Directly related to the function the model is optimizing. Stopping based on validation log loss ensures you stop when the model's probabilistic predictions stop improving on unseen data according to that specific loss function.\n",
    "\n",
    "    # Define the validation set for early stopping\n",
    "    eval_set = [(X_val, y_val)]\n",
    "\n",
    "    # --- Train model ---\n",
    "    pipeline_lgbm.fit(\n",
    "        X_train, y_train,\n",
    "        # Pass eval_set for early stopping\n",
    "        lgbmclassifier__eval_set=eval_set, #eval_set est une liste contenant des validation sets (as tuples of (X_val, y_val)) pour controler/monitor performances. Early stopping uses this to decide when to stop.\n",
    "        lgbmclassifier__eval_metric='auc',  # <--- Specify AUC here\n",
    "        # Use callbacks argument for early stopping\n",
    "        lgbmclassifier__callbacks=callbacks_list\n",
    "        )\n",
    "    \n",
    "    # --- Log Callbacks parameters\n",
    "\n",
    "    mlflow.log_param(\"early_stopping_enabled\", True)\n",
    "    mlflow.log_param(\"early_stopping_rounds\", stopping_rounds)\n",
    "    mlflow.log_param(\"early_stopping_metric\", early_stopping_metric)\n",
    "\n",
    "    # --- After fitting ---\n",
    "    \n",
    "    #  --- IMPORTANT ---best_iteration as a metric tells us how many trees were actually used in the final model selected by early stopping\n",
    "    fitted_lgbm = pipeline_lgbm.named_steps['lgbmclassifier']\n",
    "    if fitted_lgbm.best_iteration_:\n",
    "        mlflow.log_metric(\"best_iteration\", fitted_lgbm.best_iteration_)\n",
    "        # Optional: Update the n_estimators param if you want to reflect the stopped value\n",
    "        # mlflow.log_param(\"actual_n_estimators\", fitted_lgbm.best_iteration_)\n",
    "    else:\n",
    "        # Log if early stopping didn't trigger (ran full n_estimators)\n",
    "        mlflow.log_metric(\"best_iteration\", fitted_lgbm.n_estimators)\n",
    "        # mlflow.log_param(\"actual_n_estimators\", fitted_lgbm.n_estimators)\n",
    "\n",
    "    # --- Predict & Calcul des métriques ---\n",
    "    y_pred = pipeline_lgbm.predict(X_val)\n",
    "    y_proba = pipeline_lgbm.predict_proba(X_val)[:, 1] # Probabilities for class 1\n",
    "\n",
    "    business_cost = calculate_business_cost(y_val, y_pred, cost_fn=10, cost_tn=(-1), cost_fp=1)\n",
    "    accuracy = accuracy_score(y_val, y_pred)\n",
    "    f1 = f1_score(y_val, y_pred) # Default F1 for class 1\n",
    "    roc_auc = roc_auc_score(y_val, y_proba)\n",
    "    report = classification_report(y_val, y_pred, output_dict=True) # Get report as dict\n",
    "\n",
    "    # --- Log métriques ---\n",
    "    mlflow.log_metric(\"business_cost\", business_cost)\n",
    "    mlflow.log_metric(\"val_accuracy\", accuracy)\n",
    "    mlflow.log_metric(\"val_f1_score\", f1)\n",
    "    mlflow.log_metric(\"val_roc_auc\", roc_auc)\n",
    "    # metrics from classification report\n",
    "    mlflow.log_metric(\"val_precision_0\", report['0']['precision'])\n",
    "    mlflow.log_metric(\"val_recall_0\", report['0']['recall'])\n",
    "    mlflow.log_metric(\"val_f1_0\", report['0']['f1-score'])\n",
    "    mlflow.log_metric(\"val_precision_1\", report['1']['precision'])\n",
    "    mlflow.log_metric(\"val_recall_1\", report['1']['recall'])\n",
    "    mlflow.log_metric(\"val_f1_1\", report['1']['f1-score'])\n",
    "\n",
    "    # --- Input Example ---\n",
    "    input_example = X_train.head(5) #Input example = small sample of valid input data (like one or a few rows from X_train or X_val DataFrame) that demonstrates the expected format.\n",
    "    #Sert a si jamais on souhaite se resservir du modèle à ce qu'il vérifie que les données d'entrée aient le format attendu ici DataFrame Pandas\n",
    "\n",
    "    # --- Log Model ---\n",
    "    mlflow.lightgbm.log_model(\n",
    "        lgb_model=pipeline_lgbm.named_steps['lgbmclassifier'], # Log the LGBM step\n",
    "        artifact_path=\"lightgbm_model\",\n",
    "        input_example=X_train.head(5) # Provide example\n",
    "        )\n",
    "\n",
    "\n",
    "    # --- Log Artifacts (Example: Confusion Matrix) ---\n",
    "    cm = confusion_matrix(y_val, y_pred, labels=pipeline_lgbm.classes_)\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=pipeline_lgbm.classes_)\n",
    "    disp.plot()\n",
    "    plt.title(f\"Confusion Matrix LGBM (Validation Set)\")\n",
    "    cm_path = \"confusion_matrix_lgbm_val.png\"\n",
    "    plt.savefig(cm_path)\n",
    "    mlflow.log_artifact(cm_path)\n",
    "    plt.close() # Close the plot to prevent display in notebook output if desired\n",
    "\n",
    "    print(f\"Run ID: {mlflow.active_run().info.run_id} logged.\")\n",
    "    print(f\"Validation ROC-AUC: {roc_auc:.4f}\")\n",
    "    print(f\"Business cost: {business_cost}\")\n",
    "    print(classification_report(y_val, y_pred))\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "60c51810",
   "metadata": {},
   "outputs": [],
   "source": [
    "#fitted_lgbm.best_iteration_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "b61472ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "#disp = ConfusionMatrixDisplay(confusion_matrix=cm,\n",
    "                              #display_labels=pipeline_lgbm.classes_)\n",
    "#disp.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be3e5b25",
   "metadata": {},
   "source": [
    "# Run LightGBM avec optimisation du threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "cabb8804",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'# --- MLflow Experiment Run ---\\nmlflow.set_experiment(\"business_cost Full Data LightGBM\") # To organize runs into experiments\\n\\nwith mlflow.start_run(run_name=\"Second Run with full data and business cost and threshold optimization\"): #Utile plus tard pour fine tuning\\n    \\n    # --- Define Model & Pipeline ---\\n    pipeline_lgbm = make_pipeline(\\n        StandardScaler(), # Scaling is still generally recommended for LGBM, though less critical than for LogReg\\n        lgb.LGBMClassifier(\\n            \\n        # --- Core Speed Parameters ---\\n        n_estimators=2000,         # number of trees. Default is 100.\\n        learning_rate=0.005,       # learning rate of 0.05 with 2000 estimators is a common strategy coupled with early stopping qu\\'on va mettre dans le .fit()\\n        num_leaves=31,           # LOW number. Default is 31. Fewer leaves = simpler trees = faster. Increase later (e.g., 31, 63).\\n        max_depth=-1,            # Default (-1 means no limit). You could limit (e.g., 5 or 7) for speed, but num_leaves often controls complexity better.\\n\\n        # --- Subsampling Parameters (can significantly speed up) ---\\n        subsample=0.9,           # Use only 70% of data rows per tree. Default is 1.0.\\n        colsample_bytree=0.9,    # Use only 70% of features per tree. Default is 1.0.\\n        # subsample_freq=1,      # How often to subsample (every 1 iteration here). Default is 0 (disabled), set to >0 to enable row subsampling.\\n\\n        # --- Regularization parameters help prevent overfitting\\n\\n        reg_alpha=0.1,            # Added small L1 regularization\\n        reg_lambda=0.1,           # Added small L2 regularization\\n\\n        # --- Other Important Parameters ---\\n        class_weight=\\'balanced\\', # Keep this for imbalance.\\n        random_state=42,\\n        n_jobs=-1,               # Use all available CPU cores. Default.\\n        # objective=\\'binary\\',    # Default for classifier, no need to set usually.\\n        # metric=\\'auc\\',          # Default is usually logloss/binary_logloss. AUC is good for evaluation.\\n        )\\n    )\\n    \\n    nan_handling_strategy = \"LGBM_internal\" # On laisse LightGBM gérer les NaNs\\n\\n\\n    # --- Log Parameters ---\\n    mlflow.log_param(\"model_type\", \"LightGBM\") # Updated\\n    mlflow.log_param(\"imputation_merge_nans\", \"ZeroFill\") # Example for merge NaNs\\n    mlflow.log_param(\"nan_handling_model\", nan_handling_strategy) # Log NaN strategy\\n    mlflow.log_param(\"scaling\", \"StandardScaler\")\\n    mlflow.log_param(\"class_weight\", \"balanced\")\\n    mlflow.log_param(\"random_state\", 42)\\n    mlflow.log_param(\"train_val_split\", 0.2)\\n    \\n    # --- key LGBM params ---\\n    mlflow.log_param(\"lgbm_n_estimators\", 2000) \\n    mlflow.log_param(\"lgbm_learning_rate\", 0.005)              \\n    mlflow.log_param(\"lgbm_num_leaves\", 31)       \\n    mlflow.log_param(\"lgbm_max_depth\", -1) \\n    mlflow.log_param(\"lgbm_subsample\", 0.9)\\n    mlflow.log_param(\"lgbm_colsample_bytree\", 0.9)  \\n    mlflow.log_param(\"lgbm_n_jobs\", -1)\\n    mlflow.log_param(\"reg_alpha\", 0.1)\\n    mlflow.log_param(\"reg_lambda\", 0.1) \\n\\n    # --- Definition des callbacks ---\\n\\n    stopping_rounds=200\\n    verbose=100\\n    early_stopping_metric = \\'auc\\'\\n\\n    #liste de callbacks qu\\'on va mettre dans le fit pour dire quels callbacks notre modèle doit utiliser durant l\\'entrainement\\n    callbacks_list = [lgb.early_stopping(stopping_rounds=stopping_rounds, verbose=verbose)] # Stop if val AUC doesn\\'t improve for 50 rounds, print every 100 rounds\\n\\n    # --- IMPORTANT --- Meme si LightGBM utilise par défaut binary logloss ici on va utiliser ROC AUC car :\\n    # Log loss can sometimes be sensitive to outliers or poorly calibrated probabilities. It might not perfectly align with the final business metric you care about (which might be AUC, F1, precision, recall, etc.).\\n    # ROC AUX a aussi ses désavantages : Cons: AUC is threshold-independent, so stopping based on it doesn\\'t guarantee optimal performance at the specific threshold you might choose later (though it\\'s usually highly correlated).\\n    # Mais globalement AUC is a common and robust metric for evaluating binary classifier performance, especially with imbalanced datasets. It measures the model\\'s ability to rank positive instances higher than negative ones, irrespective of the specific threshold. \\n    # Stopping based on validation AUC ensures you stop when this ranking ability stops improving. Often aligns better with overall classification quality goals than log loss.\\n    # Le seul vrai avantage d\\'utiliser la même métrique que celle que le modèle regarde pendant son entrainement ici la log loss c\\'est que :\\n    # Directly related to the function the model is optimizing. Stopping based on validation log loss ensures you stop when the model\\'s probabilistic predictions stop improving on unseen data according to that specific loss function.\\n\\n    # Define the validation set for early stopping\\n    eval_set = [(X_val, y_val)]\\n\\n    # --- Train model ---\\n    pipeline_lgbm.fit(\\n        X_train, y_train,\\n        # Pass eval_set for early stopping\\n        lgbmclassifier__eval_set=eval_set, #eval_set est une liste contenant des validation sets (as tuples of (X_val, y_val)) pour controler/monitor performances. Early stopping uses this to decide when to stop.\\n        lgbmclassifier__eval_metric=\\'auc\\',  # <--- Specify AUC here\\n        # Use callbacks argument for early stopping\\n        lgbmclassifier__callbacks=callbacks_list\\n        )\\n    \\n    # --- Log Callbacks parameters\\n\\n    mlflow.log_param(\"early_stopping_enabled\", True)\\n    mlflow.log_param(\"early_stopping_rounds\", stopping_rounds)\\n    mlflow.log_param(\"early_stopping_metric\", early_stopping_metric)\\n\\n    # --- After fitting ---\\n    \\n    #  --- IMPORTANT ---best_iteration as a metric tells us how many trees were actually used in the final model selected by early stopping\\n    fitted_lgbm = pipeline_lgbm.named_steps[\\'lgbmclassifier\\']\\n    if fitted_lgbm.best_iteration_:\\n        mlflow.log_metric(\"best_iteration\", fitted_lgbm.best_iteration_)\\n        # Optional: Update the n_estimators param if you want to reflect the stopped value\\n        # mlflow.log_param(\"actual_n_estimators\", fitted_lgbm.best_iteration_)\\n    else:\\n        # Log if early stopping didn\\'t trigger (ran full n_estimators)\\n        mlflow.log_metric(\"best_iteration\", fitted_lgbm.n_estimators)\\n        # mlflow.log_param(\"actual_n_estimators\", fitted_lgbm.n_estimators)\\n\\n    # --- Predict & Calcul des métriques ---\\n    y_pred = pipeline_lgbm.predict(X_val)\\n    y_proba = pipeline_lgbm.predict_proba(X_val)[:, 1] # Probabilities for class 1\\n\\n    # --- Find the best threshold to minimize business cost ---\\n    \\n    # 1. Defining a range of thresholds\\n    thresholds_to_try = np.linspace(0.01, 0.99, 100) # Trying 100 thresholds\\n\\n    # 2. Initialize variables to store the best findings\\n    min_val_cost = float(\\'inf\\') # Initialize minimum cost to positive infinity (so any real cost will be lower)\\n    best_val_threshold_cost = 0.5 # Initialize best threshold to a default (e.g., 0.5)\\n    y_pred_val_at_min_cost = None # To store the predictions made using the best threshold\\n\\n    # 3. Loop through each threshold\\n    print(\"Optimizing threshold for business cost on validation set...\")\\n    for threshold in thresholds_to_try:\\n    # 3a. Convert probabilities to class predictions based on the current threshold\\n        y_pred_temp_val = (y_proba >= threshold).astype(int)\\n    # If y_val_proba is >= current threshold, predict 1 (default), else predict 0 (repay)\\n\\n    # 3b. Calculate the business cost using these temporary predictions\\n        current_val_cost = calculate_business_cost(y_val, y_pred_temp_val,\\n                                             cost_fn=10, cost_fp=1, cost_tn=(-1))\\n\\n    # 3c. Check if this threshold gives a lower cost\\n        if current_val_cost < min_val_cost:           # Initial value is positive infinity so first one always registered an then only lower business costs can replace it\\n            min_val_cost = current_val_cost           # Update minimum cost\\n            best_val_threshold_cost = threshold       # Update best threshold\\n            y_pred_val_at_min_cost = y_pred_temp_val  # Store these predictions\\n\\n    # 4. Output the results\\n    print(f\"\\nBest threshold (validation) to minimize business cost: {best_val_threshold_cost:.4f}\")\\n    print(f\"Minimum business cost on validation set: {min_val_cost}\")\\n    # y_pred_val_at_min_cost now holds the predictions that achieve this minimum cost\\n\\n    accuracy = accuracy_score(y_val, y_pred_val_at_min_cost)\\n    f1 = f1_score(y_val, y_pred_val_at_min_cost) # Default F1 for class 1\\n    roc_auc = roc_auc_score(y_val, y_proba)\\n    report = classification_report(y_val, y_pred_val_at_min_cost, output_dict=True) # Get report as dict\\n\\n    # --- Log métriques ---\\n    mlflow.log_metric(\"best_business_cost_obtained\", min_val_cost)\\n    mlflow.log_metric(\"best_threshold_to_minimize_business_cost\", best_val_threshold_cost)\\n    mlflow.log_metric(\"val_accuracy\", accuracy)\\n    mlflow.log_metric(\"val_f1_score\", f1)\\n    mlflow.log_metric(\"val_roc_auc\", roc_auc)\\n    # metrics from classification report\\n    mlflow.log_metric(\"val_precision_0\", report[\\'0\\'][\\'precision\\'])\\n    mlflow.log_metric(\"val_recall_0\", report[\\'0\\'][\\'recall\\'])\\n    mlflow.log_metric(\"val_f1_0\", report[\\'0\\'][\\'f1-score\\'])\\n    mlflow.log_metric(\"val_precision_1\", report[\\'1\\'][\\'precision\\'])\\n    mlflow.log_metric(\"val_recall_1\", report[\\'1\\'][\\'recall\\'])\\n    mlflow.log_metric(\"val_f1_1\", report[\\'1\\'][\\'f1-score\\'])\\n\\n    # --- Input Example ---\\n    input_example = X_train.head(5) #Input example = small sample of valid input data (like one or a few rows from X_train or X_val DataFrame) that demonstrates the expected format.\\n    #Sert a si jamais on souhaite se resservir du modèle à ce qu\\'il vérifie que les données d\\'entrée aient le format attendu ici DataFrame Pandas\\n\\n    # --- Log Model ---\\n    mlflow.lightgbm.log_model(\\n        lgb_model=pipeline_lgbm.named_steps[\\'lgbmclassifier\\'], # Log the LGBM step\\n        artifact_path=\"lightgbm_model\",\\n        input_example=X_train.head(5) # Provide example\\n        )\\n\\n\\n    # --- Log Artifacts (Example: Confusion Matrix) ---\\n    cm = confusion_matrix(y_val, y_pred_val_at_min_cost, labels=pipeline_lgbm.classes_)\\n    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=pipeline_lgbm.classes_)\\n    disp.plot()\\n    plt.title(f\"Confusion Matrix LGBM (Validation Set)\")\\n    cm_path = \"confusion_matrix_lgbm_val.png\"\\n    plt.savefig(cm_path)\\n    mlflow.log_artifact(cm_path)\\n    plt.close() # Close the plot to prevent display in notebook output if desired\\n\\n    print(f\"Run ID: {mlflow.active_run().info.run_id} logged.\")\\n    print(f\"Validation ROC-AUC: {roc_auc:.4f}\")\\n    print(f\"Business cost: {min_val_cost}\")\\n    print(classification_report(y_val, y_pred_val_at_min_cost))'"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"# --- MLflow Experiment Run ---\n",
    "mlflow.set_experiment(\"business_cost Full Data LightGBM\") # To organize runs into experiments\n",
    "\n",
    "with mlflow.start_run(run_name=\"Second Run with full data and business cost and threshold optimization\"): #Utile plus tard pour fine tuning\n",
    "    \n",
    "    # --- Define Model & Pipeline ---\n",
    "    pipeline_lgbm = make_pipeline(\n",
    "        StandardScaler(), # Scaling is still generally recommended for LGBM, though less critical than for LogReg\n",
    "        lgb.LGBMClassifier(\n",
    "            \n",
    "        # --- Core Speed Parameters ---\n",
    "        n_estimators=2000,         # number of trees. Default is 100.\n",
    "        learning_rate=0.005,       # learning rate of 0.05 with 2000 estimators is a common strategy coupled with early stopping qu'on va mettre dans le .fit()\n",
    "        num_leaves=31,           # LOW number. Default is 31. Fewer leaves = simpler trees = faster. Increase later (e.g., 31, 63).\n",
    "        max_depth=-1,            # Default (-1 means no limit). You could limit (e.g., 5 or 7) for speed, but num_leaves often controls complexity better.\n",
    "\n",
    "        # --- Subsampling Parameters (can significantly speed up) ---\n",
    "        subsample=0.9,           # Use only 70% of data rows per tree. Default is 1.0.\n",
    "        colsample_bytree=0.9,    # Use only 70% of features per tree. Default is 1.0.\n",
    "        # subsample_freq=1,      # How often to subsample (every 1 iteration here). Default is 0 (disabled), set to >0 to enable row subsampling.\n",
    "\n",
    "        # --- Regularization parameters help prevent overfitting\n",
    "\n",
    "        reg_alpha=0.1,            # Added small L1 regularization\n",
    "        reg_lambda=0.1,           # Added small L2 regularization\n",
    "\n",
    "        # --- Other Important Parameters ---\n",
    "        class_weight='balanced', # Keep this for imbalance.\n",
    "        random_state=42,\n",
    "        n_jobs=-1,               # Use all available CPU cores. Default.\n",
    "        # objective='binary',    # Default for classifier, no need to set usually.\n",
    "        # metric='auc',          # Default is usually logloss/binary_logloss. AUC is good for evaluation.\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    nan_handling_strategy = \"LGBM_internal\" # On laisse LightGBM gérer les NaNs\n",
    "\n",
    "\n",
    "    # --- Log Parameters ---\n",
    "    mlflow.log_param(\"model_type\", \"LightGBM\") # Updated\n",
    "    mlflow.log_param(\"imputation_merge_nans\", \"ZeroFill\") # Example for merge NaNs\n",
    "    mlflow.log_param(\"nan_handling_model\", nan_handling_strategy) # Log NaN strategy\n",
    "    mlflow.log_param(\"scaling\", \"StandardScaler\")\n",
    "    mlflow.log_param(\"class_weight\", \"balanced\")\n",
    "    mlflow.log_param(\"random_state\", 42)\n",
    "    mlflow.log_param(\"train_val_split\", 0.2)\n",
    "    \n",
    "    # --- key LGBM params ---\n",
    "    mlflow.log_param(\"lgbm_n_estimators\", 2000) \n",
    "    mlflow.log_param(\"lgbm_learning_rate\", 0.005)              \n",
    "    mlflow.log_param(\"lgbm_num_leaves\", 31)       \n",
    "    mlflow.log_param(\"lgbm_max_depth\", -1) \n",
    "    mlflow.log_param(\"lgbm_subsample\", 0.9)\n",
    "    mlflow.log_param(\"lgbm_colsample_bytree\", 0.9)  \n",
    "    mlflow.log_param(\"lgbm_n_jobs\", -1)\n",
    "    mlflow.log_param(\"reg_alpha\", 0.1)\n",
    "    mlflow.log_param(\"reg_lambda\", 0.1) \n",
    "\n",
    "    # --- Definition des callbacks ---\n",
    "\n",
    "    stopping_rounds=200\n",
    "    verbose=100\n",
    "    early_stopping_metric = 'auc'\n",
    "\n",
    "    #liste de callbacks qu'on va mettre dans le fit pour dire quels callbacks notre modèle doit utiliser durant l'entrainement\n",
    "    callbacks_list = [lgb.early_stopping(stopping_rounds=stopping_rounds, verbose=verbose)] # Stop if val AUC doesn't improve for 50 rounds, print every 100 rounds\n",
    "\n",
    "    # --- IMPORTANT --- Meme si LightGBM utilise par défaut binary logloss ici on va utiliser ROC AUC car :\n",
    "    # Log loss can sometimes be sensitive to outliers or poorly calibrated probabilities. It might not perfectly align with the final business metric you care about (which might be AUC, F1, precision, recall, etc.).\n",
    "    # ROC AUX a aussi ses désavantages : Cons: AUC is threshold-independent, so stopping based on it doesn't guarantee optimal performance at the specific threshold you might choose later (though it's usually highly correlated).\n",
    "    # Mais globalement AUC is a common and robust metric for evaluating binary classifier performance, especially with imbalanced datasets. It measures the model's ability to rank positive instances higher than negative ones, irrespective of the specific threshold. \n",
    "    # Stopping based on validation AUC ensures you stop when this ranking ability stops improving. Often aligns better with overall classification quality goals than log loss.\n",
    "    # Le seul vrai avantage d'utiliser la même métrique que celle que le modèle regarde pendant son entrainement ici la log loss c'est que :\n",
    "    # Directly related to the function the model is optimizing. Stopping based on validation log loss ensures you stop when the model's probabilistic predictions stop improving on unseen data according to that specific loss function.\n",
    "\n",
    "    # Define the validation set for early stopping\n",
    "    eval_set = [(X_val, y_val)]\n",
    "\n",
    "    # --- Train model ---\n",
    "    pipeline_lgbm.fit(\n",
    "        X_train, y_train,\n",
    "        # Pass eval_set for early stopping\n",
    "        lgbmclassifier__eval_set=eval_set, #eval_set est une liste contenant des validation sets (as tuples of (X_val, y_val)) pour controler/monitor performances. Early stopping uses this to decide when to stop.\n",
    "        lgbmclassifier__eval_metric='auc',  # <--- Specify AUC here\n",
    "        # Use callbacks argument for early stopping\n",
    "        lgbmclassifier__callbacks=callbacks_list\n",
    "        )\n",
    "    \n",
    "    # --- Log Callbacks parameters\n",
    "\n",
    "    mlflow.log_param(\"early_stopping_enabled\", True)\n",
    "    mlflow.log_param(\"early_stopping_rounds\", stopping_rounds)\n",
    "    mlflow.log_param(\"early_stopping_metric\", early_stopping_metric)\n",
    "\n",
    "    # --- After fitting ---\n",
    "    \n",
    "    #  --- IMPORTANT ---best_iteration as a metric tells us how many trees were actually used in the final model selected by early stopping\n",
    "    fitted_lgbm = pipeline_lgbm.named_steps['lgbmclassifier']\n",
    "    if fitted_lgbm.best_iteration_:\n",
    "        mlflow.log_metric(\"best_iteration\", fitted_lgbm.best_iteration_)\n",
    "        # Optional: Update the n_estimators param if you want to reflect the stopped value\n",
    "        # mlflow.log_param(\"actual_n_estimators\", fitted_lgbm.best_iteration_)\n",
    "    else:\n",
    "        # Log if early stopping didn't trigger (ran full n_estimators)\n",
    "        mlflow.log_metric(\"best_iteration\", fitted_lgbm.n_estimators)\n",
    "        # mlflow.log_param(\"actual_n_estimators\", fitted_lgbm.n_estimators)\n",
    "\n",
    "    # --- Predict & Calcul des métriques ---\n",
    "    y_pred = pipeline_lgbm.predict(X_val)\n",
    "    y_proba = pipeline_lgbm.predict_proba(X_val)[:, 1] # Probabilities for class 1\n",
    "\n",
    "    # --- Find the best threshold to minimize business cost ---\n",
    "    \n",
    "    # 1. Defining a range of thresholds\n",
    "    thresholds_to_try = np.linspace(0.01, 0.99, 100) # Trying 100 thresholds\n",
    "\n",
    "    # 2. Initialize variables to store the best findings\n",
    "    min_val_cost = float('inf') # Initialize minimum cost to positive infinity (so any real cost will be lower)\n",
    "    best_val_threshold_cost = 0.5 # Initialize best threshold to a default (e.g., 0.5)\n",
    "    y_pred_val_at_min_cost = None # To store the predictions made using the best threshold\n",
    "\n",
    "    # 3. Loop through each threshold\n",
    "    print(\"Optimizing threshold for business cost on validation set...\")\n",
    "    for threshold in thresholds_to_try:\n",
    "    # 3a. Convert probabilities to class predictions based on the current threshold\n",
    "        y_pred_temp_val = (y_proba >= threshold).astype(int)\n",
    "    # If y_val_proba is >= current threshold, predict 1 (default), else predict 0 (repay)\n",
    "\n",
    "    # 3b. Calculate the business cost using these temporary predictions\n",
    "        current_val_cost = calculate_business_cost(y_val, y_pred_temp_val,\n",
    "                                             cost_fn=10, cost_fp=1, cost_tn=(-1))\n",
    "\n",
    "    # 3c. Check if this threshold gives a lower cost\n",
    "        if current_val_cost < min_val_cost:           # Initial value is positive infinity so first one always registered an then only lower business costs can replace it\n",
    "            min_val_cost = current_val_cost           # Update minimum cost\n",
    "            best_val_threshold_cost = threshold       # Update best threshold\n",
    "            y_pred_val_at_min_cost = y_pred_temp_val  # Store these predictions\n",
    "\n",
    "    # 4. Output the results\n",
    "    print(f\"\\nBest threshold (validation) to minimize business cost: {best_val_threshold_cost:.4f}\")\n",
    "    print(f\"Minimum business cost on validation set: {min_val_cost}\")\n",
    "    # y_pred_val_at_min_cost now holds the predictions that achieve this minimum cost\n",
    "\n",
    "    accuracy = accuracy_score(y_val, y_pred_val_at_min_cost)\n",
    "    f1 = f1_score(y_val, y_pred_val_at_min_cost) # Default F1 for class 1\n",
    "    roc_auc = roc_auc_score(y_val, y_proba)\n",
    "    report = classification_report(y_val, y_pred_val_at_min_cost, output_dict=True) # Get report as dict\n",
    "\n",
    "    # --- Log métriques ---\n",
    "    mlflow.log_metric(\"best_business_cost_obtained\", min_val_cost)\n",
    "    mlflow.log_metric(\"best_threshold_to_minimize_business_cost\", best_val_threshold_cost)\n",
    "    mlflow.log_metric(\"val_accuracy\", accuracy)\n",
    "    mlflow.log_metric(\"val_f1_score\", f1)\n",
    "    mlflow.log_metric(\"val_roc_auc\", roc_auc)\n",
    "    # metrics from classification report\n",
    "    mlflow.log_metric(\"val_precision_0\", report['0']['precision'])\n",
    "    mlflow.log_metric(\"val_recall_0\", report['0']['recall'])\n",
    "    mlflow.log_metric(\"val_f1_0\", report['0']['f1-score'])\n",
    "    mlflow.log_metric(\"val_precision_1\", report['1']['precision'])\n",
    "    mlflow.log_metric(\"val_recall_1\", report['1']['recall'])\n",
    "    mlflow.log_metric(\"val_f1_1\", report['1']['f1-score'])\n",
    "\n",
    "    # --- Input Example ---\n",
    "    input_example = X_train.head(5) #Input example = small sample of valid input data (like one or a few rows from X_train or X_val DataFrame) that demonstrates the expected format.\n",
    "    #Sert a si jamais on souhaite se resservir du modèle à ce qu'il vérifie que les données d'entrée aient le format attendu ici DataFrame Pandas\n",
    "\n",
    "    # --- Log Model ---\n",
    "    mlflow.lightgbm.log_model(\n",
    "        lgb_model=pipeline_lgbm.named_steps['lgbmclassifier'], # Log the LGBM step\n",
    "        artifact_path=\"lightgbm_model\",\n",
    "        input_example=X_train.head(5) # Provide example\n",
    "        )\n",
    "\n",
    "\n",
    "    # --- Log Artifacts (Example: Confusion Matrix) ---\n",
    "    cm = confusion_matrix(y_val, y_pred_val_at_min_cost, labels=pipeline_lgbm.classes_)\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=pipeline_lgbm.classes_)\n",
    "    disp.plot()\n",
    "    plt.title(f\"Confusion Matrix LGBM (Validation Set)\")\n",
    "    cm_path = \"confusion_matrix_lgbm_val.png\"\n",
    "    plt.savefig(cm_path)\n",
    "    mlflow.log_artifact(cm_path)\n",
    "    plt.close() # Close the plot to prevent display in notebook output if desired\n",
    "\n",
    "    print(f\"Run ID: {mlflow.active_run().info.run_id} logged.\")\n",
    "    print(f\"Validation ROC-AUC: {roc_auc:.4f}\")\n",
    "    print(f\"Business cost: {min_val_cost}\")\n",
    "    print(classification_report(y_val, y_pred_val_at_min_cost))\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "2822c2b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#fitted_lgbm.best_iteration_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "264949d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#disp = ConfusionMatrixDisplay(confusion_matrix=cm,\n",
    "                              #display_labels=pipeline_lgbm.classes_)\n",
    "#disp.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca7ece9c",
   "metadata": {},
   "source": [
    "# Run LightGBM avec d'abord GridSearchCV puis optimisation du threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "66aca475",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n# --- MLflow Experiment Run ---\\nmlflow.set_experiment(\"business_cost Full Data LightGBM\") # To organize runs into experiments\\n\\nwith mlflow.start_run(run_name=\"Third Run with full data and business cost and GridSearchCV and threshold optimization\"): #Utile plus tard pour fine tuning\\n\\n    # \\n\\n    # --- STAGE 1: HYPERPARAMETER TUNING WITH GRIDSEARCHCV ---\\n    print(\"--- Stage 1: Hyperparameter Tuning with GridSearchCV ---\")\\n\\n    # Define pipeline FOR GridSearchCV\\n    # Note: No n_estimators here if it\\'s in param_grid. Early stopping is not directly used IN grid search here.\\n    lgbm_for_grid = lgb.LGBMClassifier(\\n        class_weight=\\'balanced\\',\\n        random_state=42,\\n        n_jobs=1 #Valeur changée en 1 pour soucis mémorie\\n    )\\n    pipeline_for_grid = Pipeline([\\n        (\\'scaler\\', StandardScaler()),\\n        (\\'lgbmclassifier\\', lgbm_for_grid)\\n    ])\\n\\n    # Define Parameter Grid\\n    param_grid = {\\n        \\'lgbmclassifier__n_estimators\\': [100, 250, 400],       # 3 options\\n        \\'lgbmclassifier__learning_rate\\': [0.05, 0.1],          # 2 options\\n        \\'lgbmclassifier__num_leaves\\': [21, 31, 41, 51],        # 4 options\\n        \\'lgbmclassifier__reg_alpha\\': [0.1],                    # 1 option\\n        \\'lgbmclassifier__reg_lambda\\': [0.1],                   # 1 option\\n    # Let\\'s keep subsampling fixed for now to limit combinations\\n    # \\'lgbmclassifier__subsample\\': [0.8, 0.9],\\n    # \\'lgbmclassifier__colsample_bytree\\': [0.8, 0.9]\\n    }\\n\\n    mlflow.log_param(\"gridsearch_param_grid\", str(param_grid))\\n\\n    cv_strategy = StratifiedKFold(n_splits=3, shuffle=True, random_state=42) # 3 splits for faster grid search\\n    \\n    nan_handling_strategy = \"LGBM_internal\" # On laisse LightGBM gérer les NaNs\\n\\n    # GridSearchCV - scoring with \\'roc_auc\\' to find robust params\\n    grid_search = GridSearchCV(\\n        estimator=pipeline_for_grid,\\n        param_grid=param_grid,\\n        scoring=\\'roc_auc\\', # Focus on good probability ranking first\\n        cv=cv_strategy,\\n        verbose=2,\\n        n_jobs=1 # Use multiple cores if possible\\n    )\\n\\n    print(\"Starting GridSearchCV on X_train, y_train...\")\\n    grid_search.fit(X_train, y_train) # GridSearchCV takes X_train and y_train. It internally performs cross-validation (e.g., 3-fold or 5-fold). In our case 3-fold\\n    # For each combination of parameters in the param_grid: It trains the pipeline on k-1 folds. \\n    # It evaluates on the 1 held-out fold using the chosen scoring metric (e.g., ROC AUC, calculated using default 0.5 threshold for predictions within the scorer). It averages the scores for each parameter combination across all folds.\\n    print(\"GridSearchCV complete.\")\\n\\n    # outputs us the best parameters it found that we store\\n    best_params_from_grid = grid_search.best_params_\\n    best_cv_score_grid = grid_search.best_score_\\n\\n    mlflow.log_params({f\"best_gs_{k}\": v for k, v in best_params_from_grid.items()}) # Log best params from gridseach\\n\\n    # for k, v in best_params_from_grid.items(): This part iterates through each key-value pair in the best_params_from_grid dictionary.\\n    # In each iteration, k will be the parameter name (e.g., \\'lgbmclassifier__n_estimators\\'). v will be the corresponding best value (e.g., 400).\\n\\n\\n\\n    mlflow.log_metric(\"gridsearch_best_cv_roc_auc\", best_cv_score_grid)\\n\\n    # --- IMPORTANT We then use the parameters it found to use with our model and then we will train our model on our data using these parameters ---\\n    \\n\\n    # --- Definition des callbacks ---\\n\\n    stopping_rounds=200\\n    verbose=100\\n    early_stopping_metric = \\'auc\\'\\n\\n    #liste de callbacks qu\\'on va mettre dans le fit pour dire quels callbacks notre modèle doit utiliser durant l\\'entrainement\\n    callbacks_list = [lgb.early_stopping(stopping_rounds=stopping_rounds, verbose=verbose)] # Stop if val AUC doesn\\'t improve for 200 rounds, print every 100 rounds    \\n    \\n    # Define the validation set for early stopping\\n    eval_set = [(X_val, y_val)]\\n   \\n    # --- Log Callbacks parameters\\n\\n    mlflow.log_param(\"early_stopping_enabled\", True)\\n    mlflow.log_param(\"early_stopping_rounds\", stopping_rounds)\\n    mlflow.log_param(\"early_stopping_metric\", early_stopping_metric)\\n\\n\\n\\n    # --- IMPORTANT --- Meme si LightGBM utilise par défaut binary logloss ici on va utiliser ROC AUC car :\\n    # Log loss can sometimes be sensitive to outliers or poorly calibrated probabilities. It might not perfectly align with the final business metric you care about (which might be AUC, F1, precision, recall, etc.).\\n    # ROC AUX a aussi ses désavantages : Cons: AUC is threshold-independent, so stopping based on it doesn\\'t guarantee optimal performance at the specific threshold you might choose later (though it\\'s usually highly correlated).\\n    # Mais globalement AUC is a common and robust metric for evaluating binary classifier performance, especially with imbalanced datasets. It measures the model\\'s ability to rank positive instances higher than negative ones, irrespective of the specific threshold. \\n    # Stopping based on validation AUC ensures you stop when this ranking ability stops improving. Often aligns better with overall classification quality goals than log loss.\\n    # Le seul vrai avantage d\\'utiliser la même métrique que celle que le modèle regarde pendant son entrainement ici la log loss c\\'est que :\\n    # Directly related to the function the model is optimizing. Stopping based on validation log loss ensures you stop when the model\\'s probabilistic predictions stop improving on unseen data according to that specific loss function.\\n\\n\\n    # --- Important --- Etant donné que l\\'on utilise EarlyStopping on souhaite avoir assez d\\'itérations pour que EarlyStopping soit pertinent\\n    # Donc malgré le fait que GridSearchCV nous ait trouvé une valeur pour n_estimators, on vasimplement la remplacer par une valeur élevée pour être sur que EarlyStopping fasse effet\\n\\n    # 1. Create the base dictionary from GridSearchCV results, stripping prefixes\\n    \\n    # In best_params_from_grid which is a dictionnary so we have key value pairs each key so the name of the parameter has the prefix lgbmclassifier__ which we remove for clarity\\n\\n    final_lgbm_params = {\\n    key.replace(\\'lgbmclassifier__\\', \\'\\'): value\\n    for key, value in best_params_from_grid.items()\\n    }\\n\\n    # 2. Add/Ensure the fixed base parameters are present because they were not in best_params_from_grid\\n    #    This will add them if they weren\\'t tuned\\n    final_lgbm_params[\\'class_weight\\'] = \\'balanced\\'\\n    final_lgbm_params[\\'random_state\\'] = 42\\n    final_lgbm_params[\\'n_jobs\\'] = 1 # Changée en 1 pour soucis de mémoire\\n\\n    # 3. Explicitly set n_estimators to a high value for early stopping.\\n    #    This will override the n_estimators value that came from GridSearchCV.\\n    final_lgbm_params[\\'n_estimators\\'] = 2000\\n\\n\\n    # --- Define Model & Pipeline ---\\n    pipeline_lgbm_final = make_pipeline( # Renamed to avoid confusion with grid search pipeline\\n    StandardScaler(),\\n    lgb.LGBMClassifier(**final_lgbm_params) # Use the defined parameters ** is for dictionnary unpacking\\n    )\\n\\n    mlflow.log_params({f\"best_gs_final_{k}\": v for k, v in final_lgbm_params.items()}) # Log best params with sligh adjustments\\n\\n    # --- Log Parameters ---\\n    mlflow.log_param(\"model_type\", \"LightGBM\") # Updated\\n    mlflow.log_param(\"imputation_merge_nans\", \"ZeroFill\") # Example for merge NaNs\\n    mlflow.log_param(\"nan_handling_model\", nan_handling_strategy) # Log NaN strategy\\n    mlflow.log_param(\"scaling\", \"StandardScaler\")\\n    mlflow.log_param(\"class_weight\", \"balanced\")\\n    mlflow.log_param(\"random_state\", 42)\\n    mlflow.log_param(\"train_val_split\", 0.2)\\n\\n    # --- Train model ---\\n\\n    print(\"Training final LGBM model with early stopping...\")\\n\\n    pipeline_lgbm_final.fit(\\n        X_train, y_train,\\n        # Pass eval_set for early stopping\\n        lgbmclassifier__eval_set=eval_set, #eval_set est une liste contenant des validation sets (as tuples of (X_val, y_val)) pour controler/monitor performances. Early stopping uses this to decide when to stop.\\n        lgbmclassifier__eval_metric=early_stopping_metric,\\n        # Use callbacks argument for early stopping\\n        lgbmclassifier__callbacks=callbacks_list\\n        )\\n    \\n    print(\"Training part done\")\\n\\n    # --- After fitting ---\\n    \\n    #  --- IMPORTANT ---best_iteration as a metric tells us how many trees were actually used in the final model selected by early stopping\\n    fitted_lgbm = pipeline_lgbm_final.named_steps[\\'lgbmclassifier\\']\\n    if fitted_lgbm.best_iteration_:\\n        mlflow.log_metric(\"best_iteration\", fitted_lgbm.best_iteration_)\\n        # Optional: Update the n_estimators param if you want to reflect the stopped value\\n        # mlflow.log_param(\"actual_n_estimators\", fitted_lgbm.best_iteration_)\\n    else:\\n        # Log if early stopping didn\\'t trigger (ran full n_estimators)\\n        mlflow.log_metric(\"best_iteration\", fitted_lgbm.n_estimators)\\n        # mlflow.log_param(\"actual_n_estimators\", fitted_lgbm.n_estimators)\\n\\n    # --- Predict & Calcul des métriques ---\\n    y_pred = pipeline_lgbm_final.predict(X_val)\\n    y_proba = pipeline_lgbm_final.predict_proba(X_val)[:, 1] # Probabilities for class 1\\n\\n    # --- Find the best threshold to minimize business cost ---\\n    \\n    # 1. Defining a range of thresholds\\n    thresholds_to_try = np.linspace(0.01, 0.99, 100) # Trying 100 thresholds\\n\\n    # 2. Initialize variables to store the best findings\\n    min_val_cost = float(\\'inf\\') # Initialize minimum cost to positive infinity (so any real cost will be lower)\\n    best_val_threshold_cost = 0.5 # Initialize best threshold to a default (e.g., 0.5)\\n    y_pred_val_at_min_cost = None # To store the predictions made using the best threshold\\n\\n    # 3. Loop through each threshold\\n    print(\"Optimizing threshold for business cost on validation set...\")\\n    for threshold in thresholds_to_try:\\n    # 3a. Convert probabilities to class predictions based on the current threshold\\n        y_pred_temp_val = (y_proba >= threshold).astype(int)\\n    # If y_val_proba is >= current threshold, predict 1 (default), else predict 0 (repay)\\n\\n    # 3b. Calculate the business cost using these temporary predictions\\n        current_val_cost = calculate_business_cost(y_val, y_pred_temp_val,\\n                                             cost_fn=10, cost_fp=1, cost_tn=(-1))\\n\\n    # 3c. Check if this threshold gives a lower cost\\n        if current_val_cost < min_val_cost:           # Initial value is positive infinity so first one always registered an then only lower business costs can replace it\\n            min_val_cost = current_val_cost           # Update minimum cost\\n            best_val_threshold_cost = threshold       # Update best threshold\\n            y_pred_val_at_min_cost = y_pred_temp_val  # Store these predictions\\n\\n    # 4. Output the results\\n    print(f\"\\nBest threshold (validation) to minimize business cost: {best_val_threshold_cost:.4f}\")\\n    print(f\"Minimum business cost on validation set: {min_val_cost}\")\\n    # y_pred_val_at_min_cost now holds the predictions that achieve this minimum cost\\n\\n    accuracy = accuracy_score(y_val, y_pred_val_at_min_cost)\\n    f1 = f1_score(y_val, y_pred_val_at_min_cost) # Default F1 for class 1\\n    roc_auc = roc_auc_score(y_val, y_proba)\\n    report = classification_report(y_val, y_pred_val_at_min_cost, output_dict=True) # Get report as dict\\n\\n    # --- Log métriques ---\\n    mlflow.log_metric(\"best_business_cost_obtained\", min_val_cost)\\n    mlflow.log_metric(\"best_threshold_to_minimize_business_cost\", best_val_threshold_cost)\\n    mlflow.log_metric(\"val_accuracy\", accuracy)\\n    mlflow.log_metric(\"val_f1_score\", f1)\\n    mlflow.log_metric(\"val_roc_auc\", roc_auc)\\n    # metrics from classification report\\n    mlflow.log_metric(\"val_precision_0\", report[\\'0\\'][\\'precision\\'])\\n    mlflow.log_metric(\"val_recall_0\", report[\\'0\\'][\\'recall\\'])\\n    mlflow.log_metric(\"val_f1_0\", report[\\'0\\'][\\'f1-score\\'])\\n    mlflow.log_metric(\"val_precision_1\", report[\\'1\\'][\\'precision\\'])\\n    mlflow.log_metric(\"val_recall_1\", report[\\'1\\'][\\'recall\\'])\\n    mlflow.log_metric(\"val_f1_1\", report[\\'1\\'][\\'f1-score\\'])\\n\\n    # --- Input Example ---\\n    input_example = X_train.head(5) #Input example = small sample of valid input data (like one or a few rows from X_train or X_val DataFrame) that demonstrates the expected format.\\n    #Sert a si jamais on souhaite se resservir du modèle à ce qu\\'il vérifie que les données d\\'entrée aient le format attendu ici DataFrame Pandas\\n\\n    # --- Log Model ---\\n    mlflow.lightgbm.log_model(\\n        lgb_model=pipeline_lgbm_final.named_steps[\\'lgbmclassifier\\'], # Log the LGBM step\\n        artifact_path=\"lightgbm_model\",\\n        input_example=X_train.head(5) # Provide example\\n        )\\n\\n\\n    # --- Log Artifacts (Example: Confusion Matrix) ---\\n    cm = confusion_matrix(y_val, y_pred_val_at_min_cost, labels=pipeline_lgbm_final.classes_)\\n    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=pipeline_lgbm_final.classes_)\\n    disp.plot()\\n    plt.title(f\"Confusion Matrix LGBM (Validation Set)\")\\n    cm_path = \"confusion_matrix_lgbm_val.png\"\\n    plt.savefig(cm_path)\\n    mlflow.log_artifact(cm_path)\\n    plt.close() # Close the plot to prevent display in notebook output if desired\\n\\n    print(f\"Run ID: {mlflow.active_run().info.run_id} logged.\")\\n    print(f\"Validation ROC-AUC: {roc_auc:.4f}\")\\n    print(f\"Business cost: {min_val_cost}\")\\n    print(classification_report(y_val, y_pred_val_at_min_cost))\\n    '"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "# --- MLflow Experiment Run ---\n",
    "mlflow.set_experiment(\"business_cost Full Data LightGBM\") # To organize runs into experiments\n",
    "\n",
    "with mlflow.start_run(run_name=\"Third Run with full data and business cost and GridSearchCV and threshold optimization\"): #Utile plus tard pour fine tuning\n",
    "\n",
    "    # \n",
    "\n",
    "    # --- STAGE 1: HYPERPARAMETER TUNING WITH GRIDSEARCHCV ---\n",
    "    print(\"--- Stage 1: Hyperparameter Tuning with GridSearchCV ---\")\n",
    "\n",
    "    # Define pipeline FOR GridSearchCV\n",
    "    # Note: No n_estimators here if it's in param_grid. Early stopping is not directly used IN grid search here.\n",
    "    lgbm_for_grid = lgb.LGBMClassifier(\n",
    "        class_weight='balanced',\n",
    "        random_state=42,\n",
    "        n_jobs=1 #Valeur changée en 1 pour soucis mémorie\n",
    "    )\n",
    "    pipeline_for_grid = Pipeline([\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('lgbmclassifier', lgbm_for_grid)\n",
    "    ])\n",
    "\n",
    "    # Define Parameter Grid\n",
    "    param_grid = {\n",
    "        'lgbmclassifier__n_estimators': [100, 250, 400],       # 3 options\n",
    "        'lgbmclassifier__learning_rate': [0.05, 0.1],          # 2 options\n",
    "        'lgbmclassifier__num_leaves': [21, 31, 41, 51],        # 4 options\n",
    "        'lgbmclassifier__reg_alpha': [0.1],                    # 1 option\n",
    "        'lgbmclassifier__reg_lambda': [0.1],                   # 1 option\n",
    "    # Let's keep subsampling fixed for now to limit combinations\n",
    "    # 'lgbmclassifier__subsample': [0.8, 0.9],\n",
    "    # 'lgbmclassifier__colsample_bytree': [0.8, 0.9]\n",
    "    }\n",
    "\n",
    "    mlflow.log_param(\"gridsearch_param_grid\", str(param_grid))\n",
    "\n",
    "    cv_strategy = StratifiedKFold(n_splits=3, shuffle=True, random_state=42) # 3 splits for faster grid search\n",
    "    \n",
    "    nan_handling_strategy = \"LGBM_internal\" # On laisse LightGBM gérer les NaNs\n",
    "\n",
    "    # GridSearchCV - scoring with 'roc_auc' to find robust params\n",
    "    grid_search = GridSearchCV(\n",
    "        estimator=pipeline_for_grid,\n",
    "        param_grid=param_grid,\n",
    "        scoring='roc_auc', # Focus on good probability ranking first\n",
    "        cv=cv_strategy,\n",
    "        verbose=2,\n",
    "        n_jobs=1 # Use multiple cores if possible\n",
    "    )\n",
    "\n",
    "    print(\"Starting GridSearchCV on X_train, y_train...\")\n",
    "    grid_search.fit(X_train, y_train) # GridSearchCV takes X_train and y_train. It internally performs cross-validation (e.g., 3-fold or 5-fold). In our case 3-fold\n",
    "    # For each combination of parameters in the param_grid: It trains the pipeline on k-1 folds. \n",
    "    # It evaluates on the 1 held-out fold using the chosen scoring metric (e.g., ROC AUC, calculated using default 0.5 threshold for predictions within the scorer). It averages the scores for each parameter combination across all folds.\n",
    "    print(\"GridSearchCV complete.\")\n",
    "\n",
    "    # outputs us the best parameters it found that we store\n",
    "    best_params_from_grid = grid_search.best_params_\n",
    "    best_cv_score_grid = grid_search.best_score_\n",
    "\n",
    "    mlflow.log_params({f\"best_gs_{k}\": v for k, v in best_params_from_grid.items()}) # Log best params from gridseach\n",
    "\n",
    "    # for k, v in best_params_from_grid.items(): This part iterates through each key-value pair in the best_params_from_grid dictionary.\n",
    "    # In each iteration, k will be the parameter name (e.g., 'lgbmclassifier__n_estimators'). v will be the corresponding best value (e.g., 400).\n",
    "\n",
    "\n",
    "\n",
    "    mlflow.log_metric(\"gridsearch_best_cv_roc_auc\", best_cv_score_grid)\n",
    "\n",
    "    # --- IMPORTANT We then use the parameters it found to use with our model and then we will train our model on our data using these parameters ---\n",
    "    \n",
    "\n",
    "    # --- Definition des callbacks ---\n",
    "\n",
    "    stopping_rounds=200\n",
    "    verbose=100\n",
    "    early_stopping_metric = 'auc'\n",
    "\n",
    "    #liste de callbacks qu'on va mettre dans le fit pour dire quels callbacks notre modèle doit utiliser durant l'entrainement\n",
    "    callbacks_list = [lgb.early_stopping(stopping_rounds=stopping_rounds, verbose=verbose)] # Stop if val AUC doesn't improve for 200 rounds, print every 100 rounds    \n",
    "    \n",
    "    # Define the validation set for early stopping\n",
    "    eval_set = [(X_val, y_val)]\n",
    "   \n",
    "    # --- Log Callbacks parameters\n",
    "\n",
    "    mlflow.log_param(\"early_stopping_enabled\", True)\n",
    "    mlflow.log_param(\"early_stopping_rounds\", stopping_rounds)\n",
    "    mlflow.log_param(\"early_stopping_metric\", early_stopping_metric)\n",
    "\n",
    "\n",
    "\n",
    "    # --- IMPORTANT --- Meme si LightGBM utilise par défaut binary logloss ici on va utiliser ROC AUC car :\n",
    "    # Log loss can sometimes be sensitive to outliers or poorly calibrated probabilities. It might not perfectly align with the final business metric you care about (which might be AUC, F1, precision, recall, etc.).\n",
    "    # ROC AUX a aussi ses désavantages : Cons: AUC is threshold-independent, so stopping based on it doesn't guarantee optimal performance at the specific threshold you might choose later (though it's usually highly correlated).\n",
    "    # Mais globalement AUC is a common and robust metric for evaluating binary classifier performance, especially with imbalanced datasets. It measures the model's ability to rank positive instances higher than negative ones, irrespective of the specific threshold. \n",
    "    # Stopping based on validation AUC ensures you stop when this ranking ability stops improving. Often aligns better with overall classification quality goals than log loss.\n",
    "    # Le seul vrai avantage d'utiliser la même métrique que celle que le modèle regarde pendant son entrainement ici la log loss c'est que :\n",
    "    # Directly related to the function the model is optimizing. Stopping based on validation log loss ensures you stop when the model's probabilistic predictions stop improving on unseen data according to that specific loss function.\n",
    "\n",
    "\n",
    "    # --- Important --- Etant donné que l'on utilise EarlyStopping on souhaite avoir assez d'itérations pour que EarlyStopping soit pertinent\n",
    "    # Donc malgré le fait que GridSearchCV nous ait trouvé une valeur pour n_estimators, on vasimplement la remplacer par une valeur élevée pour être sur que EarlyStopping fasse effet\n",
    "\n",
    "    # 1. Create the base dictionary from GridSearchCV results, stripping prefixes\n",
    "    \n",
    "    # In best_params_from_grid which is a dictionnary so we have key value pairs each key so the name of the parameter has the prefix lgbmclassifier__ which we remove for clarity\n",
    "\n",
    "    final_lgbm_params = {\n",
    "    key.replace('lgbmclassifier__', ''): value\n",
    "    for key, value in best_params_from_grid.items()\n",
    "    }\n",
    "\n",
    "    # 2. Add/Ensure the fixed base parameters are present because they were not in best_params_from_grid\n",
    "    #    This will add them if they weren't tuned\n",
    "    final_lgbm_params['class_weight'] = 'balanced'\n",
    "    final_lgbm_params['random_state'] = 42\n",
    "    final_lgbm_params['n_jobs'] = 1 # Changée en 1 pour soucis de mémoire\n",
    "\n",
    "    # 3. Explicitly set n_estimators to a high value for early stopping.\n",
    "    #    This will override the n_estimators value that came from GridSearchCV.\n",
    "    final_lgbm_params['n_estimators'] = 2000\n",
    "\n",
    "\n",
    "    # --- Define Model & Pipeline ---\n",
    "    pipeline_lgbm_final = make_pipeline( # Renamed to avoid confusion with grid search pipeline\n",
    "    StandardScaler(),\n",
    "    lgb.LGBMClassifier(**final_lgbm_params) # Use the defined parameters ** is for dictionnary unpacking\n",
    "    )\n",
    "\n",
    "    mlflow.log_params({f\"best_gs_final_{k}\": v for k, v in final_lgbm_params.items()}) # Log best params with sligh adjustments\n",
    "\n",
    "    # --- Log Parameters ---\n",
    "    mlflow.log_param(\"model_type\", \"LightGBM\") # Updated\n",
    "    mlflow.log_param(\"imputation_merge_nans\", \"ZeroFill\") # Example for merge NaNs\n",
    "    mlflow.log_param(\"nan_handling_model\", nan_handling_strategy) # Log NaN strategy\n",
    "    mlflow.log_param(\"scaling\", \"StandardScaler\")\n",
    "    mlflow.log_param(\"class_weight\", \"balanced\")\n",
    "    mlflow.log_param(\"random_state\", 42)\n",
    "    mlflow.log_param(\"train_val_split\", 0.2)\n",
    "\n",
    "    # --- Train model ---\n",
    "\n",
    "    print(\"Training final LGBM model with early stopping...\")\n",
    "\n",
    "    pipeline_lgbm_final.fit(\n",
    "        X_train, y_train,\n",
    "        # Pass eval_set for early stopping\n",
    "        lgbmclassifier__eval_set=eval_set, #eval_set est une liste contenant des validation sets (as tuples of (X_val, y_val)) pour controler/monitor performances. Early stopping uses this to decide when to stop.\n",
    "        lgbmclassifier__eval_metric=early_stopping_metric,\n",
    "        # Use callbacks argument for early stopping\n",
    "        lgbmclassifier__callbacks=callbacks_list\n",
    "        )\n",
    "    \n",
    "    print(\"Training part done\")\n",
    "\n",
    "    # --- After fitting ---\n",
    "    \n",
    "    #  --- IMPORTANT ---best_iteration as a metric tells us how many trees were actually used in the final model selected by early stopping\n",
    "    fitted_lgbm = pipeline_lgbm_final.named_steps['lgbmclassifier']\n",
    "    if fitted_lgbm.best_iteration_:\n",
    "        mlflow.log_metric(\"best_iteration\", fitted_lgbm.best_iteration_)\n",
    "        # Optional: Update the n_estimators param if you want to reflect the stopped value\n",
    "        # mlflow.log_param(\"actual_n_estimators\", fitted_lgbm.best_iteration_)\n",
    "    else:\n",
    "        # Log if early stopping didn't trigger (ran full n_estimators)\n",
    "        mlflow.log_metric(\"best_iteration\", fitted_lgbm.n_estimators)\n",
    "        # mlflow.log_param(\"actual_n_estimators\", fitted_lgbm.n_estimators)\n",
    "\n",
    "    # --- Predict & Calcul des métriques ---\n",
    "    y_pred = pipeline_lgbm_final.predict(X_val)\n",
    "    y_proba = pipeline_lgbm_final.predict_proba(X_val)[:, 1] # Probabilities for class 1\n",
    "\n",
    "    # --- Find the best threshold to minimize business cost ---\n",
    "    \n",
    "    # 1. Defining a range of thresholds\n",
    "    thresholds_to_try = np.linspace(0.01, 0.99, 100) # Trying 100 thresholds\n",
    "\n",
    "    # 2. Initialize variables to store the best findings\n",
    "    min_val_cost = float('inf') # Initialize minimum cost to positive infinity (so any real cost will be lower)\n",
    "    best_val_threshold_cost = 0.5 # Initialize best threshold to a default (e.g., 0.5)\n",
    "    y_pred_val_at_min_cost = None # To store the predictions made using the best threshold\n",
    "\n",
    "    # 3. Loop through each threshold\n",
    "    print(\"Optimizing threshold for business cost on validation set...\")\n",
    "    for threshold in thresholds_to_try:\n",
    "    # 3a. Convert probabilities to class predictions based on the current threshold\n",
    "        y_pred_temp_val = (y_proba >= threshold).astype(int)\n",
    "    # If y_val_proba is >= current threshold, predict 1 (default), else predict 0 (repay)\n",
    "\n",
    "    # 3b. Calculate the business cost using these temporary predictions\n",
    "        current_val_cost = calculate_business_cost(y_val, y_pred_temp_val,\n",
    "                                             cost_fn=10, cost_fp=1, cost_tn=(-1))\n",
    "\n",
    "    # 3c. Check if this threshold gives a lower cost\n",
    "        if current_val_cost < min_val_cost:           # Initial value is positive infinity so first one always registered an then only lower business costs can replace it\n",
    "            min_val_cost = current_val_cost           # Update minimum cost\n",
    "            best_val_threshold_cost = threshold       # Update best threshold\n",
    "            y_pred_val_at_min_cost = y_pred_temp_val  # Store these predictions\n",
    "\n",
    "    # 4. Output the results\n",
    "    print(f\"\\nBest threshold (validation) to minimize business cost: {best_val_threshold_cost:.4f}\")\n",
    "    print(f\"Minimum business cost on validation set: {min_val_cost}\")\n",
    "    # y_pred_val_at_min_cost now holds the predictions that achieve this minimum cost\n",
    "\n",
    "    accuracy = accuracy_score(y_val, y_pred_val_at_min_cost)\n",
    "    f1 = f1_score(y_val, y_pred_val_at_min_cost) # Default F1 for class 1\n",
    "    roc_auc = roc_auc_score(y_val, y_proba)\n",
    "    report = classification_report(y_val, y_pred_val_at_min_cost, output_dict=True) # Get report as dict\n",
    "\n",
    "    # --- Log métriques ---\n",
    "    mlflow.log_metric(\"best_business_cost_obtained\", min_val_cost)\n",
    "    mlflow.log_metric(\"best_threshold_to_minimize_business_cost\", best_val_threshold_cost)\n",
    "    mlflow.log_metric(\"val_accuracy\", accuracy)\n",
    "    mlflow.log_metric(\"val_f1_score\", f1)\n",
    "    mlflow.log_metric(\"val_roc_auc\", roc_auc)\n",
    "    # metrics from classification report\n",
    "    mlflow.log_metric(\"val_precision_0\", report['0']['precision'])\n",
    "    mlflow.log_metric(\"val_recall_0\", report['0']['recall'])\n",
    "    mlflow.log_metric(\"val_f1_0\", report['0']['f1-score'])\n",
    "    mlflow.log_metric(\"val_precision_1\", report['1']['precision'])\n",
    "    mlflow.log_metric(\"val_recall_1\", report['1']['recall'])\n",
    "    mlflow.log_metric(\"val_f1_1\", report['1']['f1-score'])\n",
    "\n",
    "    # --- Input Example ---\n",
    "    input_example = X_train.head(5) #Input example = small sample of valid input data (like one or a few rows from X_train or X_val DataFrame) that demonstrates the expected format.\n",
    "    #Sert a si jamais on souhaite se resservir du modèle à ce qu'il vérifie que les données d'entrée aient le format attendu ici DataFrame Pandas\n",
    "\n",
    "    # --- Log Model ---\n",
    "    mlflow.lightgbm.log_model(\n",
    "        lgb_model=pipeline_lgbm_final.named_steps['lgbmclassifier'], # Log the LGBM step\n",
    "        artifact_path=\"lightgbm_model\",\n",
    "        input_example=X_train.head(5) # Provide example\n",
    "        )\n",
    "\n",
    "\n",
    "    # --- Log Artifacts (Example: Confusion Matrix) ---\n",
    "    cm = confusion_matrix(y_val, y_pred_val_at_min_cost, labels=pipeline_lgbm_final.classes_)\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=pipeline_lgbm_final.classes_)\n",
    "    disp.plot()\n",
    "    plt.title(f\"Confusion Matrix LGBM (Validation Set)\")\n",
    "    cm_path = \"confusion_matrix_lgbm_val.png\"\n",
    "    plt.savefig(cm_path)\n",
    "    mlflow.log_artifact(cm_path)\n",
    "    plt.close() # Close the plot to prevent display in notebook output if desired\n",
    "\n",
    "    print(f\"Run ID: {mlflow.active_run().info.run_id} logged.\")\n",
    "    print(f\"Validation ROC-AUC: {roc_auc:.4f}\")\n",
    "    print(f\"Business cost: {min_val_cost}\")\n",
    "    print(classification_report(y_val, y_pred_val_at_min_cost))\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "ba3fe74c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#fitted_lgbm.best_iteration_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "95d11166",
   "metadata": {},
   "outputs": [],
   "source": [
    "#disp = ConfusionMatrixDisplay(confusion_matrix=cm,\n",
    "                              #display_labels=pipeline_lgbm_final.classes_)\n",
    "#disp.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3cb388f",
   "metadata": {},
   "source": [
    "# Prise en compte de la multicolinéarité des variables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57af5d75",
   "metadata": {},
   "source": [
    "On va désormais supprimer les variables trop corrélées entre elles tout en gardant celle qui est le plus corrélée à la TARGET pour cela on va calculer notre matrice de corrélation en utilisant la méthode Spearman étant donné que l'on à un déséquilibre des classes avec la TARGET et on va utiliser la valeur absolue pour traiter de la même façon les corrélations positives et négatives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "8f342658",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n# correlation_threshold_ff: Feature-to-feature correlation threshold (e.g., 0.95)\\n\\ncorrelation_threshold_ftf = 0.95\\n\\n# --- Calculate Spearman correlation of features with the target ---\\nprint(\"Calculating feature-target correlations (Spearman)...\")\\ntarget_corr = X_train.corrwith(y_train, method=\\'spearman\\').abs()\\n# .abs() because we care about the strength of correlation, not direction, for this selection\\n# On calcule cette corrélation avec la target pour qu\\'après quand on regarde les corrélations des variables entre elles on puissse sélectionner celle la plus corrélée à la target\\n\\n# --- Calculate feature-to-feature Spearman correlation matrix ---\\nprint(\"\\nCalculating feature-to-feature correlation matrix (Spearman)...\")\\n# Ensure only numeric types are used for correlation matrix\\nnumeric_cols_for_corr = X_train.select_dtypes(include=np.number).columns\\ncorr_matrix_ftf = X_train[numeric_cols_for_corr].corr(method=\\'spearman\\').abs()\\n\\n# --- Identify and remove highly correlated features ---\\nprint(f\"\\nIdentifying features to drop with feature-to-feature correlation > {correlation_threshold_ftf}...\")\\nupper_tri = corr_matrix_ftf.where(np.triu(np.ones(corr_matrix_ftf.shape), k=1).astype(bool))\\n\\n# np.ones crée un array NumPy de la meme shape que corr_matrix_ftf qui est rempli de 1\\n# np.triu prend l\\'array crée juste avant et k permet de jouer avec quelles valeurs on veut en fonction de la diagonale de cet array \\n# En gros une matrice de corrélation est symétrique en fonction de la diagonale ducoup pour nous calculs on a besoin que de la moitié de ces valeurs ducoup on spécifie soit k=1 pour prendre valeurs au dessus de la diagonale ou k=-1 pour en dessous ou k=0 pour prendre la diagonale\\n# ça va nous retourner un array de la same shape et vu qu\\'on à mis k=1 toutes les valeurs au dessus de la diagonale sous égales à 1 et la diagonale en elle meme et en dessous c\\'est remplacé par des 0\\n# puis on fait .astype(bool) qui transforme les 1 en True et les 0 en False\\n# Et après le .where qui vient de pandas prend une condition True/False en entrée. Si on a True prend la valeur originale de corr_matrix_ftf sinon si on a False met un NaN à la place\\n# L\\'interet d\\'avoir fait ça c\\'est 1 de gagner du temps car on ferait tout les memes calculs deux fois sinon mais aussi car on pourrait avoir des soucis si on essaie par exemple de supprimer une meme colonne deux fois\\n\\ncolumns_to_drop = set() # Use a set to avoid dropping the same column multiple times\\n\\nfor column in upper_tri.columns:\\n    # Find features highly correlated with the current \\'column\\'\\n    highly_correlated_with_column = upper_tri[upper_tri[column] > correlation_threshold_ftf].index.tolist()\\n\\n    if highly_correlated_with_column:\\n        # Group contains the current \\'column\\' and all features highly correlated with it\\n        correlation_group = [column] + highly_correlated_with_column\\n\\n        # Get target correlations for this group\\n        group_target_corrs = target_corr.loc[target_corr.index.isin(correlation_group)]\\n\\n        if not group_target_corrs.empty:\\n            # Identify the feature in the group with the highest target correlation\\n            best_feature_in_group = group_target_corrs.idxmax()\\n\\n            # Identify features to drop (all in group except the best one)\\n            for feature_to_check in correlation_group:\\n                if feature_to_check != best_feature_in_group:\\n                    columns_to_drop.add(feature_to_check)\\n        else:\\n            # If no target correlations found for this group (e.g., all were non-numeric or dropped)\\n            if len(correlation_group) > 1:\\n                 columns_to_drop.update(correlation_group[1:])\\n\\n\\nprint(f\"\\nTotal features to drop based on high correlation and target: {len(columns_to_drop)}\")\\n# print(\"Features to drop:\", list(columns_to_drop)) # Uncomment to see the list\\n\\n# --- Drop the identified columns from X_train and X_val (and X_test later) ---\\nX_train_corr_filtered = X_train.drop(columns=list(columns_to_drop), errors=\\'ignore\\')\\nX_val_corr_filtered = X_val.drop(columns=list(columns_to_drop), errors=\\'ignore\\')\\n# X_test_corr_filtered = X_test.drop(columns=list(columns_to_drop), errors=\\'ignore\\') # For later\\n\\nprint(\"\\nShapes after correlation filtering:\")\\nprint(\"X_train_corr_filtered:\", X_train_corr_filtered.shape)\\nprint(\"X_val_corr_filtered:\", X_val_corr_filtered.shape)\\n'"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "# correlation_threshold_ff: Feature-to-feature correlation threshold (e.g., 0.95)\n",
    "\n",
    "correlation_threshold_ftf = 0.95\n",
    "\n",
    "# --- Calculate Spearman correlation of features with the target ---\n",
    "print(\"Calculating feature-target correlations (Spearman)...\")\n",
    "target_corr = X_train.corrwith(y_train, method='spearman').abs()\n",
    "# .abs() because we care about the strength of correlation, not direction, for this selection\n",
    "# On calcule cette corrélation avec la target pour qu'après quand on regarde les corrélations des variables entre elles on puissse sélectionner celle la plus corrélée à la target\n",
    "\n",
    "# --- Calculate feature-to-feature Spearman correlation matrix ---\n",
    "print(\"\\nCalculating feature-to-feature correlation matrix (Spearman)...\")\n",
    "# Ensure only numeric types are used for correlation matrix\n",
    "numeric_cols_for_corr = X_train.select_dtypes(include=np.number).columns\n",
    "corr_matrix_ftf = X_train[numeric_cols_for_corr].corr(method='spearman').abs()\n",
    "\n",
    "# --- Identify and remove highly correlated features ---\n",
    "print(f\"\\nIdentifying features to drop with feature-to-feature correlation > {correlation_threshold_ftf}...\")\n",
    "upper_tri = corr_matrix_ftf.where(np.triu(np.ones(corr_matrix_ftf.shape), k=1).astype(bool))\n",
    "\n",
    "# np.ones crée un array NumPy de la meme shape que corr_matrix_ftf qui est rempli de 1\n",
    "# np.triu prend l'array crée juste avant et k permet de jouer avec quelles valeurs on veut en fonction de la diagonale de cet array \n",
    "# En gros une matrice de corrélation est symétrique en fonction de la diagonale ducoup pour nous calculs on a besoin que de la moitié de ces valeurs ducoup on spécifie soit k=1 pour prendre valeurs au dessus de la diagonale ou k=-1 pour en dessous ou k=0 pour prendre la diagonale\n",
    "# ça va nous retourner un array de la same shape et vu qu'on à mis k=1 toutes les valeurs au dessus de la diagonale sous égales à 1 et la diagonale en elle meme et en dessous c'est remplacé par des 0\n",
    "# puis on fait .astype(bool) qui transforme les 1 en True et les 0 en False\n",
    "# Et après le .where qui vient de pandas prend une condition True/False en entrée. Si on a True prend la valeur originale de corr_matrix_ftf sinon si on a False met un NaN à la place\n",
    "# L'interet d'avoir fait ça c'est 1 de gagner du temps car on ferait tout les memes calculs deux fois sinon mais aussi car on pourrait avoir des soucis si on essaie par exemple de supprimer une meme colonne deux fois\n",
    "\n",
    "columns_to_drop = set() # Use a set to avoid dropping the same column multiple times\n",
    "\n",
    "for column in upper_tri.columns:\n",
    "    # Find features highly correlated with the current 'column'\n",
    "    highly_correlated_with_column = upper_tri[upper_tri[column] > correlation_threshold_ftf].index.tolist()\n",
    "\n",
    "    if highly_correlated_with_column:\n",
    "        # Group contains the current 'column' and all features highly correlated with it\n",
    "        correlation_group = [column] + highly_correlated_with_column\n",
    "\n",
    "        # Get target correlations for this group\n",
    "        group_target_corrs = target_corr.loc[target_corr.index.isin(correlation_group)]\n",
    "\n",
    "        if not group_target_corrs.empty:\n",
    "            # Identify the feature in the group with the highest target correlation\n",
    "            best_feature_in_group = group_target_corrs.idxmax()\n",
    "\n",
    "            # Identify features to drop (all in group except the best one)\n",
    "            for feature_to_check in correlation_group:\n",
    "                if feature_to_check != best_feature_in_group:\n",
    "                    columns_to_drop.add(feature_to_check)\n",
    "        else:\n",
    "            # If no target correlations found for this group (e.g., all were non-numeric or dropped)\n",
    "            if len(correlation_group) > 1:\n",
    "                 columns_to_drop.update(correlation_group[1:])\n",
    "\n",
    "\n",
    "print(f\"\\nTotal features to drop based on high correlation and target: {len(columns_to_drop)}\")\n",
    "# print(\"Features to drop:\", list(columns_to_drop)) # Uncomment to see the list\n",
    "\n",
    "# --- Drop the identified columns from X_train and X_val (and X_test later) ---\n",
    "X_train_corr_filtered = X_train.drop(columns=list(columns_to_drop), errors='ignore')\n",
    "X_val_corr_filtered = X_val.drop(columns=list(columns_to_drop), errors='ignore')\n",
    "# X_test_corr_filtered = X_test.drop(columns=list(columns_to_drop), errors='ignore') # For later\n",
    "\n",
    "print(\"\\nShapes after correlation filtering:\")\n",
    "print(\"X_train_corr_filtered:\", X_train_corr_filtered.shape)\n",
    "print(\"X_val_corr_filtered:\", X_val_corr_filtered.shape)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "55c719d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ncorrelation_threshold_ftf = 0.95 # threshold pour sélection de features\\n\\n# --- Calculate Spearman correlation of features with the target ---\\nprint(\"Calculating feature-target correlations (Spearman)...\")\\ntarget_corr = X_train.corrwith(y_train, method=\\'spearman\\').abs()\\n# .abs() because we care about the strength of correlation, not direction, for this selection\\n# On calcule cette corrélation avec la target pour qu\\'après quand on regarde les corrélations des variables entre elles on puissse sélectionner celle la plus corrélée à la target\\n\\n# --- Calculate feature-to-feature Spearman correlation matrix ---\\nprint(\"\\nCalculating feature-to-feature correlation matrix (Spearman)...\")\\n# Ensure only numeric types are used for correlation matrix\\nnumeric_cols_for_corr = X_train.select_dtypes(include=np.number).columns\\ncorr_matrix_ftf = X_train[numeric_cols_for_corr].corr(method=\\'spearman\\').abs()\\n\\n\\n# --- Identify and remove highly correlated features ---\\nprint(f\"\\nIdentifying features to drop with feature-to-feature correlation > {correlation_threshold_ftf}...\")\\n\\n# Get a list of all feature names that are in the correlation matrix\\nall_features_in_corr_matrix = corr_matrix_ftf.columns.tolist()\\n\\n# Use a set to store columns to drop to automatically handle duplicates\\ncolumns_to_drop = set() # Once a set is created, you cannot change its items, but you can remove items and add new items and duplicates are not allowed and will be ignored\\n# Utiliser un set nous permet de ne pas avoir de soucis avec le fait d\\'avoir les colonnes en deux fois (étant donné que la corr matrix est symétrique)\\n\\n# Iterate through each unique pair of features\\nfor i in range(len(all_features_in_corr_matrix)):\\n    feature_i = all_features_in_corr_matrix[i]\\n\\n    # If feature_i is already marked to be dropped, skip its comparisons\\n    if feature_i in columns_to_drop:\\n        continue\\n\\n    # --- C\\'est cette partie la ou on va calculer corrélation entre feature[i] et feature[j] et dé cider si on  supprime ou si on garde et la quelle on supprime\\n\\n    # Inner loop starts from i + 1 to only consider unique pairs (upper triangle idea) si on commencait à i = j ça ne serviarait a rien car on aurait corr = 1 a chaue fois\\n    for j in range(i + 1, len(all_features_in_corr_matrix)): # cette partie la va nous permettre d\\'incrémenter la valeur de j pour check toutes les corrélations entre feature[i] et les autres features\\n        feature_j = all_features_in_corr_matrix[j]\\n\\n        # If feature_j is already marked to be dropped, skip this pair\\n        if feature_j in columns_to_drop:\\n            continue\\n\\n        # Check the correlation between feature_i and feature_j\\n        if corr_matrix_ftf.loc[feature_i, feature_j] > correlation_threshold_ftf:\\n            # If they are highly correlated, decide which one to drop\\n            # based on their correlation with the target variable.\\n\\n            # Get the target correlation for feature_i\\n            # Use .get(key, default_value) to handle cases where a feature might not be in target_corr\\n            # (e.g., if target_corr was calculated on a subset, or if a feature name is problematic)\\n            corr_i_target = target_corr.get(feature_i, 0)\\n\\n            # Get the target correlation for feature_j\\n            corr_j_target = target_corr.get(feature_j, 0)\\n\\n            # Compare their correlations with the target\\n            # We want to keep the one with the HIGHER absolute correlation to the target\\n            if corr_i_target >= corr_j_target:\\n                # Keep feature_i, mark feature_j for dropping\\n                print(f\"  \\'{feature_j}\\' (target corr: {corr_j_target:.3f}) is highly correlated with \\'{feature_i}\\' (target corr: {corr_i_target:.3f}). Dropping \\'{feature_j}\\'.\")\\n                columns_to_drop.add(feature_j)\\n            else:\\n                # Keep feature_j, mark feature_i for dropping\\n                print(f\"  \\'{feature_i}\\' (target corr: {corr_i_target:.3f}) is highly correlated with \\'{feature_j}\\' (target corr: {corr_j_target:.3f}). Dropping \\'{feature_i}\\'.\")\\n                columns_to_drop.add(feature_i)\\n                # If feature_i is dropped, we could \\'break\\' the inner loop for feature_i\\n                # because its further comparisons are now irrelevant. However, letting it\\n                # continue and relying on the set \\'columns_to_drop\\' to handle uniqueness\\n                # is also fine and sometimes simpler to manage.\\n                # For this more complex logic, if feature_i is dropped, its subsequent pairings\\n                # are still valid with other features unless those other features are also dropped.\\n                # The `if feature_i in columns_to_drop:` check at the start of the outer loop\\n                # handles the case where feature_i itself gets dropped.\\n\\nprint(f\"\\nTotal unique features to drop: {len(columns_to_drop)}\")\\nif columns_to_drop:\\n    print(\"Features to drop:\", list(columns_to_drop))\\n\\n# --- Drop the identified columns from X_train and X_val (and X_test later) ---\\nX_train_corr_filtered = X_train.drop(columns=list(columns_to_drop), errors=\\'ignore\\')\\nX_val_corr_filtered = X_val.drop(columns=list(columns_to_drop), errors=\\'ignore\\')\\n# X_test_corr_filtered = X_test.drop(columns=list(columns_to_drop), errors=\\'ignore\\') # For later\\n\\nprint(\"\\nShapes after correlation filtering:\")\\nprint(\"Original X_train shape:\", X_train.shape)\\nprint(\"X_train_corr_filtered shape:\", X_train_corr_filtered.shape)\\n# ... print shapes for X_val ...\\n'"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "correlation_threshold_ftf = 0.95 # threshold pour sélection de features\n",
    "\n",
    "# --- Calculate Spearman correlation of features with the target ---\n",
    "print(\"Calculating feature-target correlations (Spearman)...\")\n",
    "target_corr = X_train.corrwith(y_train, method='spearman').abs()\n",
    "# .abs() because we care about the strength of correlation, not direction, for this selection\n",
    "# On calcule cette corrélation avec la target pour qu'après quand on regarde les corrélations des variables entre elles on puissse sélectionner celle la plus corrélée à la target\n",
    "\n",
    "# --- Calculate feature-to-feature Spearman correlation matrix ---\n",
    "print(\"\\nCalculating feature-to-feature correlation matrix (Spearman)...\")\n",
    "# Ensure only numeric types are used for correlation matrix\n",
    "numeric_cols_for_corr = X_train.select_dtypes(include=np.number).columns\n",
    "corr_matrix_ftf = X_train[numeric_cols_for_corr].corr(method='spearman').abs()\n",
    "\n",
    "\n",
    "# --- Identify and remove highly correlated features ---\n",
    "print(f\"\\nIdentifying features to drop with feature-to-feature correlation > {correlation_threshold_ftf}...\")\n",
    "\n",
    "# Get a list of all feature names that are in the correlation matrix\n",
    "all_features_in_corr_matrix = corr_matrix_ftf.columns.tolist()\n",
    "\n",
    "# Use a set to store columns to drop to automatically handle duplicates\n",
    "columns_to_drop = set() # Once a set is created, you cannot change its items, but you can remove items and add new items and duplicates are not allowed and will be ignored\n",
    "# Utiliser un set nous permet de ne pas avoir de soucis avec le fait d'avoir les colonnes en deux fois (étant donné que la corr matrix est symétrique)\n",
    "\n",
    "# Iterate through each unique pair of features\n",
    "for i in range(len(all_features_in_corr_matrix)):\n",
    "    feature_i = all_features_in_corr_matrix[i]\n",
    "\n",
    "    # If feature_i is already marked to be dropped, skip its comparisons\n",
    "    if feature_i in columns_to_drop:\n",
    "        continue\n",
    "\n",
    "    # --- C'est cette partie la ou on va calculer corrélation entre feature[i] et feature[j] et dé cider si on  supprime ou si on garde et la quelle on supprime\n",
    "\n",
    "    # Inner loop starts from i + 1 to only consider unique pairs (upper triangle idea) si on commencait à i = j ça ne serviarait a rien car on aurait corr = 1 a chaue fois\n",
    "    for j in range(i + 1, len(all_features_in_corr_matrix)): # cette partie la va nous permettre d'incrémenter la valeur de j pour check toutes les corrélations entre feature[i] et les autres features\n",
    "        feature_j = all_features_in_corr_matrix[j]\n",
    "\n",
    "        # If feature_j is already marked to be dropped, skip this pair\n",
    "        if feature_j in columns_to_drop:\n",
    "            continue\n",
    "\n",
    "        # Check the correlation between feature_i and feature_j\n",
    "        if corr_matrix_ftf.loc[feature_i, feature_j] > correlation_threshold_ftf:\n",
    "            # If they are highly correlated, decide which one to drop\n",
    "            # based on their correlation with the target variable.\n",
    "\n",
    "            # Get the target correlation for feature_i\n",
    "            # Use .get(key, default_value) to handle cases where a feature might not be in target_corr\n",
    "            # (e.g., if target_corr was calculated on a subset, or if a feature name is problematic)\n",
    "            corr_i_target = target_corr.get(feature_i, 0)\n",
    "\n",
    "            # Get the target correlation for feature_j\n",
    "            corr_j_target = target_corr.get(feature_j, 0)\n",
    "\n",
    "            # Compare their correlations with the target\n",
    "            # We want to keep the one with the HIGHER absolute correlation to the target\n",
    "            if corr_i_target >= corr_j_target:\n",
    "                # Keep feature_i, mark feature_j for dropping\n",
    "                print(f\"  '{feature_j}' (target corr: {corr_j_target:.3f}) is highly correlated with '{feature_i}' (target corr: {corr_i_target:.3f}). Dropping '{feature_j}'.\")\n",
    "                columns_to_drop.add(feature_j)\n",
    "            else:\n",
    "                # Keep feature_j, mark feature_i for dropping\n",
    "                print(f\"  '{feature_i}' (target corr: {corr_i_target:.3f}) is highly correlated with '{feature_j}' (target corr: {corr_j_target:.3f}). Dropping '{feature_i}'.\")\n",
    "                columns_to_drop.add(feature_i)\n",
    "                # If feature_i is dropped, we could 'break' the inner loop for feature_i\n",
    "                # because its further comparisons are now irrelevant. However, letting it\n",
    "                # continue and relying on the set 'columns_to_drop' to handle uniqueness\n",
    "                # is also fine and sometimes simpler to manage.\n",
    "                # For this more complex logic, if feature_i is dropped, its subsequent pairings\n",
    "                # are still valid with other features unless those other features are also dropped.\n",
    "                # The `if feature_i in columns_to_drop:` check at the start of the outer loop\n",
    "                # handles the case where feature_i itself gets dropped.\n",
    "\n",
    "print(f\"\\nTotal unique features to drop: {len(columns_to_drop)}\")\n",
    "if columns_to_drop:\n",
    "    print(\"Features to drop:\", list(columns_to_drop))\n",
    "\n",
    "# --- Drop the identified columns from X_train and X_val (and X_test later) ---\n",
    "X_train_corr_filtered = X_train.drop(columns=list(columns_to_drop), errors='ignore')\n",
    "X_val_corr_filtered = X_val.drop(columns=list(columns_to_drop), errors='ignore')\n",
    "# X_test_corr_filtered = X_test.drop(columns=list(columns_to_drop), errors='ignore') # For later\n",
    "\n",
    "print(\"\\nShapes after correlation filtering:\")\n",
    "print(\"Original X_train shape:\", X_train.shape)\n",
    "print(\"X_train_corr_filtered shape:\", X_train_corr_filtered.shape)\n",
    "# ... print shapes for X_val ...\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "1103725f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_corr_filtered_ini = pd.read_csv('C:/Users/Maxime/Desktop/CSV COrrelations/X_train_corr_filtered.csv')\n",
    "X_val_corr_filtered_ini = pd.read_csv('C:/Users/Maxime/Desktop/CSV COrrelations/X_val_corr_filtered.csv')\n",
    "\n",
    "X_train_corr_filtered = X_train_corr_filtered_ini.drop(columns=['Unnamed: 0'])\n",
    "X_val_corr_filtered = X_val_corr_filtered_ini.drop(columns=['Unnamed: 0'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae8b7116",
   "metadata": {},
   "source": [
    "# Run LightGBM avec variables trop corrélées entre elles enlevées"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "284b9368",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Stage 1: Hyperparameter Tuning with GridSearchCV ---\n",
      "Starting GridSearchCV on X_train, y_train...\n",
      "Fitting 3 folds for each of 24 candidates, totalling 72 fits\n",
      "[LightGBM] [Info] Number of positive: 13240, number of negative: 150765\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.380778 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 60617\n",
      "[LightGBM] [Info] Number of data points in the train set: 164005, number of used features: 650\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[CV] END lgbmclassifier__learning_rate=0.05, lgbmclassifier__n_estimators=100, lgbmclassifier__num_leaves=21, lgbmclassifier__reg_alpha=0.1, lgbmclassifier__reg_lambda=0.1; total time=  37.7s\n",
      "[LightGBM] [Info] Number of positive: 13240, number of negative: 150765\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.379210 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 60799\n",
      "[LightGBM] [Info] Number of data points in the train set: 164005, number of used features: 650\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[CV] END lgbmclassifier__learning_rate=0.05, lgbmclassifier__n_estimators=100, lgbmclassifier__num_leaves=21, lgbmclassifier__reg_alpha=0.1, lgbmclassifier__reg_lambda=0.1; total time=  37.3s\n",
      "[LightGBM] [Info] Number of positive: 13240, number of negative: 150766\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.382139 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 60820\n",
      "[LightGBM] [Info] Number of data points in the train set: 164006, number of used features: 650\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "[CV] END lgbmclassifier__learning_rate=0.05, lgbmclassifier__n_estimators=100, lgbmclassifier__num_leaves=21, lgbmclassifier__reg_alpha=0.1, lgbmclassifier__reg_lambda=0.1; total time=  37.3s\n",
      "[LightGBM] [Info] Number of positive: 13240, number of negative: 150765\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.378027 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 60617\n",
      "[LightGBM] [Info] Number of data points in the train set: 164005, number of used features: 650\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[CV] END lgbmclassifier__learning_rate=0.05, lgbmclassifier__n_estimators=100, lgbmclassifier__num_leaves=31, lgbmclassifier__reg_alpha=0.1, lgbmclassifier__reg_lambda=0.1; total time=  40.1s\n",
      "[LightGBM] [Info] Number of positive: 13240, number of negative: 150765\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.378127 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 60799\n",
      "[LightGBM] [Info] Number of data points in the train set: 164005, number of used features: 650\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[CV] END lgbmclassifier__learning_rate=0.05, lgbmclassifier__n_estimators=100, lgbmclassifier__num_leaves=31, lgbmclassifier__reg_alpha=0.1, lgbmclassifier__reg_lambda=0.1; total time=  40.4s\n",
      "[LightGBM] [Info] Number of positive: 13240, number of negative: 150766\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.377390 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 60820\n",
      "[LightGBM] [Info] Number of data points in the train set: 164006, number of used features: 650\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "[CV] END lgbmclassifier__learning_rate=0.05, lgbmclassifier__n_estimators=100, lgbmclassifier__num_leaves=31, lgbmclassifier__reg_alpha=0.1, lgbmclassifier__reg_lambda=0.1; total time=  40.0s\n",
      "[LightGBM] [Info] Number of positive: 13240, number of negative: 150765\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.379898 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 60617\n",
      "[LightGBM] [Info] Number of data points in the train set: 164005, number of used features: 650\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[CV] END lgbmclassifier__learning_rate=0.05, lgbmclassifier__n_estimators=100, lgbmclassifier__num_leaves=41, lgbmclassifier__reg_alpha=0.1, lgbmclassifier__reg_lambda=0.1; total time=  42.8s\n",
      "[LightGBM] [Info] Number of positive: 13240, number of negative: 150765\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.399480 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 60799\n",
      "[LightGBM] [Info] Number of data points in the train set: 164005, number of used features: 650\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[CV] END lgbmclassifier__learning_rate=0.05, lgbmclassifier__n_estimators=100, lgbmclassifier__num_leaves=41, lgbmclassifier__reg_alpha=0.1, lgbmclassifier__reg_lambda=0.1; total time=  43.1s\n",
      "[LightGBM] [Info] Number of positive: 13240, number of negative: 150766\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.383420 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 60820\n",
      "[LightGBM] [Info] Number of data points in the train set: 164006, number of used features: 650\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "[CV] END lgbmclassifier__learning_rate=0.05, lgbmclassifier__n_estimators=100, lgbmclassifier__num_leaves=41, lgbmclassifier__reg_alpha=0.1, lgbmclassifier__reg_lambda=0.1; total time=  42.7s\n",
      "[LightGBM] [Info] Number of positive: 13240, number of negative: 150765\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.383145 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 60617\n",
      "[LightGBM] [Info] Number of data points in the train set: 164005, number of used features: 650\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[CV] END lgbmclassifier__learning_rate=0.05, lgbmclassifier__n_estimators=100, lgbmclassifier__num_leaves=51, lgbmclassifier__reg_alpha=0.1, lgbmclassifier__reg_lambda=0.1; total time=  45.3s\n",
      "[LightGBM] [Info] Number of positive: 13240, number of negative: 150765\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.376810 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 60799\n",
      "[LightGBM] [Info] Number of data points in the train set: 164005, number of used features: 650\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[CV] END lgbmclassifier__learning_rate=0.05, lgbmclassifier__n_estimators=100, lgbmclassifier__num_leaves=51, lgbmclassifier__reg_alpha=0.1, lgbmclassifier__reg_lambda=0.1; total time=  45.3s\n",
      "[LightGBM] [Info] Number of positive: 13240, number of negative: 150766\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.381081 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 60820\n",
      "[LightGBM] [Info] Number of data points in the train set: 164006, number of used features: 650\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "[CV] END lgbmclassifier__learning_rate=0.05, lgbmclassifier__n_estimators=100, lgbmclassifier__num_leaves=51, lgbmclassifier__reg_alpha=0.1, lgbmclassifier__reg_lambda=0.1; total time=  45.1s\n",
      "[LightGBM] [Info] Number of positive: 13240, number of negative: 150765\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.373176 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 60617\n",
      "[LightGBM] [Info] Number of data points in the train set: 164005, number of used features: 650\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[CV] END lgbmclassifier__learning_rate=0.05, lgbmclassifier__n_estimators=250, lgbmclassifier__num_leaves=21, lgbmclassifier__reg_alpha=0.1, lgbmclassifier__reg_lambda=0.1; total time=  59.9s\n",
      "[LightGBM] [Info] Number of positive: 13240, number of negative: 150765\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.393004 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 60799\n",
      "[LightGBM] [Info] Number of data points in the train set: 164005, number of used features: 650\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[CV] END lgbmclassifier__learning_rate=0.05, lgbmclassifier__n_estimators=250, lgbmclassifier__num_leaves=21, lgbmclassifier__reg_alpha=0.1, lgbmclassifier__reg_lambda=0.1; total time= 1.1min\n",
      "[LightGBM] [Info] Number of positive: 13240, number of negative: 150766\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.389546 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 60820\n",
      "[LightGBM] [Info] Number of data points in the train set: 164006, number of used features: 650\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "[CV] END lgbmclassifier__learning_rate=0.05, lgbmclassifier__n_estimators=250, lgbmclassifier__num_leaves=21, lgbmclassifier__reg_alpha=0.1, lgbmclassifier__reg_lambda=0.1; total time= 1.0min\n",
      "[LightGBM] [Info] Number of positive: 13240, number of negative: 150765\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.396498 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 60617\n",
      "[LightGBM] [Info] Number of data points in the train set: 164005, number of used features: 650\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[CV] END lgbmclassifier__learning_rate=0.05, lgbmclassifier__n_estimators=250, lgbmclassifier__num_leaves=31, lgbmclassifier__reg_alpha=0.1, lgbmclassifier__reg_lambda=0.1; total time= 1.1min\n",
      "[LightGBM] [Info] Number of positive: 13240, number of negative: 150765\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.409193 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 60799\n",
      "[LightGBM] [Info] Number of data points in the train set: 164005, number of used features: 650\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[CV] END lgbmclassifier__learning_rate=0.05, lgbmclassifier__n_estimators=250, lgbmclassifier__num_leaves=31, lgbmclassifier__reg_alpha=0.1, lgbmclassifier__reg_lambda=0.1; total time= 1.1min\n",
      "[LightGBM] [Info] Number of positive: 13240, number of negative: 150766\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.404138 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 60820\n",
      "[LightGBM] [Info] Number of data points in the train set: 164006, number of used features: 650\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "[CV] END lgbmclassifier__learning_rate=0.05, lgbmclassifier__n_estimators=250, lgbmclassifier__num_leaves=31, lgbmclassifier__reg_alpha=0.1, lgbmclassifier__reg_lambda=0.1; total time= 1.1min\n",
      "[LightGBM] [Info] Number of positive: 13240, number of negative: 150765\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.427950 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 60617\n",
      "[LightGBM] [Info] Number of data points in the train set: 164005, number of used features: 650\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[CV] END lgbmclassifier__learning_rate=0.05, lgbmclassifier__n_estimators=250, lgbmclassifier__num_leaves=41, lgbmclassifier__reg_alpha=0.1, lgbmclassifier__reg_lambda=0.1; total time= 1.2min\n",
      "[LightGBM] [Info] Number of positive: 13240, number of negative: 150765\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.388767 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 60799\n",
      "[LightGBM] [Info] Number of data points in the train set: 164005, number of used features: 650\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[CV] END lgbmclassifier__learning_rate=0.05, lgbmclassifier__n_estimators=250, lgbmclassifier__num_leaves=41, lgbmclassifier__reg_alpha=0.1, lgbmclassifier__reg_lambda=0.1; total time= 1.2min\n",
      "[LightGBM] [Info] Number of positive: 13240, number of negative: 150766\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.382523 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 60820\n",
      "[LightGBM] [Info] Number of data points in the train set: 164006, number of used features: 650\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "[CV] END lgbmclassifier__learning_rate=0.05, lgbmclassifier__n_estimators=250, lgbmclassifier__num_leaves=41, lgbmclassifier__reg_alpha=0.1, lgbmclassifier__reg_lambda=0.1; total time= 1.2min\n",
      "[LightGBM] [Info] Number of positive: 13240, number of negative: 150765\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.380769 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 60617\n",
      "[LightGBM] [Info] Number of data points in the train set: 164005, number of used features: 650\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[CV] END lgbmclassifier__learning_rate=0.05, lgbmclassifier__n_estimators=250, lgbmclassifier__num_leaves=51, lgbmclassifier__reg_alpha=0.1, lgbmclassifier__reg_lambda=0.1; total time= 1.3min\n",
      "[LightGBM] [Info] Number of positive: 13240, number of negative: 150765\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.375106 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 60799\n",
      "[LightGBM] [Info] Number of data points in the train set: 164005, number of used features: 650\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[CV] END lgbmclassifier__learning_rate=0.05, lgbmclassifier__n_estimators=250, lgbmclassifier__num_leaves=51, lgbmclassifier__reg_alpha=0.1, lgbmclassifier__reg_lambda=0.1; total time= 1.3min\n",
      "[LightGBM] [Info] Number of positive: 13240, number of negative: 150766\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.384860 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 60820\n",
      "[LightGBM] [Info] Number of data points in the train set: 164006, number of used features: 650\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "[CV] END lgbmclassifier__learning_rate=0.05, lgbmclassifier__n_estimators=250, lgbmclassifier__num_leaves=51, lgbmclassifier__reg_alpha=0.1, lgbmclassifier__reg_lambda=0.1; total time= 1.2min\n",
      "[LightGBM] [Info] Number of positive: 13240, number of negative: 150765\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.376804 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 60617\n",
      "[LightGBM] [Info] Number of data points in the train set: 164005, number of used features: 650\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[CV] END lgbmclassifier__learning_rate=0.05, lgbmclassifier__n_estimators=400, lgbmclassifier__num_leaves=21, lgbmclassifier__reg_alpha=0.1, lgbmclassifier__reg_lambda=0.1; total time= 1.3min\n",
      "[LightGBM] [Info] Number of positive: 13240, number of negative: 150765\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.376490 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 60799\n",
      "[LightGBM] [Info] Number of data points in the train set: 164005, number of used features: 650\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[CV] END lgbmclassifier__learning_rate=0.05, lgbmclassifier__n_estimators=400, lgbmclassifier__num_leaves=21, lgbmclassifier__reg_alpha=0.1, lgbmclassifier__reg_lambda=0.1; total time= 1.3min\n",
      "[LightGBM] [Info] Number of positive: 13240, number of negative: 150766\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.389675 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 60820\n",
      "[LightGBM] [Info] Number of data points in the train set: 164006, number of used features: 650\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "[CV] END lgbmclassifier__learning_rate=0.05, lgbmclassifier__n_estimators=400, lgbmclassifier__num_leaves=21, lgbmclassifier__reg_alpha=0.1, lgbmclassifier__reg_lambda=0.1; total time= 1.3min\n",
      "[LightGBM] [Info] Number of positive: 13240, number of negative: 150765\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.385520 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 60617\n",
      "[LightGBM] [Info] Number of data points in the train set: 164005, number of used features: 650\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[CV] END lgbmclassifier__learning_rate=0.05, lgbmclassifier__n_estimators=400, lgbmclassifier__num_leaves=31, lgbmclassifier__reg_alpha=0.1, lgbmclassifier__reg_lambda=0.1; total time= 1.4min\n",
      "[LightGBM] [Info] Number of positive: 13240, number of negative: 150765\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.382921 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 60799\n",
      "[LightGBM] [Info] Number of data points in the train set: 164005, number of used features: 650\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[CV] END lgbmclassifier__learning_rate=0.05, lgbmclassifier__n_estimators=400, lgbmclassifier__num_leaves=31, lgbmclassifier__reg_alpha=0.1, lgbmclassifier__reg_lambda=0.1; total time= 1.4min\n",
      "[LightGBM] [Info] Number of positive: 13240, number of negative: 150766\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.381510 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 60820\n",
      "[LightGBM] [Info] Number of data points in the train set: 164006, number of used features: 650\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "[CV] END lgbmclassifier__learning_rate=0.05, lgbmclassifier__n_estimators=400, lgbmclassifier__num_leaves=31, lgbmclassifier__reg_alpha=0.1, lgbmclassifier__reg_lambda=0.1; total time= 1.5min\n",
      "[LightGBM] [Info] Number of positive: 13240, number of negative: 150765\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.397031 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 60617\n",
      "[LightGBM] [Info] Number of data points in the train set: 164005, number of used features: 650\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[CV] END lgbmclassifier__learning_rate=0.05, lgbmclassifier__n_estimators=400, lgbmclassifier__num_leaves=41, lgbmclassifier__reg_alpha=0.1, lgbmclassifier__reg_lambda=0.1; total time= 1.6min\n",
      "[LightGBM] [Info] Number of positive: 13240, number of negative: 150765\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.396209 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 60799\n",
      "[LightGBM] [Info] Number of data points in the train set: 164005, number of used features: 650\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[CV] END lgbmclassifier__learning_rate=0.05, lgbmclassifier__n_estimators=400, lgbmclassifier__num_leaves=41, lgbmclassifier__reg_alpha=0.1, lgbmclassifier__reg_lambda=0.1; total time= 1.6min\n",
      "[LightGBM] [Info] Number of positive: 13240, number of negative: 150766\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.400499 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 60820\n",
      "[LightGBM] [Info] Number of data points in the train set: 164006, number of used features: 650\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "[CV] END lgbmclassifier__learning_rate=0.05, lgbmclassifier__n_estimators=400, lgbmclassifier__num_leaves=41, lgbmclassifier__reg_alpha=0.1, lgbmclassifier__reg_lambda=0.1; total time= 1.6min\n",
      "[LightGBM] [Info] Number of positive: 13240, number of negative: 150765\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.452037 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 60617\n",
      "[LightGBM] [Info] Number of data points in the train set: 164005, number of used features: 650\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[CV] END lgbmclassifier__learning_rate=0.05, lgbmclassifier__n_estimators=400, lgbmclassifier__num_leaves=51, lgbmclassifier__reg_alpha=0.1, lgbmclassifier__reg_lambda=0.1; total time= 1.8min\n",
      "[LightGBM] [Info] Number of positive: 13240, number of negative: 150765\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.387455 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 60799\n",
      "[LightGBM] [Info] Number of data points in the train set: 164005, number of used features: 650\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[CV] END lgbmclassifier__learning_rate=0.05, lgbmclassifier__n_estimators=400, lgbmclassifier__num_leaves=51, lgbmclassifier__reg_alpha=0.1, lgbmclassifier__reg_lambda=0.1; total time= 1.8min\n",
      "[LightGBM] [Info] Number of positive: 13240, number of negative: 150766\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.400945 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 60820\n",
      "[LightGBM] [Info] Number of data points in the train set: 164006, number of used features: 650\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "[CV] END lgbmclassifier__learning_rate=0.05, lgbmclassifier__n_estimators=400, lgbmclassifier__num_leaves=51, lgbmclassifier__reg_alpha=0.1, lgbmclassifier__reg_lambda=0.1; total time= 1.7min\n",
      "[LightGBM] [Info] Number of positive: 13240, number of negative: 150765\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 1.110939 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 60617\n",
      "[LightGBM] [Info] Number of data points in the train set: 164005, number of used features: 650\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[CV] END lgbmclassifier__learning_rate=0.1, lgbmclassifier__n_estimators=100, lgbmclassifier__num_leaves=21, lgbmclassifier__reg_alpha=0.1, lgbmclassifier__reg_lambda=0.1; total time=  42.7s\n",
      "[LightGBM] [Info] Number of positive: 13240, number of negative: 150765\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.426387 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 60799\n",
      "[LightGBM] [Info] Number of data points in the train set: 164005, number of used features: 650\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[CV] END lgbmclassifier__learning_rate=0.1, lgbmclassifier__n_estimators=100, lgbmclassifier__num_leaves=21, lgbmclassifier__reg_alpha=0.1, lgbmclassifier__reg_lambda=0.1; total time=  37.6s\n",
      "[LightGBM] [Info] Number of positive: 13240, number of negative: 150766\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.399574 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 60820\n",
      "[LightGBM] [Info] Number of data points in the train set: 164006, number of used features: 650\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "[CV] END lgbmclassifier__learning_rate=0.1, lgbmclassifier__n_estimators=100, lgbmclassifier__num_leaves=21, lgbmclassifier__reg_alpha=0.1, lgbmclassifier__reg_lambda=0.1; total time=  37.5s\n",
      "[LightGBM] [Info] Number of positive: 13240, number of negative: 150765\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.396421 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 60617\n",
      "[LightGBM] [Info] Number of data points in the train set: 164005, number of used features: 650\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[CV] END lgbmclassifier__learning_rate=0.1, lgbmclassifier__n_estimators=100, lgbmclassifier__num_leaves=31, lgbmclassifier__reg_alpha=0.1, lgbmclassifier__reg_lambda=0.1; total time=  40.0s\n",
      "[LightGBM] [Info] Number of positive: 13240, number of negative: 150765\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.396525 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 60799\n",
      "[LightGBM] [Info] Number of data points in the train set: 164005, number of used features: 650\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[CV] END lgbmclassifier__learning_rate=0.1, lgbmclassifier__n_estimators=100, lgbmclassifier__num_leaves=31, lgbmclassifier__reg_alpha=0.1, lgbmclassifier__reg_lambda=0.1; total time=  40.3s\n",
      "[LightGBM] [Info] Number of positive: 13240, number of negative: 150766\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.399745 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 60820\n",
      "[LightGBM] [Info] Number of data points in the train set: 164006, number of used features: 650\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "[CV] END lgbmclassifier__learning_rate=0.1, lgbmclassifier__n_estimators=100, lgbmclassifier__num_leaves=31, lgbmclassifier__reg_alpha=0.1, lgbmclassifier__reg_lambda=0.1; total time=  39.6s\n",
      "[LightGBM] [Info] Number of positive: 13240, number of negative: 150765\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.391484 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 60617\n",
      "[LightGBM] [Info] Number of data points in the train set: 164005, number of used features: 650\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[CV] END lgbmclassifier__learning_rate=0.1, lgbmclassifier__n_estimators=100, lgbmclassifier__num_leaves=41, lgbmclassifier__reg_alpha=0.1, lgbmclassifier__reg_lambda=0.1; total time=  42.8s\n",
      "[LightGBM] [Info] Number of positive: 13240, number of negative: 150765\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.395803 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 60799\n",
      "[LightGBM] [Info] Number of data points in the train set: 164005, number of used features: 650\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[CV] END lgbmclassifier__learning_rate=0.1, lgbmclassifier__n_estimators=100, lgbmclassifier__num_leaves=41, lgbmclassifier__reg_alpha=0.1, lgbmclassifier__reg_lambda=0.1; total time=  42.8s\n",
      "[LightGBM] [Info] Number of positive: 13240, number of negative: 150766\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.394322 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 60820\n",
      "[LightGBM] [Info] Number of data points in the train set: 164006, number of used features: 650\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "[CV] END lgbmclassifier__learning_rate=0.1, lgbmclassifier__n_estimators=100, lgbmclassifier__num_leaves=41, lgbmclassifier__reg_alpha=0.1, lgbmclassifier__reg_lambda=0.1; total time=  42.2s\n",
      "[LightGBM] [Info] Number of positive: 13240, number of negative: 150765\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.393050 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 60617\n",
      "[LightGBM] [Info] Number of data points in the train set: 164005, number of used features: 650\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[CV] END lgbmclassifier__learning_rate=0.1, lgbmclassifier__n_estimators=100, lgbmclassifier__num_leaves=51, lgbmclassifier__reg_alpha=0.1, lgbmclassifier__reg_lambda=0.1; total time=  44.4s\n",
      "[LightGBM] [Info] Number of positive: 13240, number of negative: 150765\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.398860 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 60799\n",
      "[LightGBM] [Info] Number of data points in the train set: 164005, number of used features: 650\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[CV] END lgbmclassifier__learning_rate=0.1, lgbmclassifier__n_estimators=100, lgbmclassifier__num_leaves=51, lgbmclassifier__reg_alpha=0.1, lgbmclassifier__reg_lambda=0.1; total time=  44.5s\n",
      "[LightGBM] [Info] Number of positive: 13240, number of negative: 150766\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.398599 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 60820\n",
      "[LightGBM] [Info] Number of data points in the train set: 164006, number of used features: 650\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "[CV] END lgbmclassifier__learning_rate=0.1, lgbmclassifier__n_estimators=100, lgbmclassifier__num_leaves=51, lgbmclassifier__reg_alpha=0.1, lgbmclassifier__reg_lambda=0.1; total time=  44.3s\n",
      "[LightGBM] [Info] Number of positive: 13240, number of negative: 150765\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.398025 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 60617\n",
      "[LightGBM] [Info] Number of data points in the train set: 164005, number of used features: 650\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[CV] END lgbmclassifier__learning_rate=0.1, lgbmclassifier__n_estimators=250, lgbmclassifier__num_leaves=21, lgbmclassifier__reg_alpha=0.1, lgbmclassifier__reg_lambda=0.1; total time=  55.5s\n",
      "[LightGBM] [Info] Number of positive: 13240, number of negative: 150765\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.394673 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 60799\n",
      "[LightGBM] [Info] Number of data points in the train set: 164005, number of used features: 650\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[CV] END lgbmclassifier__learning_rate=0.1, lgbmclassifier__n_estimators=250, lgbmclassifier__num_leaves=21, lgbmclassifier__reg_alpha=0.1, lgbmclassifier__reg_lambda=0.1; total time=  55.8s\n",
      "[LightGBM] [Info] Number of positive: 13240, number of negative: 150766\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.391642 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 60820\n",
      "[LightGBM] [Info] Number of data points in the train set: 164006, number of used features: 650\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "[CV] END lgbmclassifier__learning_rate=0.1, lgbmclassifier__n_estimators=250, lgbmclassifier__num_leaves=21, lgbmclassifier__reg_alpha=0.1, lgbmclassifier__reg_lambda=0.1; total time=  55.5s\n",
      "[LightGBM] [Info] Number of positive: 13240, number of negative: 150765\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.395907 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 60617\n",
      "[LightGBM] [Info] Number of data points in the train set: 164005, number of used features: 650\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[CV] END lgbmclassifier__learning_rate=0.1, lgbmclassifier__n_estimators=250, lgbmclassifier__num_leaves=31, lgbmclassifier__reg_alpha=0.1, lgbmclassifier__reg_lambda=0.1; total time= 1.0min\n",
      "[LightGBM] [Info] Number of positive: 13240, number of negative: 150765\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.390284 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 60799\n",
      "[LightGBM] [Info] Number of data points in the train set: 164005, number of used features: 650\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[CV] END lgbmclassifier__learning_rate=0.1, lgbmclassifier__n_estimators=250, lgbmclassifier__num_leaves=31, lgbmclassifier__reg_alpha=0.1, lgbmclassifier__reg_lambda=0.1; total time=  59.2s\n",
      "[LightGBM] [Info] Number of positive: 13240, number of negative: 150766\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.413612 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 60820\n",
      "[LightGBM] [Info] Number of data points in the train set: 164006, number of used features: 650\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "[CV] END lgbmclassifier__learning_rate=0.1, lgbmclassifier__n_estimators=250, lgbmclassifier__num_leaves=31, lgbmclassifier__reg_alpha=0.1, lgbmclassifier__reg_lambda=0.1; total time=  58.9s\n",
      "[LightGBM] [Info] Number of positive: 13240, number of negative: 150765\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.401281 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 60617\n",
      "[LightGBM] [Info] Number of data points in the train set: 164005, number of used features: 650\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[CV] END lgbmclassifier__learning_rate=0.1, lgbmclassifier__n_estimators=250, lgbmclassifier__num_leaves=41, lgbmclassifier__reg_alpha=0.1, lgbmclassifier__reg_lambda=0.1; total time= 1.1min\n",
      "[LightGBM] [Info] Number of positive: 13240, number of negative: 150765\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.443069 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 60799\n",
      "[LightGBM] [Info] Number of data points in the train set: 164005, number of used features: 650\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[CV] END lgbmclassifier__learning_rate=0.1, lgbmclassifier__n_estimators=250, lgbmclassifier__num_leaves=41, lgbmclassifier__reg_alpha=0.1, lgbmclassifier__reg_lambda=0.1; total time= 1.1min\n",
      "[LightGBM] [Info] Number of positive: 13240, number of negative: 150766\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.439478 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 60820\n",
      "[LightGBM] [Info] Number of data points in the train set: 164006, number of used features: 650\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "[CV] END lgbmclassifier__learning_rate=0.1, lgbmclassifier__n_estimators=250, lgbmclassifier__num_leaves=41, lgbmclassifier__reg_alpha=0.1, lgbmclassifier__reg_lambda=0.1; total time= 1.1min\n",
      "[LightGBM] [Info] Number of positive: 13240, number of negative: 150765\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.388368 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 60617\n",
      "[LightGBM] [Info] Number of data points in the train set: 164005, number of used features: 650\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[CV] END lgbmclassifier__learning_rate=0.1, lgbmclassifier__n_estimators=250, lgbmclassifier__num_leaves=51, lgbmclassifier__reg_alpha=0.1, lgbmclassifier__reg_lambda=0.1; total time= 1.1min\n",
      "[LightGBM] [Info] Number of positive: 13240, number of negative: 150765\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.384156 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 60799\n",
      "[LightGBM] [Info] Number of data points in the train set: 164005, number of used features: 650\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[CV] END lgbmclassifier__learning_rate=0.1, lgbmclassifier__n_estimators=250, lgbmclassifier__num_leaves=51, lgbmclassifier__reg_alpha=0.1, lgbmclassifier__reg_lambda=0.1; total time= 1.2min\n",
      "[LightGBM] [Info] Number of positive: 13240, number of negative: 150766\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.452233 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 60820\n",
      "[LightGBM] [Info] Number of data points in the train set: 164006, number of used features: 650\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "[CV] END lgbmclassifier__learning_rate=0.1, lgbmclassifier__n_estimators=250, lgbmclassifier__num_leaves=51, lgbmclassifier__reg_alpha=0.1, lgbmclassifier__reg_lambda=0.1; total time= 1.4min\n",
      "[LightGBM] [Info] Number of positive: 13240, number of negative: 150765\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.447029 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 60617\n",
      "[LightGBM] [Info] Number of data points in the train set: 164005, number of used features: 650\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[CV] END lgbmclassifier__learning_rate=0.1, lgbmclassifier__n_estimators=400, lgbmclassifier__num_leaves=21, lgbmclassifier__reg_alpha=0.1, lgbmclassifier__reg_lambda=0.1; total time= 1.7min\n",
      "[LightGBM] [Info] Number of positive: 13240, number of negative: 150765\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.426665 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 60799\n",
      "[LightGBM] [Info] Number of data points in the train set: 164005, number of used features: 650\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[CV] END lgbmclassifier__learning_rate=0.1, lgbmclassifier__n_estimators=400, lgbmclassifier__num_leaves=21, lgbmclassifier__reg_alpha=0.1, lgbmclassifier__reg_lambda=0.1; total time= 1.4min\n",
      "[LightGBM] [Info] Number of positive: 13240, number of negative: 150766\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.409313 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 60820\n",
      "[LightGBM] [Info] Number of data points in the train set: 164006, number of used features: 650\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "[CV] END lgbmclassifier__learning_rate=0.1, lgbmclassifier__n_estimators=400, lgbmclassifier__num_leaves=21, lgbmclassifier__reg_alpha=0.1, lgbmclassifier__reg_lambda=0.1; total time= 1.4min\n",
      "[LightGBM] [Info] Number of positive: 13240, number of negative: 150765\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.406900 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 60617\n",
      "[LightGBM] [Info] Number of data points in the train set: 164005, number of used features: 650\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[CV] END lgbmclassifier__learning_rate=0.1, lgbmclassifier__n_estimators=400, lgbmclassifier__num_leaves=31, lgbmclassifier__reg_alpha=0.1, lgbmclassifier__reg_lambda=0.1; total time= 1.4min\n",
      "[LightGBM] [Info] Number of positive: 13240, number of negative: 150765\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.399296 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 60799\n",
      "[LightGBM] [Info] Number of data points in the train set: 164005, number of used features: 650\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[CV] END lgbmclassifier__learning_rate=0.1, lgbmclassifier__n_estimators=400, lgbmclassifier__num_leaves=31, lgbmclassifier__reg_alpha=0.1, lgbmclassifier__reg_lambda=0.1; total time= 1.3min\n",
      "[LightGBM] [Info] Number of positive: 13240, number of negative: 150766\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.392241 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 60820\n",
      "[LightGBM] [Info] Number of data points in the train set: 164006, number of used features: 650\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "[CV] END lgbmclassifier__learning_rate=0.1, lgbmclassifier__n_estimators=400, lgbmclassifier__num_leaves=31, lgbmclassifier__reg_alpha=0.1, lgbmclassifier__reg_lambda=0.1; total time= 1.3min\n",
      "[LightGBM] [Info] Number of positive: 13240, number of negative: 150765\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.399769 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 60617\n",
      "[LightGBM] [Info] Number of data points in the train set: 164005, number of used features: 650\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[CV] END lgbmclassifier__learning_rate=0.1, lgbmclassifier__n_estimators=400, lgbmclassifier__num_leaves=41, lgbmclassifier__reg_alpha=0.1, lgbmclassifier__reg_lambda=0.1; total time= 1.5min\n",
      "[LightGBM] [Info] Number of positive: 13240, number of negative: 150765\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.399503 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 60799\n",
      "[LightGBM] [Info] Number of data points in the train set: 164005, number of used features: 650\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[CV] END lgbmclassifier__learning_rate=0.1, lgbmclassifier__n_estimators=400, lgbmclassifier__num_leaves=41, lgbmclassifier__reg_alpha=0.1, lgbmclassifier__reg_lambda=0.1; total time= 1.4min\n",
      "[LightGBM] [Info] Number of positive: 13240, number of negative: 150766\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.415153 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 60820\n",
      "[LightGBM] [Info] Number of data points in the train set: 164006, number of used features: 650\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "[CV] END lgbmclassifier__learning_rate=0.1, lgbmclassifier__n_estimators=400, lgbmclassifier__num_leaves=41, lgbmclassifier__reg_alpha=0.1, lgbmclassifier__reg_lambda=0.1; total time= 1.4min\n",
      "[LightGBM] [Info] Number of positive: 13240, number of negative: 150765\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.416233 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 60617\n",
      "[LightGBM] [Info] Number of data points in the train set: 164005, number of used features: 650\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[CV] END lgbmclassifier__learning_rate=0.1, lgbmclassifier__n_estimators=400, lgbmclassifier__num_leaves=51, lgbmclassifier__reg_alpha=0.1, lgbmclassifier__reg_lambda=0.1; total time= 1.5min\n",
      "[LightGBM] [Info] Number of positive: 13240, number of negative: 150765\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.390127 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 60799\n",
      "[LightGBM] [Info] Number of data points in the train set: 164005, number of used features: 650\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[CV] END lgbmclassifier__learning_rate=0.1, lgbmclassifier__n_estimators=400, lgbmclassifier__num_leaves=51, lgbmclassifier__reg_alpha=0.1, lgbmclassifier__reg_lambda=0.1; total time= 1.6min\n",
      "[LightGBM] [Info] Number of positive: 13240, number of negative: 150766\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.401924 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 60820\n",
      "[LightGBM] [Info] Number of data points in the train set: 164006, number of used features: 650\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "[CV] END lgbmclassifier__learning_rate=0.1, lgbmclassifier__n_estimators=400, lgbmclassifier__num_leaves=51, lgbmclassifier__reg_alpha=0.1, lgbmclassifier__reg_lambda=0.1; total time= 1.5min\n",
      "[LightGBM] [Info] Number of positive: 19860, number of negative: 226148\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.653468 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 61229\n",
      "[LightGBM] [Info] Number of data points in the train set: 246008, number of used features: 651\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "GridSearchCV complete.\n",
      "Training final LGBM model with early stopping...\n",
      "[LightGBM] [Info] Number of positive: 19860, number of negative: 226148\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.595380 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 61229\n",
      "[LightGBM] [Info] Number of data points in the train set: 246008, number of used features: 651\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[28]\tvalid_0's auc: 0.670245\tvalid_0's binary_logloss: 0.464307\n",
      "Training part done\n",
      "Optimizing threshold for business cost on validation set...\n",
      "\n",
      "Best threshold (validation) to minimize business cost: 0.6336\n",
      "Minimum business cost on validation set: -13722\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Maxime\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\mlflow\\types\\utils.py:452: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Maxime\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\mlflow\\types\\utils.py:452: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e3218a6c0e374731aaa9a1eeef1538b2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run ID: f21fdd62edfd4358b4d8280afb7fa3c0 logged.\n",
      "Validation ROC-AUC: 0.7478\n",
      "Business cost: -13722\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.91      0.92     56538\n",
      "           1       0.25      0.34      0.29      4965\n",
      "\n",
      "    accuracy                           0.86     61503\n",
      "   macro avg       0.60      0.63      0.61     61503\n",
      "weighted avg       0.88      0.86      0.87     61503\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "# --- MLflow Experiment Run ---\n",
    "mlflow.set_experiment(\"business_cost Full Data LightGBM\") # To organize runs into experiments\n",
    "\n",
    "with mlflow.start_run(run_name=\"Fourth Run with full data and business cost and GridSearchCV and threshold optimization and high correlations removed\"): #Utile plus tard pour fine tuning\n",
    "\n",
    "    # \n",
    "\n",
    "    # --- STAGE 1: HYPERPARAMETER TUNING WITH GRIDSEARCHCV ---\n",
    "    print(\"--- Stage 1: Hyperparameter Tuning with GridSearchCV ---\")\n",
    "\n",
    "    # Define pipeline FOR GridSearchCV\n",
    "    # Note: No n_estimators here if it's in param_grid. Early stopping is not directly used IN grid search here.\n",
    "    lgbm_for_grid = lgb.LGBMClassifier(\n",
    "        class_weight='balanced',\n",
    "        random_state=42,\n",
    "        n_jobs=1 #Valeur changée en 1 pour soucis mémorie\n",
    "    )\n",
    "    pipeline_for_grid = Pipeline([\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('lgbmclassifier', lgbm_for_grid)\n",
    "    ])\n",
    "\n",
    "    # Define Parameter Grid\n",
    "    param_grid = {\n",
    "        'lgbmclassifier__n_estimators': [100, 250, 400],       # 3 options\n",
    "        'lgbmclassifier__learning_rate': [0.05, 0.1],          # 2 options\n",
    "        'lgbmclassifier__num_leaves': [21, 31, 41, 51],        # 4 options\n",
    "        'lgbmclassifier__reg_alpha': [0.1],                    # 1 option\n",
    "        'lgbmclassifier__reg_lambda': [0.1],                   # 1 option\n",
    "    # Let's keep subsampling fixed for now to limit combinations\n",
    "    # 'lgbmclassifier__subsample': [0.8, 0.9],\n",
    "    # 'lgbmclassifier__colsample_bytree': [0.8, 0.9]\n",
    "    }\n",
    "\n",
    "    mlflow.log_param(\"gridsearch_param_grid\", str(param_grid))\n",
    "\n",
    "    cv_strategy = StratifiedKFold(n_splits=3, shuffle=True, random_state=42) # 3 splits for faster grid search\n",
    "    \n",
    "    nan_handling_strategy = \"LGBM_internal\" # On laisse LightGBM gérer les NaNs\n",
    "\n",
    "    # GridSearchCV - scoring with 'roc_auc' to find robust params\n",
    "    grid_search = GridSearchCV(\n",
    "        estimator=pipeline_for_grid,\n",
    "        param_grid=param_grid,\n",
    "        scoring='roc_auc', # Focus on good probability ranking first\n",
    "        cv=cv_strategy,\n",
    "        verbose=2,\n",
    "        n_jobs=1 # Use multiple cores if possible\n",
    "    )\n",
    "\n",
    "    print(\"Starting GridSearchCV on X_train, y_train...\")\n",
    "    grid_search.fit(X_train_corr_filtered, y_train) # GridSearchCV takes X_train and y_train. It internally performs cross-validation (e.g., 3-fold or 5-fold). In our case 3-fold\n",
    "    # For each combination of parameters in the param_grid: It trains the pipeline on k-1 folds. \n",
    "    # It evaluates on the 1 held-out fold using the chosen scoring metric (e.g., ROC AUC, calculated using default 0.5 threshold for predictions within the scorer). It averages the scores for each parameter combination across all folds.\n",
    "    print(\"GridSearchCV complete.\")\n",
    "\n",
    "    # outputs us the best parameters it found that we store\n",
    "    best_params_from_grid = grid_search.best_params_\n",
    "    best_cv_score_grid = grid_search.best_score_\n",
    "\n",
    "    mlflow.log_params({f\"best_gs_{k}\": v for k, v in best_params_from_grid.items()}) # Log best params from gridseach\n",
    "\n",
    "    # for k, v in best_params_from_grid.items(): This part iterates through each key-value pair in the best_params_from_grid dictionary.\n",
    "    # In each iteration, k will be the parameter name (e.g., 'lgbmclassifier__n_estimators'). v will be the corresponding best value (e.g., 400).\n",
    "\n",
    "\n",
    "\n",
    "    mlflow.log_metric(\"gridsearch_best_cv_roc_auc\", best_cv_score_grid)\n",
    "\n",
    "    # --- IMPORTANT We then use the parameters it found to use with our model and then we will train our model on our data using these parameters ---\n",
    "    \n",
    "\n",
    "    # --- Definition des callbacks ---\n",
    "\n",
    "    stopping_rounds=200\n",
    "    verbose=100\n",
    "    early_stopping_metric = 'auc'\n",
    "\n",
    "    #liste de callbacks qu'on va mettre dans le fit pour dire quels callbacks notre modèle doit utiliser durant l'entrainement\n",
    "    callbacks_list = [lgb.early_stopping(stopping_rounds=stopping_rounds, verbose=verbose)] # Stop if val AUC doesn't improve for 200 rounds, print every 100 rounds    \n",
    "    \n",
    "    # Define the validation set for early stopping\n",
    "    eval_set = [(X_val_corr_filtered, y_val)]\n",
    "   \n",
    "    # --- Log Callbacks parameters\n",
    "\n",
    "    mlflow.log_param(\"early_stopping_enabled\", True)\n",
    "    mlflow.log_param(\"early_stopping_rounds\", stopping_rounds)\n",
    "    mlflow.log_param(\"early_stopping_metric\", early_stopping_metric)\n",
    "\n",
    "\n",
    "\n",
    "    # --- IMPORTANT --- Meme si LightGBM utilise par défaut binary logloss ici on va utiliser ROC AUC car :\n",
    "    # Log loss can sometimes be sensitive to outliers or poorly calibrated probabilities. It might not perfectly align with the final business metric you care about (which might be AUC, F1, precision, recall, etc.).\n",
    "    # ROC AUX a aussi ses désavantages : Cons: AUC is threshold-independent, so stopping based on it doesn't guarantee optimal performance at the specific threshold you might choose later (though it's usually highly correlated).\n",
    "    # Mais globalement AUC is a common and robust metric for evaluating binary classifier performance, especially with imbalanced datasets. It measures the model's ability to rank positive instances higher than negative ones, irrespective of the specific threshold. \n",
    "    # Stopping based on validation AUC ensures you stop when this ranking ability stops improving. Often aligns better with overall classification quality goals than log loss.\n",
    "    # Le seul vrai avantage d'utiliser la même métrique que celle que le modèle regarde pendant son entrainement ici la log loss c'est que :\n",
    "    # Directly related to the function the model is optimizing. Stopping based on validation log loss ensures you stop when the model's probabilistic predictions stop improving on unseen data according to that specific loss function.\n",
    "\n",
    "\n",
    "    # --- Important --- Etant donné que l'on utilise EarlyStopping on souhaite avoir assez d'itérations pour que EarlyStopping soit pertinent\n",
    "    # Donc malgré le fait que GridSearchCV nous ait trouvé une valeur pour n_estimators, on vasimplement la remplacer par une valeur élevée pour être sur que EarlyStopping fasse effet\n",
    "\n",
    "    # 1. Create the base dictionary from GridSearchCV results, stripping prefixes\n",
    "    \n",
    "    # In best_params_from_grid which is a dictionnary so we have key value pairs each key so the name of the parameter has the prefix lgbmclassifier__ which we remove for clarity\n",
    "\n",
    "    final_lgbm_params = {\n",
    "    key.replace('lgbmclassifier__', ''): value\n",
    "    for key, value in best_params_from_grid.items()\n",
    "    }\n",
    "\n",
    "    # 2. Add/Ensure the fixed base parameters are present because they were not in best_params_from_grid\n",
    "    #    This will add them if they weren't tuned\n",
    "    final_lgbm_params['class_weight'] = 'balanced'\n",
    "    final_lgbm_params['random_state'] = 42\n",
    "    final_lgbm_params['n_jobs'] = 1 # Changée en 1 pour soucis de mémoire\n",
    "\n",
    "    # 3. Explicitly set n_estimators to a high value for early stopping.\n",
    "    #    This will override the n_estimators value that came from GridSearchCV.\n",
    "    final_lgbm_params['n_estimators'] = 2000\n",
    "\n",
    "\n",
    "    # --- Define Model & Pipeline ---\n",
    "    pipeline_lgbm_final = make_pipeline( # Renamed to avoid confusion with grid search pipeline\n",
    "    StandardScaler(),\n",
    "    lgb.LGBMClassifier(**final_lgbm_params) # Use the defined parameters ** is for dictionnary unpacking\n",
    "    )\n",
    "\n",
    "    mlflow.log_params({f\"best_gs_final_{k}\": v for k, v in final_lgbm_params.items()}) # Log best params with sligh adjustments\n",
    "\n",
    "    # --- Log Parameters ---\n",
    "    mlflow.log_param(\"model_type\", \"LightGBM\") # Updated\n",
    "    mlflow.log_param(\"imputation_merge_nans\", \"ZeroFill\") # Example for merge NaNs\n",
    "    mlflow.log_param(\"nan_handling_model\", nan_handling_strategy) # Log NaN strategy\n",
    "    mlflow.log_param(\"scaling\", \"StandardScaler\")\n",
    "    mlflow.log_param(\"class_weight\", \"balanced\")\n",
    "    mlflow.log_param(\"random_state\", 42)\n",
    "    mlflow.log_param(\"train_val_split\", 0.2)\n",
    "\n",
    "    # --- Train model ---\n",
    "\n",
    "    print(\"Training final LGBM model with early stopping...\")\n",
    "\n",
    "    pipeline_lgbm_final.fit(\n",
    "        X_train_corr_filtered, y_train,\n",
    "        # Pass eval_set for early stopping\n",
    "        lgbmclassifier__eval_set=eval_set, #eval_set est une liste contenant des validation sets (as tuples of (X_val, y_val)) pour controler/monitor performances. Early stopping uses this to decide when to stop.\n",
    "        lgbmclassifier__eval_metric=early_stopping_metric,\n",
    "        # Use callbacks argument for early stopping\n",
    "        lgbmclassifier__callbacks=callbacks_list\n",
    "        )\n",
    "    \n",
    "    print(\"Training part done\")\n",
    "\n",
    "    # --- After fitting ---\n",
    "    \n",
    "    #  --- IMPORTANT ---best_iteration as a metric tells us how many trees were actually used in the final model selected by early stopping\n",
    "    fitted_lgbm = pipeline_lgbm_final.named_steps['lgbmclassifier']\n",
    "    if fitted_lgbm.best_iteration_:\n",
    "        mlflow.log_metric(\"best_iteration\", fitted_lgbm.best_iteration_)\n",
    "        # Optional: Update the n_estimators param if you want to reflect the stopped value\n",
    "        # mlflow.log_param(\"actual_n_estimators\", fitted_lgbm.best_iteration_)\n",
    "    else:\n",
    "        # Log if early stopping didn't trigger (ran full n_estimators)\n",
    "        mlflow.log_metric(\"best_iteration\", fitted_lgbm.n_estimators)\n",
    "        # mlflow.log_param(\"actual_n_estimators\", fitted_lgbm.n_estimators)\n",
    "\n",
    "    # --- Predict & Calcul des métriques ---\n",
    "    y_pred = pipeline_lgbm_final.predict(X_val_corr_filtered)\n",
    "    y_proba = pipeline_lgbm_final.predict_proba(X_val_corr_filtered)[:, 1] # Probabilities for class 1\n",
    "\n",
    "    # --- Find the best threshold to minimize business cost ---\n",
    "    \n",
    "    # 1. Defining a range of thresholds\n",
    "    thresholds_to_try = np.linspace(0.01, 0.99, 100) # Trying 100 thresholds\n",
    "\n",
    "    # 2. Initialize variables to store the best findings\n",
    "    min_val_cost = float('inf') # Initialize minimum cost to positive infinity (so any real cost will be lower)\n",
    "    best_val_threshold_cost = 0.5 # Initialize best threshold to a default (e.g., 0.5)\n",
    "    y_pred_val_at_min_cost = None # To store the predictions made using the best threshold\n",
    "\n",
    "    # 3. Loop through each threshold\n",
    "    print(\"Optimizing threshold for business cost on validation set...\")\n",
    "    for threshold in thresholds_to_try:\n",
    "    # 3a. Convert probabilities to class predictions based on the current threshold\n",
    "        y_pred_temp_val = (y_proba >= threshold).astype(int)\n",
    "    # If y_val_proba is >= current threshold, predict 1 (default), else predict 0 (repay)\n",
    "\n",
    "    # 3b. Calculate the business cost using these temporary predictions\n",
    "        current_val_cost = calculate_business_cost(y_val, y_pred_temp_val,\n",
    "                                             cost_fn=10, cost_fp=1, cost_tn=(-1))\n",
    "\n",
    "    # 3c. Check if this threshold gives a lower cost\n",
    "        if current_val_cost < min_val_cost:           # Initial value is positive infinity so first one always registered an then only lower business costs can replace it\n",
    "            min_val_cost = current_val_cost           # Update minimum cost\n",
    "            best_val_threshold_cost = threshold       # Update best threshold\n",
    "            y_pred_val_at_min_cost = y_pred_temp_val  # Store these predictions\n",
    "\n",
    "    # 4. Output the results\n",
    "    print(f\"\\nBest threshold (validation) to minimize business cost: {best_val_threshold_cost:.4f}\")\n",
    "    print(f\"Minimum business cost on validation set: {min_val_cost}\")\n",
    "    # y_pred_val_at_min_cost now holds the predictions that achieve this minimum cost\n",
    "\n",
    "    accuracy = accuracy_score(y_val, y_pred_val_at_min_cost)\n",
    "    f1 = f1_score(y_val, y_pred_val_at_min_cost) # Default F1 for class 1\n",
    "    roc_auc = roc_auc_score(y_val, y_proba)\n",
    "    report = classification_report(y_val, y_pred_val_at_min_cost, output_dict=True) # Get report as dict\n",
    "\n",
    "    # --- Log métriques ---\n",
    "    mlflow.log_metric(\"best_business_cost_obtained\", min_val_cost)\n",
    "    mlflow.log_metric(\"best_threshold_to_minimize_business_cost\", best_val_threshold_cost)\n",
    "    mlflow.log_metric(\"val_accuracy\", accuracy)\n",
    "    mlflow.log_metric(\"val_f1_score\", f1)\n",
    "    mlflow.log_metric(\"val_roc_auc\", roc_auc)\n",
    "    # metrics from classification report\n",
    "    mlflow.log_metric(\"val_precision_0\", report['0']['precision'])\n",
    "    mlflow.log_metric(\"val_recall_0\", report['0']['recall'])\n",
    "    mlflow.log_metric(\"val_f1_0\", report['0']['f1-score'])\n",
    "    mlflow.log_metric(\"val_precision_1\", report['1']['precision'])\n",
    "    mlflow.log_metric(\"val_recall_1\", report['1']['recall'])\n",
    "    mlflow.log_metric(\"val_f1_1\", report['1']['f1-score'])\n",
    "\n",
    "    # --- Input Example ---\n",
    "    input_example = X_train_corr_filtered.head(5) #Input example = small sample of valid input data (like one or a few rows from X_train or X_val DataFrame) that demonstrates the expected format.\n",
    "    #Sert a si jamais on souhaite se resservir du modèle à ce qu'il vérifie que les données d'entrée aient le format attendu ici DataFrame Pandas\n",
    "\n",
    "    # --- Log Model ---\n",
    "    mlflow.lightgbm.log_model(\n",
    "        lgb_model=pipeline_lgbm_final.named_steps['lgbmclassifier'], # Log the LGBM step\n",
    "        artifact_path=\"lightgbm_model\",\n",
    "        input_example=X_train_corr_filtered.head(5) # Provide example\n",
    "        )\n",
    "\n",
    "\n",
    "    # --- Log Artifacts (Example: Confusion Matrix) ---\n",
    "    cm = confusion_matrix(y_val, y_pred_val_at_min_cost, labels=pipeline_lgbm_final.classes_)\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=pipeline_lgbm_final.classes_)\n",
    "    disp.plot()\n",
    "    plt.title(f\"Confusion Matrix LGBM (Validation Set)\")\n",
    "    cm_path = \"confusion_matrix_lgbm_val.png\"\n",
    "    plt.savefig(cm_path)\n",
    "    mlflow.log_artifact(cm_path)\n",
    "    plt.close() # Close the plot to prevent display in notebook output if desired\n",
    "\n",
    "    print(f\"Run ID: {mlflow.active_run().info.run_id} logged.\")\n",
    "    print(f\"Validation ROC-AUC: {roc_auc:.4f}\")\n",
    "    print(f\"Business cost: {min_val_cost}\")\n",
    "    print(classification_report(y_val, y_pred_val_at_min_cost))\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b9cd169",
   "metadata": {},
   "source": [
    "# Analyse de la feature importance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "299e21b8",
   "metadata": {},
   "source": [
    "Apres avoir testé en enlevant les variables trop corrélées entre elles on se retrouve avec un business cost moins bon en ayant enlevé ces variables on va donc réaliser l'analyse de la feature importance avec le modèle qui garde toutes les variables et on va essayer d'enlever le bruit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "3ebeef4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_id_to_load = \"7e69e332cab3437888b88958c8c24fec\" # Correspond au modèle avec toutes les données gridsearchCV et threshold optimization\n",
    "model_artifact_path = \"lightgbm_model\" # L'artifact path utilisé"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "1d68e5d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_features = X_train.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "03b77265",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading LightGBM model from MLflow run ID: 7e69e332cab3437888b88958c8c24fec, artifact path: lightgbm_model\n",
      "\n",
      "Extracting feature importances...\n",
      "\n",
      "Top 20 Feature Importances:\n",
      "                                                           feature  importance\n",
      "30                                                    EXT_SOURCE_1         188\n",
      "31                                                    EXT_SOURCE_2         164\n",
      "32                                                    EXT_SOURCE_3         133\n",
      "5                                                       AMT_CREDIT          94\n",
      "9                                                       DAYS_BIRTH          84\n",
      "599                            credit_card_balance_AMT_PAYMENT_min          74\n",
      "6                                                      AMT_ANNUITY          71\n",
      "7                                                  AMT_GOODS_PRICE          58\n",
      "600                            credit_card_balance_AMT_PAYMENT_sum          54\n",
      "368                                              PROPORTION_REPAID          52\n",
      "10                                                   DAYS_EMPLOYED          51\n",
      "1091             credit_card_balance_CNT_DRAWINGS_ATM_CURRENT_mean          47\n",
      "993                    POS_CASH_balance_CNT_INSTALMENT_FUTURE_mean          45\n",
      "13                                                     OWN_CAR_AGE          44\n",
      "107                                                  CODE_GENDER_F          43\n",
      "777   previous_application_NAME_CONTRACT_STATUS_Refused_count_norm          37\n",
      "662                          previous_application_CNT_PAYMENT_mean          33\n",
      "1003                              POS_CASH_balance_SK_DPD_DEF_mean          33\n",
      "124                           NAME_EDUCATION_TYPE_Higher_education          28\n",
      "240                                         bureau_DAYS_CREDIT_max          28\n"
     ]
    }
   ],
   "source": [
    "# --- Load the LightGBM model from MLflow --\n",
    "print(f\"Loading LightGBM model from MLflow run ID: {run_id_to_load}, artifact path: {model_artifact_path}\")\n",
    "loaded_lgbm_model = mlflow.lightgbm.load_model(f\"runs:/{run_id_to_load}/{model_artifact_path}\")\n",
    "\n",
    "# --- Get Feature Importances ---\n",
    "print(\"\\nExtracting feature importances...\")\n",
    "importances = loaded_lgbm_model.feature_importances_\n",
    "\n",
    "# --- Get Feature Names from the X_train used for THAT run ---\n",
    "feature_names = X_train_features.columns.tolist()\n",
    "\n",
    "# --- Création du DataFrames quantifiant l'importance des features\n",
    "feature_importance_df = pd.DataFrame({'feature': feature_names, 'importance': importances})\n",
    "feature_importance_df = feature_importance_df.sort_values(by='importance', ascending=False)\n",
    "\n",
    "print(\"\\nTop 20 Feature Importances:\")\n",
    "print(feature_importance_df.head(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "c5fc23f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x1800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot feature importances\n",
    "plt.figure(figsize=(10, max(15, len(feature_importance_df.head(60)) * 0.3))) # Dynamic height\n",
    "sns.barplot(x='importance', y='feature', data=feature_importance_df.head(60)) # Plot top 60 or fewer\n",
    "plt.title(f'LightGBM Feature Importances (Run ID: {run_id_to_load[:8]}...)') # Shorten run_id for title\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "1f643da6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of features with ZERO importance: 878\n"
     ]
    }
   ],
   "source": [
    "zero_importance_features = feature_importance_df[feature_importance_df['importance'] == 0]['feature'].tolist()\n",
    "print(f\"Number of features with ZERO importance: {len(zero_importance_features)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8abcfb02",
   "metadata": {},
   "source": [
    "On va d'abord supprimer toutes les variables qui ont 0 d'importance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "3f61ce50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of features with NON-ZERO importance to keep: 261\n"
     ]
    }
   ],
   "source": [
    "# Get the list of features to KEEP\n",
    "features_to_keep = feature_importance_df[feature_importance_df['importance'] > 0]['feature'].tolist()\n",
    "print(f\"Number of features with NON-ZERO importance to keep: {len(features_to_keep)}\")\n",
    "\n",
    "# Create new DataFrames with only the selected features\n",
    "# Ensure the X_train/X_val here are the same ones used to train the model whose importances you extracted\n",
    "X_train_filtered_with_non_null_importance = X_train[features_to_keep]\n",
    "X_val_filtered_with_non_null_importance = X_val[features_to_keep]\n",
    "# X_test_fi_filtered = X_test[features_to_keep] # For later"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "587e6923",
   "metadata": {},
   "source": [
    "# Run LightGBM avec Features ayant importance nulle filtrées"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be31b3f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Stage 1: Hyperparameter Tuning with GridSearchCV ---\n",
      "Starting GridSearchCV on X_train, y_train...\n",
      "Fitting 3 folds for each of 24 candidates, totalling 72 fits\n",
      "[LightGBM] [Info] Number of positive: 13240, number of negative: 150765\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.229473 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 46157\n",
      "[LightGBM] [Info] Number of data points in the train set: 164005, number of used features: 261\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[CV] END lgbmclassifier__learning_rate=0.05, lgbmclassifier__n_estimators=100, lgbmclassifier__num_leaves=21, lgbmclassifier__reg_alpha=0.1, lgbmclassifier__reg_lambda=0.1; total time=  24.6s\n",
      "[LightGBM] [Info] Number of positive: 13240, number of negative: 150765\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.510013 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 46253\n",
      "[LightGBM] [Info] Number of data points in the train set: 164005, number of used features: 261\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[CV] END lgbmclassifier__learning_rate=0.05, lgbmclassifier__n_estimators=100, lgbmclassifier__num_leaves=21, lgbmclassifier__reg_alpha=0.1, lgbmclassifier__reg_lambda=0.1; total time=  26.5s\n",
      "[LightGBM] [Info] Number of positive: 13240, number of negative: 150766\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.162308 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 46309\n",
      "[LightGBM] [Info] Number of data points in the train set: 164006, number of used features: 261\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "[CV] END lgbmclassifier__learning_rate=0.05, lgbmclassifier__n_estimators=100, lgbmclassifier__num_leaves=21, lgbmclassifier__reg_alpha=0.1, lgbmclassifier__reg_lambda=0.1; total time=  23.9s\n",
      "[LightGBM] [Info] Number of positive: 13240, number of negative: 150765\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.151132 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 46157\n",
      "[LightGBM] [Info] Number of data points in the train set: 164005, number of used features: 261\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[CV] END lgbmclassifier__learning_rate=0.05, lgbmclassifier__n_estimators=100, lgbmclassifier__num_leaves=31, lgbmclassifier__reg_alpha=0.1, lgbmclassifier__reg_lambda=0.1; total time=  26.1s\n",
      "[LightGBM] [Info] Number of positive: 13240, number of negative: 150765\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.155065 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 46253\n",
      "[LightGBM] [Info] Number of data points in the train set: 164005, number of used features: 261\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[CV] END lgbmclassifier__learning_rate=0.05, lgbmclassifier__n_estimators=100, lgbmclassifier__num_leaves=31, lgbmclassifier__reg_alpha=0.1, lgbmclassifier__reg_lambda=0.1; total time=  26.8s\n",
      "[LightGBM] [Info] Number of positive: 13240, number of negative: 150766\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.143621 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 46309\n",
      "[LightGBM] [Info] Number of data points in the train set: 164006, number of used features: 261\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "[CV] END lgbmclassifier__learning_rate=0.05, lgbmclassifier__n_estimators=100, lgbmclassifier__num_leaves=31, lgbmclassifier__reg_alpha=0.1, lgbmclassifier__reg_lambda=0.1; total time=  23.6s\n",
      "[LightGBM] [Info] Number of positive: 13240, number of negative: 150765\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.145897 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 46157\n",
      "[LightGBM] [Info] Number of data points in the train set: 164005, number of used features: 261\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[CV] END lgbmclassifier__learning_rate=0.05, lgbmclassifier__n_estimators=100, lgbmclassifier__num_leaves=41, lgbmclassifier__reg_alpha=0.1, lgbmclassifier__reg_lambda=0.1; total time=  25.9s\n",
      "[LightGBM] [Info] Number of positive: 13240, number of negative: 150765\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.143169 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 46253\n",
      "[LightGBM] [Info] Number of data points in the train set: 164005, number of used features: 261\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[CV] END lgbmclassifier__learning_rate=0.05, lgbmclassifier__n_estimators=100, lgbmclassifier__num_leaves=41, lgbmclassifier__reg_alpha=0.1, lgbmclassifier__reg_lambda=0.1; total time=  25.4s\n",
      "[LightGBM] [Info] Number of positive: 13240, number of negative: 150766\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.142345 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 46309\n",
      "[LightGBM] [Info] Number of data points in the train set: 164006, number of used features: 261\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "[CV] END lgbmclassifier__learning_rate=0.05, lgbmclassifier__n_estimators=100, lgbmclassifier__num_leaves=41, lgbmclassifier__reg_alpha=0.1, lgbmclassifier__reg_lambda=0.1; total time=  27.1s\n",
      "[LightGBM] [Info] Number of positive: 13240, number of negative: 150765\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.186235 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 46157\n",
      "[LightGBM] [Info] Number of data points in the train set: 164005, number of used features: 261\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[CV] END lgbmclassifier__learning_rate=0.05, lgbmclassifier__n_estimators=100, lgbmclassifier__num_leaves=51, lgbmclassifier__reg_alpha=0.1, lgbmclassifier__reg_lambda=0.1; total time=  29.3s\n",
      "[LightGBM] [Info] Number of positive: 13240, number of negative: 150765\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.140734 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 46253\n",
      "[LightGBM] [Info] Number of data points in the train set: 164005, number of used features: 261\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[CV] END lgbmclassifier__learning_rate=0.05, lgbmclassifier__n_estimators=100, lgbmclassifier__num_leaves=51, lgbmclassifier__reg_alpha=0.1, lgbmclassifier__reg_lambda=0.1; total time=  29.7s\n",
      "[LightGBM] [Info] Number of positive: 13240, number of negative: 150766\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.141862 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 46309\n",
      "[LightGBM] [Info] Number of data points in the train set: 164006, number of used features: 261\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "[CV] END lgbmclassifier__learning_rate=0.05, lgbmclassifier__n_estimators=100, lgbmclassifier__num_leaves=51, lgbmclassifier__reg_alpha=0.1, lgbmclassifier__reg_lambda=0.1; total time=  28.2s\n",
      "[LightGBM] [Info] Number of positive: 13240, number of negative: 150765\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.152579 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 46157\n",
      "[LightGBM] [Info] Number of data points in the train set: 164005, number of used features: 261\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[CV] END lgbmclassifier__learning_rate=0.05, lgbmclassifier__n_estimators=250, lgbmclassifier__num_leaves=21, lgbmclassifier__reg_alpha=0.1, lgbmclassifier__reg_lambda=0.1; total time=  42.6s\n",
      "[LightGBM] [Info] Number of positive: 13240, number of negative: 150765\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.145031 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 46253\n",
      "[LightGBM] [Info] Number of data points in the train set: 164005, number of used features: 261\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[CV] END lgbmclassifier__learning_rate=0.05, lgbmclassifier__n_estimators=250, lgbmclassifier__num_leaves=21, lgbmclassifier__reg_alpha=0.1, lgbmclassifier__reg_lambda=0.1; total time=  38.7s\n",
      "[LightGBM] [Info] Number of positive: 13240, number of negative: 150766\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.149604 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 46309\n",
      "[LightGBM] [Info] Number of data points in the train set: 164006, number of used features: 261\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "[CV] END lgbmclassifier__learning_rate=0.05, lgbmclassifier__n_estimators=250, lgbmclassifier__num_leaves=21, lgbmclassifier__reg_alpha=0.1, lgbmclassifier__reg_lambda=0.1; total time=  37.3s\n",
      "[LightGBM] [Info] Number of positive: 13240, number of negative: 150765\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.141829 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 46157\n",
      "[LightGBM] [Info] Number of data points in the train set: 164005, number of used features: 261\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[CV] END lgbmclassifier__learning_rate=0.05, lgbmclassifier__n_estimators=250, lgbmclassifier__num_leaves=31, lgbmclassifier__reg_alpha=0.1, lgbmclassifier__reg_lambda=0.1; total time=  41.4s\n",
      "[LightGBM] [Info] Number of positive: 13240, number of negative: 150765\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.140900 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 46253\n",
      "[LightGBM] [Info] Number of data points in the train set: 164005, number of used features: 261\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[CV] END lgbmclassifier__learning_rate=0.05, lgbmclassifier__n_estimators=250, lgbmclassifier__num_leaves=31, lgbmclassifier__reg_alpha=0.1, lgbmclassifier__reg_lambda=0.1; total time=  41.4s\n",
      "[LightGBM] [Info] Number of positive: 13240, number of negative: 150766\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.147977 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 46309\n",
      "[LightGBM] [Info] Number of data points in the train set: 164006, number of used features: 261\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "[CV] END lgbmclassifier__learning_rate=0.05, lgbmclassifier__n_estimators=250, lgbmclassifier__num_leaves=31, lgbmclassifier__reg_alpha=0.1, lgbmclassifier__reg_lambda=0.1; total time=  41.2s\n",
      "[LightGBM] [Info] Number of positive: 13240, number of negative: 150765\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.139890 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 46157\n",
      "[LightGBM] [Info] Number of data points in the train set: 164005, number of used features: 261\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[CV] END lgbmclassifier__learning_rate=0.05, lgbmclassifier__n_estimators=250, lgbmclassifier__num_leaves=41, lgbmclassifier__reg_alpha=0.1, lgbmclassifier__reg_lambda=0.1; total time=  45.5s\n",
      "[LightGBM] [Info] Number of positive: 13240, number of negative: 150765\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.140506 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 46253\n",
      "[LightGBM] [Info] Number of data points in the train set: 164005, number of used features: 261\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[CV] END lgbmclassifier__learning_rate=0.05, lgbmclassifier__n_estimators=250, lgbmclassifier__num_leaves=41, lgbmclassifier__reg_alpha=0.1, lgbmclassifier__reg_lambda=0.1; total time=  45.8s\n",
      "[LightGBM] [Info] Number of positive: 13240, number of negative: 150766\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.142209 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 46309\n",
      "[LightGBM] [Info] Number of data points in the train set: 164006, number of used features: 261\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "[CV] END lgbmclassifier__learning_rate=0.05, lgbmclassifier__n_estimators=250, lgbmclassifier__num_leaves=41, lgbmclassifier__reg_alpha=0.1, lgbmclassifier__reg_lambda=0.1; total time=  45.1s\n",
      "[LightGBM] [Info] Number of positive: 13240, number of negative: 150765\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.144139 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 46157\n",
      "[LightGBM] [Info] Number of data points in the train set: 164005, number of used features: 261\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[CV] END lgbmclassifier__learning_rate=0.05, lgbmclassifier__n_estimators=250, lgbmclassifier__num_leaves=51, lgbmclassifier__reg_alpha=0.1, lgbmclassifier__reg_lambda=0.1; total time=  49.3s\n",
      "[LightGBM] [Info] Number of positive: 13240, number of negative: 150765\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.141205 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 46253\n",
      "[LightGBM] [Info] Number of data points in the train set: 164005, number of used features: 261\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[CV] END lgbmclassifier__learning_rate=0.05, lgbmclassifier__n_estimators=250, lgbmclassifier__num_leaves=51, lgbmclassifier__reg_alpha=0.1, lgbmclassifier__reg_lambda=0.1; total time=  49.4s\n",
      "[LightGBM] [Info] Number of positive: 13240, number of negative: 150766\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.141689 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 46309\n",
      "[LightGBM] [Info] Number of data points in the train set: 164006, number of used features: 261\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "[CV] END lgbmclassifier__learning_rate=0.05, lgbmclassifier__n_estimators=250, lgbmclassifier__num_leaves=51, lgbmclassifier__reg_alpha=0.1, lgbmclassifier__reg_lambda=0.1; total time=  49.1s\n",
      "[LightGBM] [Info] Number of positive: 13240, number of negative: 150765\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.140888 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 46157\n",
      "[LightGBM] [Info] Number of data points in the train set: 164005, number of used features: 261\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[CV] END lgbmclassifier__learning_rate=0.05, lgbmclassifier__n_estimators=400, lgbmclassifier__num_leaves=21, lgbmclassifier__reg_alpha=0.1, lgbmclassifier__reg_lambda=0.1; total time=  49.9s\n",
      "[LightGBM] [Info] Number of positive: 13240, number of negative: 150765\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.140891 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 46253\n",
      "[LightGBM] [Info] Number of data points in the train set: 164005, number of used features: 261\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[CV] END lgbmclassifier__learning_rate=0.05, lgbmclassifier__n_estimators=400, lgbmclassifier__num_leaves=21, lgbmclassifier__reg_alpha=0.1, lgbmclassifier__reg_lambda=0.1; total time=  49.3s\n",
      "[LightGBM] [Info] Number of positive: 13240, number of negative: 150766\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.143265 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 46309\n",
      "[LightGBM] [Info] Number of data points in the train set: 164006, number of used features: 261\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "[CV] END lgbmclassifier__learning_rate=0.05, lgbmclassifier__n_estimators=400, lgbmclassifier__num_leaves=21, lgbmclassifier__reg_alpha=0.1, lgbmclassifier__reg_lambda=0.1; total time=  50.4s\n",
      "[LightGBM] [Info] Number of positive: 13240, number of negative: 150765\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.151565 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 46157\n",
      "[LightGBM] [Info] Number of data points in the train set: 164005, number of used features: 261\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[CV] END lgbmclassifier__learning_rate=0.05, lgbmclassifier__n_estimators=400, lgbmclassifier__num_leaves=31, lgbmclassifier__reg_alpha=0.1, lgbmclassifier__reg_lambda=0.1; total time=  58.0s\n",
      "[LightGBM] [Info] Number of positive: 13240, number of negative: 150765\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.145097 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 46253\n",
      "[LightGBM] [Info] Number of data points in the train set: 164005, number of used features: 261\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[CV] END lgbmclassifier__learning_rate=0.05, lgbmclassifier__n_estimators=400, lgbmclassifier__num_leaves=31, lgbmclassifier__reg_alpha=0.1, lgbmclassifier__reg_lambda=0.1; total time=  58.0s\n",
      "[LightGBM] [Info] Number of positive: 13240, number of negative: 150766\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.144555 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 46309\n",
      "[LightGBM] [Info] Number of data points in the train set: 164006, number of used features: 261\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "[CV] END lgbmclassifier__learning_rate=0.05, lgbmclassifier__n_estimators=400, lgbmclassifier__num_leaves=31, lgbmclassifier__reg_alpha=0.1, lgbmclassifier__reg_lambda=0.1; total time=  57.6s\n",
      "[LightGBM] [Info] Number of positive: 13240, number of negative: 150765\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.145886 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 46157\n",
      "[LightGBM] [Info] Number of data points in the train set: 164005, number of used features: 261\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[CV] END lgbmclassifier__learning_rate=0.05, lgbmclassifier__n_estimators=400, lgbmclassifier__num_leaves=41, lgbmclassifier__reg_alpha=0.1, lgbmclassifier__reg_lambda=0.1; total time= 1.1min\n",
      "[LightGBM] [Info] Number of positive: 13240, number of negative: 150765\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.143910 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 46253\n",
      "[LightGBM] [Info] Number of data points in the train set: 164005, number of used features: 261\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[CV] END lgbmclassifier__learning_rate=0.05, lgbmclassifier__n_estimators=400, lgbmclassifier__num_leaves=41, lgbmclassifier__reg_alpha=0.1, lgbmclassifier__reg_lambda=0.1; total time= 1.1min\n",
      "[LightGBM] [Info] Number of positive: 13240, number of negative: 150766\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.148437 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 46309\n",
      "[LightGBM] [Info] Number of data points in the train set: 164006, number of used features: 261\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "[CV] END lgbmclassifier__learning_rate=0.05, lgbmclassifier__n_estimators=400, lgbmclassifier__num_leaves=41, lgbmclassifier__reg_alpha=0.1, lgbmclassifier__reg_lambda=0.1; total time= 1.1min\n",
      "[LightGBM] [Info] Number of positive: 13240, number of negative: 150765\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.493121 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 46157\n",
      "[LightGBM] [Info] Number of data points in the train set: 164005, number of used features: 261\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[CV] END lgbmclassifier__learning_rate=0.05, lgbmclassifier__n_estimators=400, lgbmclassifier__num_leaves=51, lgbmclassifier__reg_alpha=0.1, lgbmclassifier__reg_lambda=0.1; total time= 1.4min\n",
      "[LightGBM] [Info] Number of positive: 13240, number of negative: 150765\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.145410 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 46253\n",
      "[LightGBM] [Info] Number of data points in the train set: 164005, number of used features: 261\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[CV] END lgbmclassifier__learning_rate=0.05, lgbmclassifier__n_estimators=400, lgbmclassifier__num_leaves=51, lgbmclassifier__reg_alpha=0.1, lgbmclassifier__reg_lambda=0.1; total time= 1.1min\n",
      "[LightGBM] [Info] Number of positive: 13240, number of negative: 150766\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.146282 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 46309\n",
      "[LightGBM] [Info] Number of data points in the train set: 164006, number of used features: 261\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "[CV] END lgbmclassifier__learning_rate=0.05, lgbmclassifier__n_estimators=400, lgbmclassifier__num_leaves=51, lgbmclassifier__reg_alpha=0.1, lgbmclassifier__reg_lambda=0.1; total time= 1.1min\n",
      "[LightGBM] [Info] Number of positive: 13240, number of negative: 150765\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.146672 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 46157\n",
      "[LightGBM] [Info] Number of data points in the train set: 164005, number of used features: 261\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[CV] END lgbmclassifier__learning_rate=0.1, lgbmclassifier__n_estimators=100, lgbmclassifier__num_leaves=21, lgbmclassifier__reg_alpha=0.1, lgbmclassifier__reg_lambda=0.1; total time=  21.0s\n",
      "[LightGBM] [Info] Number of positive: 13240, number of negative: 150765\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.144676 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 46253\n",
      "[LightGBM] [Info] Number of data points in the train set: 164005, number of used features: 261\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[CV] END lgbmclassifier__learning_rate=0.1, lgbmclassifier__n_estimators=100, lgbmclassifier__num_leaves=21, lgbmclassifier__reg_alpha=0.1, lgbmclassifier__reg_lambda=0.1; total time=  21.2s\n",
      "[LightGBM] [Info] Number of positive: 13240, number of negative: 150766\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.144085 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 46309\n",
      "[LightGBM] [Info] Number of data points in the train set: 164006, number of used features: 261\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "[CV] END lgbmclassifier__learning_rate=0.1, lgbmclassifier__n_estimators=100, lgbmclassifier__num_leaves=21, lgbmclassifier__reg_alpha=0.1, lgbmclassifier__reg_lambda=0.1; total time=  20.6s\n",
      "[LightGBM] [Info] Number of positive: 13240, number of negative: 150765\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.152766 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 46157\n",
      "[LightGBM] [Info] Number of data points in the train set: 164005, number of used features: 261\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[CV] END lgbmclassifier__learning_rate=0.1, lgbmclassifier__n_estimators=100, lgbmclassifier__num_leaves=31, lgbmclassifier__reg_alpha=0.1, lgbmclassifier__reg_lambda=0.1; total time=  23.1s\n",
      "[LightGBM] [Info] Number of positive: 13240, number of negative: 150765\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.146002 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 46253\n",
      "[LightGBM] [Info] Number of data points in the train set: 164005, number of used features: 261\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[CV] END lgbmclassifier__learning_rate=0.1, lgbmclassifier__n_estimators=100, lgbmclassifier__num_leaves=31, lgbmclassifier__reg_alpha=0.1, lgbmclassifier__reg_lambda=0.1; total time=  23.8s\n",
      "[LightGBM] [Info] Number of positive: 13240, number of negative: 150766\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.145211 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 46309\n",
      "[LightGBM] [Info] Number of data points in the train set: 164006, number of used features: 261\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "[CV] END lgbmclassifier__learning_rate=0.1, lgbmclassifier__n_estimators=100, lgbmclassifier__num_leaves=31, lgbmclassifier__reg_alpha=0.1, lgbmclassifier__reg_lambda=0.1; total time=  23.0s\n",
      "[LightGBM] [Info] Number of positive: 13240, number of negative: 150765\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.151640 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 46157\n",
      "[LightGBM] [Info] Number of data points in the train set: 164005, number of used features: 261\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[CV] END lgbmclassifier__learning_rate=0.1, lgbmclassifier__n_estimators=100, lgbmclassifier__num_leaves=41, lgbmclassifier__reg_alpha=0.1, lgbmclassifier__reg_lambda=0.1; total time=  25.0s\n",
      "[LightGBM] [Info] Number of positive: 13240, number of negative: 150765\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.148842 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 46253\n",
      "[LightGBM] [Info] Number of data points in the train set: 164005, number of used features: 261\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[CV] END lgbmclassifier__learning_rate=0.1, lgbmclassifier__n_estimators=100, lgbmclassifier__num_leaves=41, lgbmclassifier__reg_alpha=0.1, lgbmclassifier__reg_lambda=0.1; total time=  24.4s\n",
      "[LightGBM] [Info] Number of positive: 13240, number of negative: 150766\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.140631 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 46309\n",
      "[LightGBM] [Info] Number of data points in the train set: 164006, number of used features: 261\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "[CV] END lgbmclassifier__learning_rate=0.1, lgbmclassifier__n_estimators=100, lgbmclassifier__num_leaves=41, lgbmclassifier__reg_alpha=0.1, lgbmclassifier__reg_lambda=0.1; total time=  23.9s\n",
      "[LightGBM] [Info] Number of positive: 13240, number of negative: 150765\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.139877 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 46157\n",
      "[LightGBM] [Info] Number of data points in the train set: 164005, number of used features: 261\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[CV] END lgbmclassifier__learning_rate=0.1, lgbmclassifier__n_estimators=100, lgbmclassifier__num_leaves=51, lgbmclassifier__reg_alpha=0.1, lgbmclassifier__reg_lambda=0.1; total time=  24.8s\n",
      "[LightGBM] [Info] Number of positive: 13240, number of negative: 150765\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.140365 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 46253\n",
      "[LightGBM] [Info] Number of data points in the train set: 164005, number of used features: 261\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[CV] END lgbmclassifier__learning_rate=0.1, lgbmclassifier__n_estimators=100, lgbmclassifier__num_leaves=51, lgbmclassifier__reg_alpha=0.1, lgbmclassifier__reg_lambda=0.1; total time=  25.0s\n",
      "[LightGBM] [Info] Number of positive: 13240, number of negative: 150766\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.720241 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 46309\n",
      "[LightGBM] [Info] Number of data points in the train set: 164006, number of used features: 261\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "[CV] END lgbmclassifier__learning_rate=0.1, lgbmclassifier__n_estimators=100, lgbmclassifier__num_leaves=51, lgbmclassifier__reg_alpha=0.1, lgbmclassifier__reg_lambda=0.1; total time=  30.8s\n",
      "[LightGBM] [Info] Number of positive: 13240, number of negative: 150765\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.175488 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 46157\n",
      "[LightGBM] [Info] Number of data points in the train set: 164005, number of used features: 261\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[CV] END lgbmclassifier__learning_rate=0.1, lgbmclassifier__n_estimators=250, lgbmclassifier__num_leaves=21, lgbmclassifier__reg_alpha=0.1, lgbmclassifier__reg_lambda=0.1; total time=  32.8s\n",
      "[LightGBM] [Info] Number of positive: 13240, number of negative: 150765\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.141587 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 46253\n",
      "[LightGBM] [Info] Number of data points in the train set: 164005, number of used features: 261\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[CV] END lgbmclassifier__learning_rate=0.1, lgbmclassifier__n_estimators=250, lgbmclassifier__num_leaves=21, lgbmclassifier__reg_alpha=0.1, lgbmclassifier__reg_lambda=0.1; total time=  33.4s\n",
      "[LightGBM] [Info] Number of positive: 13240, number of negative: 150766\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.140985 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 46309\n",
      "[LightGBM] [Info] Number of data points in the train set: 164006, number of used features: 261\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "[CV] END lgbmclassifier__learning_rate=0.1, lgbmclassifier__n_estimators=250, lgbmclassifier__num_leaves=21, lgbmclassifier__reg_alpha=0.1, lgbmclassifier__reg_lambda=0.1; total time=  32.8s\n",
      "[LightGBM] [Info] Number of positive: 13240, number of negative: 150765\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.140685 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 46157\n",
      "[LightGBM] [Info] Number of data points in the train set: 164005, number of used features: 261\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[CV] END lgbmclassifier__learning_rate=0.1, lgbmclassifier__n_estimators=250, lgbmclassifier__num_leaves=31, lgbmclassifier__reg_alpha=0.1, lgbmclassifier__reg_lambda=0.1; total time=  37.2s\n",
      "[LightGBM] [Info] Number of positive: 13240, number of negative: 150765\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.143895 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 46253\n",
      "[LightGBM] [Info] Number of data points in the train set: 164005, number of used features: 261\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[CV] END lgbmclassifier__learning_rate=0.1, lgbmclassifier__n_estimators=250, lgbmclassifier__num_leaves=31, lgbmclassifier__reg_alpha=0.1, lgbmclassifier__reg_lambda=0.1; total time=  36.3s\n",
      "[LightGBM] [Info] Number of positive: 13240, number of negative: 150766\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.137134 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 46309\n",
      "[LightGBM] [Info] Number of data points in the train set: 164006, number of used features: 261\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "[CV] END lgbmclassifier__learning_rate=0.1, lgbmclassifier__n_estimators=250, lgbmclassifier__num_leaves=31, lgbmclassifier__reg_alpha=0.1, lgbmclassifier__reg_lambda=0.1; total time=  36.3s\n",
      "[LightGBM] [Info] Number of positive: 13240, number of negative: 150765\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.601326 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 46157\n",
      "[LightGBM] [Info] Number of data points in the train set: 164005, number of used features: 261\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[CV] END lgbmclassifier__learning_rate=0.1, lgbmclassifier__n_estimators=250, lgbmclassifier__num_leaves=41, lgbmclassifier__reg_alpha=0.1, lgbmclassifier__reg_lambda=0.1; total time=  52.8s\n",
      "[LightGBM] [Info] Number of positive: 13240, number of negative: 150765\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.644235 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 46253\n",
      "[LightGBM] [Info] Number of data points in the train set: 164005, number of used features: 261\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[CV] END lgbmclassifier__learning_rate=0.1, lgbmclassifier__n_estimators=250, lgbmclassifier__num_leaves=41, lgbmclassifier__reg_alpha=0.1, lgbmclassifier__reg_lambda=0.1; total time=  51.2s\n",
      "[LightGBM] [Info] Number of positive: 13240, number of negative: 150766\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.157100 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 46309\n",
      "[LightGBM] [Info] Number of data points in the train set: 164006, number of used features: 261\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "[CV] END lgbmclassifier__learning_rate=0.1, lgbmclassifier__n_estimators=250, lgbmclassifier__num_leaves=41, lgbmclassifier__reg_alpha=0.1, lgbmclassifier__reg_lambda=0.1; total time=  45.3s\n",
      "[LightGBM] [Info] Number of positive: 13240, number of negative: 150765\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.144927 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 46157\n",
      "[LightGBM] [Info] Number of data points in the train set: 164005, number of used features: 261\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[CV] END lgbmclassifier__learning_rate=0.1, lgbmclassifier__n_estimators=250, lgbmclassifier__num_leaves=51, lgbmclassifier__reg_alpha=0.1, lgbmclassifier__reg_lambda=0.1; total time=  46.4s\n",
      "[LightGBM] [Info] Number of positive: 13240, number of negative: 150765\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.145910 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 46253\n",
      "[LightGBM] [Info] Number of data points in the train set: 164005, number of used features: 261\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[CV] END lgbmclassifier__learning_rate=0.1, lgbmclassifier__n_estimators=250, lgbmclassifier__num_leaves=51, lgbmclassifier__reg_alpha=0.1, lgbmclassifier__reg_lambda=0.1; total time=  45.8s\n",
      "[LightGBM] [Info] Number of positive: 13240, number of negative: 150766\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.169211 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 46309\n",
      "[LightGBM] [Info] Number of data points in the train set: 164006, number of used features: 261\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "[CV] END lgbmclassifier__learning_rate=0.1, lgbmclassifier__n_estimators=250, lgbmclassifier__num_leaves=51, lgbmclassifier__reg_alpha=0.1, lgbmclassifier__reg_lambda=0.1; total time=  45.9s\n",
      "[LightGBM] [Info] Number of positive: 13240, number of negative: 150765\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.145528 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 46157\n",
      "[LightGBM] [Info] Number of data points in the train set: 164005, number of used features: 261\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[CV] END lgbmclassifier__learning_rate=0.1, lgbmclassifier__n_estimators=400, lgbmclassifier__num_leaves=21, lgbmclassifier__reg_alpha=0.1, lgbmclassifier__reg_lambda=0.1; total time=  47.4s\n",
      "[LightGBM] [Info] Number of positive: 13240, number of negative: 150765\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.514658 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 46253\n",
      "[LightGBM] [Info] Number of data points in the train set: 164005, number of used features: 261\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[CV] END lgbmclassifier__learning_rate=0.1, lgbmclassifier__n_estimators=400, lgbmclassifier__num_leaves=21, lgbmclassifier__reg_alpha=0.1, lgbmclassifier__reg_lambda=0.1; total time=  54.7s\n",
      "[LightGBM] [Info] Number of positive: 13240, number of negative: 150766\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.144446 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 46309\n",
      "[LightGBM] [Info] Number of data points in the train set: 164006, number of used features: 261\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "[CV] END lgbmclassifier__learning_rate=0.1, lgbmclassifier__n_estimators=400, lgbmclassifier__num_leaves=21, lgbmclassifier__reg_alpha=0.1, lgbmclassifier__reg_lambda=0.1; total time=  46.4s\n",
      "[LightGBM] [Info] Number of positive: 13240, number of negative: 150765\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.144658 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 46157\n",
      "[LightGBM] [Info] Number of data points in the train set: 164005, number of used features: 261\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[CV] END lgbmclassifier__learning_rate=0.1, lgbmclassifier__n_estimators=400, lgbmclassifier__num_leaves=31, lgbmclassifier__reg_alpha=0.1, lgbmclassifier__reg_lambda=0.1; total time=  52.2s\n",
      "[LightGBM] [Info] Number of positive: 13240, number of negative: 150765\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.144411 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 46253\n",
      "[LightGBM] [Info] Number of data points in the train set: 164005, number of used features: 261\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[CV] END lgbmclassifier__learning_rate=0.1, lgbmclassifier__n_estimators=400, lgbmclassifier__num_leaves=31, lgbmclassifier__reg_alpha=0.1, lgbmclassifier__reg_lambda=0.1; total time=  50.4s\n",
      "[LightGBM] [Info] Number of positive: 13240, number of negative: 150766\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.166772 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 46309\n",
      "[LightGBM] [Info] Number of data points in the train set: 164006, number of used features: 261\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "[CV] END lgbmclassifier__learning_rate=0.1, lgbmclassifier__n_estimators=400, lgbmclassifier__num_leaves=31, lgbmclassifier__reg_alpha=0.1, lgbmclassifier__reg_lambda=0.1; total time=  52.5s\n",
      "[LightGBM] [Info] Number of positive: 13240, number of negative: 150765\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.145257 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 46157\n",
      "[LightGBM] [Info] Number of data points in the train set: 164005, number of used features: 261\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[CV] END lgbmclassifier__learning_rate=0.1, lgbmclassifier__n_estimators=400, lgbmclassifier__num_leaves=41, lgbmclassifier__reg_alpha=0.1, lgbmclassifier__reg_lambda=0.1; total time=  56.6s\n",
      "[LightGBM] [Info] Number of positive: 13240, number of negative: 150765\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.143603 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 46253\n",
      "[LightGBM] [Info] Number of data points in the train set: 164005, number of used features: 261\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[CV] END lgbmclassifier__learning_rate=0.1, lgbmclassifier__n_estimators=400, lgbmclassifier__num_leaves=41, lgbmclassifier__reg_alpha=0.1, lgbmclassifier__reg_lambda=0.1; total time=  56.1s\n",
      "[LightGBM] [Info] Number of positive: 13240, number of negative: 150766\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.158940 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 46309\n",
      "[LightGBM] [Info] Number of data points in the train set: 164006, number of used features: 261\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "[CV] END lgbmclassifier__learning_rate=0.1, lgbmclassifier__n_estimators=400, lgbmclassifier__num_leaves=41, lgbmclassifier__reg_alpha=0.1, lgbmclassifier__reg_lambda=0.1; total time= 1.0min\n",
      "[LightGBM] [Info] Number of positive: 13240, number of negative: 150765\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.146069 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 46157\n",
      "[LightGBM] [Info] Number of data points in the train set: 164005, number of used features: 261\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[CV] END lgbmclassifier__learning_rate=0.1, lgbmclassifier__n_estimators=400, lgbmclassifier__num_leaves=51, lgbmclassifier__reg_alpha=0.1, lgbmclassifier__reg_lambda=0.1; total time= 1.0min\n",
      "[LightGBM] [Info] Number of positive: 13240, number of negative: 150765\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.144651 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 46253\n",
      "[LightGBM] [Info] Number of data points in the train set: 164005, number of used features: 261\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[CV] END lgbmclassifier__learning_rate=0.1, lgbmclassifier__n_estimators=400, lgbmclassifier__num_leaves=51, lgbmclassifier__reg_alpha=0.1, lgbmclassifier__reg_lambda=0.1; total time= 1.0min\n",
      "[LightGBM] [Info] Number of positive: 13240, number of negative: 150766\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.141049 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 46309\n",
      "[LightGBM] [Info] Number of data points in the train set: 164006, number of used features: 261\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "[CV] END lgbmclassifier__learning_rate=0.1, lgbmclassifier__n_estimators=400, lgbmclassifier__num_leaves=51, lgbmclassifier__reg_alpha=0.1, lgbmclassifier__reg_lambda=0.1; total time=  58.7s\n",
      "[LightGBM] [Info] Number of positive: 19860, number of negative: 226148\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.211500 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 46436\n",
      "[LightGBM] [Info] Number of data points in the train set: 246008, number of used features: 261\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "GridSearchCV complete.\n",
      "Training final LGBM model with early stopping...\n",
      "[LightGBM] [Info] Number of positive: 19860, number of negative: 226148\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.211370 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 46436\n",
      "[LightGBM] [Info] Number of data points in the train set: 246008, number of used features: 261\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[44]\tvalid_0's auc: 0.666669\tvalid_0's binary_logloss: 0.468099\n",
      "Training part done\n",
      "Optimizing threshold for business cost on validation set...\n",
      "\n",
      "Best threshold (validation) to minimize business cost: 0.6336\n",
      "Minimum business cost on validation set: -15166\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Maxime\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\mlflow\\types\\utils.py:452: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Maxime\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\mlflow\\types\\utils.py:452: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5e9e2da159cf4792be926d0b9edc26a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run ID: 80673ee8f1734525b95cebefc59f17f8 logged.\n",
      "Validation ROC-AUC: 0.7627\n",
      "Business cost: -15166\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.89      0.92     56538\n",
      "           1       0.25      0.42      0.31      4965\n",
      "\n",
      "    accuracy                           0.85     61503\n",
      "   macro avg       0.60      0.65      0.61     61503\n",
      "weighted avg       0.89      0.85      0.87     61503\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "# --- MLflow Experiment Run ---\n",
    "mlflow.set_experiment(\"business_cost Full Data LightGBM\") # To organize runs into experiments\n",
    "\n",
    "with mlflow.start_run(run_name=\"Fifth Run with full data and business cost and GridSearchCV and threshold optimization and 0 importance feature removed\"): #Utile plus tard pour fine tuning\n",
    "\n",
    "    # \n",
    "\n",
    "    # --- STAGE 1: HYPERPARAMETER TUNING WITH GRIDSEARCHCV ---\n",
    "    print(\"--- Stage 1: Hyperparameter Tuning with GridSearchCV ---\")\n",
    "\n",
    "    # Define pipeline FOR GridSearchCV\n",
    "    # Note: No n_estimators here if it's in param_grid. Early stopping is not directly used IN grid search here.\n",
    "    lgbm_for_grid = lgb.LGBMClassifier(\n",
    "        class_weight='balanced',\n",
    "        random_state=42,\n",
    "        n_jobs=1 #Valeur changée en 1 pour soucis mémorie\n",
    "    )\n",
    "    pipeline_for_grid = Pipeline([\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('lgbmclassifier', lgbm_for_grid)\n",
    "    ])\n",
    "\n",
    "    # Define Parameter Grid\n",
    "    param_grid = {\n",
    "        'lgbmclassifier__n_estimators': [100, 250, 400],       # 3 options\n",
    "        'lgbmclassifier__learning_rate': [0.05, 0.1],          # 2 options\n",
    "        'lgbmclassifier__num_leaves': [21, 31, 41, 51],        # 4 options\n",
    "        'lgbmclassifier__reg_alpha': [0.1],                    # 1 option\n",
    "        'lgbmclassifier__reg_lambda': [0.1],                   # 1 option\n",
    "    # Let's keep subsampling fixed for now to limit combinations\n",
    "    # 'lgbmclassifier__subsample': [0.8, 0.9],\n",
    "    # 'lgbmclassifier__colsample_bytree': [0.8, 0.9]\n",
    "    }\n",
    "\n",
    "    mlflow.log_param(\"gridsearch_param_grid\", str(param_grid))\n",
    "\n",
    "    cv_strategy = StratifiedKFold(n_splits=3, shuffle=True, random_state=42) # 3 splits for faster grid search\n",
    "    \n",
    "    nan_handling_strategy = \"LGBM_internal\" # On laisse LightGBM gérer les NaNs\n",
    "\n",
    "    # GridSearchCV - scoring with 'roc_auc' to find robust params\n",
    "    grid_search = GridSearchCV(\n",
    "        estimator=pipeline_for_grid,\n",
    "        param_grid=param_grid,\n",
    "        scoring='roc_auc', # Focus on good probability ranking first\n",
    "        cv=cv_strategy,\n",
    "        verbose=2,\n",
    "        n_jobs=1 # Use multiple cores if possible\n",
    "    )\n",
    "\n",
    "    print(\"Starting GridSearchCV on X_train, y_train...\")\n",
    "    grid_search.fit(X_train_filtered_with_non_null_importance, y_train) # GridSearchCV takes X_train and y_train. It internally performs cross-validation (e.g., 3-fold or 5-fold). In our case 3-fold\n",
    "    # For each combination of parameters in the param_grid: It trains the pipeline on k-1 folds. \n",
    "    # It evaluates on the 1 held-out fold using the chosen scoring metric (e.g., ROC AUC, calculated using default 0.5 threshold for predictions within the scorer). It averages the scores for each parameter combination across all folds.\n",
    "    print(\"GridSearchCV complete.\")\n",
    "\n",
    "    # outputs us the best parameters it found that we store\n",
    "    best_params_from_grid = grid_search.best_params_\n",
    "    best_cv_score_grid = grid_search.best_score_\n",
    "\n",
    "    mlflow.log_params({f\"best_gs_{k}\": v for k, v in best_params_from_grid.items()}) # Log best params from gridseach\n",
    "\n",
    "    # for k, v in best_params_from_grid.items(): This part iterates through each key-value pair in the best_params_from_grid dictionary.\n",
    "    # In each iteration, k will be the parameter name (e.g., 'lgbmclassifier__n_estimators'). v will be the corresponding best value (e.g., 400).\n",
    "\n",
    "\n",
    "\n",
    "    mlflow.log_metric(\"gridsearch_best_cv_roc_auc\", best_cv_score_grid)\n",
    "\n",
    "    # --- IMPORTANT We then use the parameters it found to use with our model and then we will train our model on our data using these parameters ---\n",
    "    \n",
    "\n",
    "    # --- Definition des callbacks ---\n",
    "\n",
    "    stopping_rounds=200\n",
    "    verbose=100\n",
    "    early_stopping_metric = 'auc'\n",
    "\n",
    "    #liste de callbacks qu'on va mettre dans le fit pour dire quels callbacks notre modèle doit utiliser durant l'entrainement\n",
    "    callbacks_list = [lgb.early_stopping(stopping_rounds=stopping_rounds, verbose=verbose)] # Stop if val AUC doesn't improve for 200 rounds, print every 100 rounds    \n",
    "    \n",
    "    # Define the validation set for early stopping\n",
    "    eval_set = [(X_val_filtered_with_non_null_importance, y_val)]\n",
    "   \n",
    "    # --- Log Callbacks parameters\n",
    "\n",
    "    mlflow.log_param(\"early_stopping_enabled\", True)\n",
    "    mlflow.log_param(\"early_stopping_rounds\", stopping_rounds)\n",
    "    mlflow.log_param(\"early_stopping_metric\", early_stopping_metric)\n",
    "\n",
    "\n",
    "\n",
    "    # --- IMPORTANT --- Meme si LightGBM utilise par défaut binary logloss ici on va utiliser ROC AUC car :\n",
    "    # Log loss can sometimes be sensitive to outliers or poorly calibrated probabilities. It might not perfectly align with the final business metric you care about (which might be AUC, F1, precision, recall, etc.).\n",
    "    # ROC AUX a aussi ses désavantages : Cons: AUC is threshold-independent, so stopping based on it doesn't guarantee optimal performance at the specific threshold you might choose later (though it's usually highly correlated).\n",
    "    # Mais globalement AUC is a common and robust metric for evaluating binary classifier performance, especially with imbalanced datasets. It measures the model's ability to rank positive instances higher than negative ones, irrespective of the specific threshold. \n",
    "    # Stopping based on validation AUC ensures you stop when this ranking ability stops improving. Often aligns better with overall classification quality goals than log loss.\n",
    "    # Le seul vrai avantage d'utiliser la même métrique que celle que le modèle regarde pendant son entrainement ici la log loss c'est que :\n",
    "    # Directly related to the function the model is optimizing. Stopping based on validation log loss ensures you stop when the model's probabilistic predictions stop improving on unseen data according to that specific loss function.\n",
    "\n",
    "\n",
    "    # --- Important --- Etant donné que l'on utilise EarlyStopping on souhaite avoir assez d'itérations pour que EarlyStopping soit pertinent\n",
    "    # Donc malgré le fait que GridSearchCV nous ait trouvé une valeur pour n_estimators, on vasimplement la remplacer par une valeur élevée pour être sur que EarlyStopping fasse effet\n",
    "\n",
    "    # 1. Create the base dictionary from GridSearchCV results, stripping prefixes\n",
    "    \n",
    "    # In best_params_from_grid which is a dictionnary so we have key value pairs each key so the name of the parameter has the prefix lgbmclassifier__ which we remove for clarity\n",
    "\n",
    "    final_lgbm_params = {\n",
    "    key.replace('lgbmclassifier__', ''): value\n",
    "    for key, value in best_params_from_grid.items()\n",
    "    }\n",
    "\n",
    "    # 2. Add/Ensure the fixed base parameters are present because they were not in best_params_from_grid\n",
    "    #    This will add them if they weren't tuned\n",
    "    final_lgbm_params['class_weight'] = 'balanced'\n",
    "    final_lgbm_params['random_state'] = 42\n",
    "    final_lgbm_params['n_jobs'] = 1 # Changée en 1 pour soucis de mémoire\n",
    "\n",
    "    # 3. Explicitly set n_estimators to a high value for early stopping.\n",
    "    #    This will override the n_estimators value that came from GridSearchCV.\n",
    "    final_lgbm_params['n_estimators'] = 2000\n",
    "\n",
    "\n",
    "    # --- Define Model & Pipeline ---\n",
    "    pipeline_lgbm_final = make_pipeline( # Renamed to avoid confusion with grid search pipeline\n",
    "    StandardScaler(),\n",
    "    lgb.LGBMClassifier(**final_lgbm_params) # Use the defined parameters ** is for dictionnary unpacking\n",
    "    )\n",
    "\n",
    "    mlflow.log_params({f\"best_gs_final_{k}\": v for k, v in final_lgbm_params.items()}) # Log best params with sligh adjustments\n",
    "\n",
    "    # --- Log Parameters ---\n",
    "    mlflow.log_param(\"model_type\", \"LightGBM\") # Updated\n",
    "    mlflow.log_param(\"imputation_merge_nans\", \"ZeroFill\") # Example for merge NaNs\n",
    "    mlflow.log_param(\"nan_handling_model\", nan_handling_strategy) # Log NaN strategy\n",
    "    mlflow.log_param(\"scaling\", \"StandardScaler\")\n",
    "    mlflow.log_param(\"class_weight\", \"balanced\")\n",
    "    mlflow.log_param(\"random_state\", 42)\n",
    "    mlflow.log_param(\"train_val_split\", 0.2)\n",
    "\n",
    "    # --- Train model ---\n",
    "\n",
    "    print(\"Training final LGBM model with early stopping...\")\n",
    "\n",
    "    pipeline_lgbm_final.fit(\n",
    "        X_train_filtered_with_non_null_importance, y_train,\n",
    "        # Pass eval_set for early stopping\n",
    "        lgbmclassifier__eval_set=eval_set, #eval_set est une liste contenant des validation sets (as tuples of (X_val, y_val)) pour controler/monitor performances. Early stopping uses this to decide when to stop.\n",
    "        lgbmclassifier__eval_metric=early_stopping_metric,\n",
    "        # Use callbacks argument for early stopping\n",
    "        lgbmclassifier__callbacks=callbacks_list\n",
    "        )\n",
    "    \n",
    "    print(\"Training part done\")\n",
    "\n",
    "    # --- After fitting ---\n",
    "    \n",
    "    #  --- IMPORTANT ---best_iteration as a metric tells us how many trees were actually used in the final model selected by early stopping\n",
    "    fitted_lgbm = pipeline_lgbm_final.named_steps['lgbmclassifier']\n",
    "    if fitted_lgbm.best_iteration_:\n",
    "        mlflow.log_metric(\"best_iteration\", fitted_lgbm.best_iteration_)\n",
    "        # Optional: Update the n_estimators param if you want to reflect the stopped value\n",
    "        # mlflow.log_param(\"actual_n_estimators\", fitted_lgbm.best_iteration_)\n",
    "    else:\n",
    "        # Log if early stopping didn't trigger (ran full n_estimators)\n",
    "        mlflow.log_metric(\"best_iteration\", fitted_lgbm.n_estimators)\n",
    "        # mlflow.log_param(\"actual_n_estimators\", fitted_lgbm.n_estimators)\n",
    "\n",
    "    # --- Predict & Calcul des métriques ---\n",
    "    y_pred = pipeline_lgbm_final.predict(X_val_filtered_with_non_null_importance)\n",
    "    y_proba = pipeline_lgbm_final.predict_proba(X_val_filtered_with_non_null_importance)[:, 1] # Probabilities for class 1\n",
    "\n",
    "    # --- Find the best threshold to minimize business cost ---\n",
    "    \n",
    "    # 1. Defining a range of thresholds\n",
    "    thresholds_to_try = np.linspace(0.01, 0.99, 100) # Trying 100 thresholds\n",
    "\n",
    "    # 2. Initialize variables to store the best findings\n",
    "    min_val_cost = float('inf') # Initialize minimum cost to positive infinity (so any real cost will be lower)\n",
    "    best_val_threshold_cost = 0.5 # Initialize best threshold to a default (e.g., 0.5)\n",
    "    y_pred_val_at_min_cost = None # To store the predictions made using the best threshold\n",
    "\n",
    "    # 3. Loop through each threshold\n",
    "    print(\"Optimizing threshold for business cost on validation set...\")\n",
    "    for threshold in thresholds_to_try:\n",
    "    # 3a. Convert probabilities to class predictions based on the current threshold\n",
    "        y_pred_temp_val = (y_proba >= threshold).astype(int)\n",
    "    # If y_val_proba is >= current threshold, predict 1 (default), else predict 0 (repay)\n",
    "\n",
    "    # 3b. Calculate the business cost using these temporary predictions\n",
    "        current_val_cost = calculate_business_cost(y_val, y_pred_temp_val,\n",
    "                                             cost_fn=10, cost_fp=1, cost_tn=(-1))\n",
    "\n",
    "    # 3c. Check if this threshold gives a lower cost\n",
    "        if current_val_cost < min_val_cost:           # Initial value is positive infinity so first one always registered an then only lower business costs can replace it\n",
    "            min_val_cost = current_val_cost           # Update minimum cost\n",
    "            best_val_threshold_cost = threshold       # Update best threshold\n",
    "            y_pred_val_at_min_cost = y_pred_temp_val  # Store these predictions\n",
    "\n",
    "    # 4. Output the results\n",
    "    print(f\"\\nBest threshold (validation) to minimize business cost: {best_val_threshold_cost:.4f}\")\n",
    "    print(f\"Minimum business cost on validation set: {min_val_cost}\")\n",
    "    # y_pred_val_at_min_cost now holds the predictions that achieve this minimum cost\n",
    "\n",
    "    accuracy = accuracy_score(y_val, y_pred_val_at_min_cost)\n",
    "    f1 = f1_score(y_val, y_pred_val_at_min_cost) # Default F1 for class 1\n",
    "    roc_auc = roc_auc_score(y_val, y_proba)\n",
    "    report = classification_report(y_val, y_pred_val_at_min_cost, output_dict=True) # Get report as dict\n",
    "\n",
    "    # --- Log métriques ---\n",
    "    mlflow.log_metric(\"best_business_cost_obtained\", min_val_cost)\n",
    "    mlflow.log_metric(\"best_threshold_to_minimize_business_cost\", best_val_threshold_cost)\n",
    "    mlflow.log_metric(\"val_accuracy\", accuracy)\n",
    "    mlflow.log_metric(\"val_f1_score\", f1)\n",
    "    mlflow.log_metric(\"val_roc_auc\", roc_auc)\n",
    "    # metrics from classification report\n",
    "    mlflow.log_metric(\"val_precision_0\", report['0']['precision'])\n",
    "    mlflow.log_metric(\"val_recall_0\", report['0']['recall'])\n",
    "    mlflow.log_metric(\"val_f1_0\", report['0']['f1-score'])\n",
    "    mlflow.log_metric(\"val_precision_1\", report['1']['precision'])\n",
    "    mlflow.log_metric(\"val_recall_1\", report['1']['recall'])\n",
    "    mlflow.log_metric(\"val_f1_1\", report['1']['f1-score'])\n",
    "\n",
    "    # --- Input Example ---\n",
    "    input_example = X_train.head(5) #Input example = small sample of valid input data (like one or a few rows from X_train or X_val DataFrame) that demonstrates the expected format.\n",
    "    #Sert a si jamais on souhaite se resservir du modèle à ce qu'il vérifie que les données d'entrée aient le format attendu ici DataFrame Pandas\n",
    "\n",
    "    # --- Log Model ---\n",
    "    mlflow.lightgbm.log_model(\n",
    "        lgb_model=pipeline_lgbm_final.named_steps['lgbmclassifier'], # Log the LGBM step\n",
    "        artifact_path=\"lightgbm_model\",\n",
    "        input_example=X_train_filtered_with_non_null_importance.head(5) # Provide example\n",
    "        )\n",
    "\n",
    "\n",
    "    # --- Log Artifacts (Example: Confusion Matrix) ---\n",
    "    cm = confusion_matrix(y_val, y_pred_val_at_min_cost, labels=pipeline_lgbm_final.classes_)\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=pipeline_lgbm_final.classes_)\n",
    "    disp.plot()\n",
    "    plt.title(f\"Confusion Matrix LGBM (Validation Set)\")\n",
    "    cm_path = \"confusion_matrix_lgbm_val.png\"\n",
    "    plt.savefig(cm_path)\n",
    "    mlflow.log_artifact(cm_path)\n",
    "    plt.close() # Close the plot to prevent display in notebook output if desired\n",
    "\n",
    "    print(f\"Run ID: {mlflow.active_run().info.run_id} logged.\")\n",
    "    print(f\"Validation ROC-AUC: {roc_auc:.4f}\")\n",
    "    print(f\"Business cost: {min_val_cost}\")\n",
    "    print(classification_report(y_val, y_pred_val_at_min_cost))\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08f533d9",
   "metadata": {},
   "source": [
    "Apres analyse des résultats on peut voir que en enlevant les 878 features ayant une importance = 0 on se retrouve avec des résultats légérements moins bon +1596 de business cost et ROC AUC -0.016 ce qui est assez léger. \n",
    "Malgré le fait que nos résultats soient légérement moins bons on va choisir ce nouveau modèle comme notre baseline pour les raisons suivantes :\n",
    "Il est très probable que sur ces 878 variables que l'on a enlevées même si certaines pouvaient contribuer positivement à la précision du modèle il y a de grandes chances que la majeure partie était en réalité une source de bruit et que le fait que nos résultats soient légérements moins bons soit du au fait que l'on ait supprimé ce bruit.\n",
    "En enlevant ces variables on se retrouve avec un modèle moins succeptible à l'overfitting car il ne va pas s'entrainer sur ce bruit et sera donc aussi capable de mieux généraliser.\n",
    "Si l'on souhaite optimiser/fine tune les paramètres avec gridsearch ce sera beaucoup plus simple avec moins de features.\n",
    "Notre modèle sera aussi plus simple à interpréter."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7844e0b5",
   "metadata": {},
   "source": [
    "# Second feature importance analysis after having removed 0 importance features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26c86b08",
   "metadata": {},
   "source": [
    "On va procéder a la suite de l'analyse de feature importance"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
